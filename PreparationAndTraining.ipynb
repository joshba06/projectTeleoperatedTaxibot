{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshba06/Object_Detection/blob/main/PreparationAndTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h3jZ8O9eJKiC",
      "metadata": {
        "id": "h3jZ8O9eJKiC"
      },
      "source": [
        "# Readme\n",
        "\n",
        "**Step 1**: \n",
        "\n",
        "This script has to be run on both, Colab (training) and the local machine (object detection). Set the variable \"system_id\" to 1, if running on Colab or to 0 if running on local machine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bba4db",
      "metadata": {
        "id": "16bba4db"
      },
      "source": [
        "# 1. Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xTsthyMa7O1t",
      "metadata": {
        "id": "xTsthyMa7O1t"
      },
      "source": [
        "## 1.1 Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "900cbd24",
      "metadata": {
        "id": "900cbd24"
      },
      "outputs": [],
      "source": [
        "# Choose 1, if running on colab and 0 if running on local machine\n",
        "system_id = 1\n",
        "\n",
        "# Define the objects that you would like to train the deep learning-model with below\n",
        "labels = ['Car', 'Mug']\n",
        "\n",
        "# Change model url and name if model changes\n",
        "pre_trained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "pre_trained_model_name = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "custom_model_name = 'my_ssd_mobilenet_v2_fpnlite'\n",
        "\n",
        "img_size = (640, 640)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb1fba8",
      "metadata": {
        "id": "edb1fba8"
      },
      "source": [
        "## 1.2 Create file and folder structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "VYjsBYZoo2PX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYjsBYZoo2PX",
        "outputId": "f404483b-7b53-40c3-9b64-34c4445df23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Local machine\n",
        "if system_id == 0:\n",
        "    home_path = '/Users/niklas/Virtual_Environment/Version_4/Object_Detection'\n",
        "    print('Running on local machine...')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "    \n",
        "    print('Running on Google Colab...')\n",
        "    \n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Setup path to home directory \n",
        "    home_path = '/content/drive/MyDrive/Colab_Notebooks/Object_Detection'\n",
        "    os.chdir(home_path)    \n",
        "\n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "56a85065",
      "metadata": {
        "id": "56a85065",
        "outputId": "895ba508-07df-4f1e-bbb9-ad5f370b4901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/0_User_Input already exists..\n",
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/0_User_Input/backgrounds already exists..\n",
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/0_User_Input/objects already exists..\n",
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/1_Preprocessing already exists..\n",
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/1_Preprocessing/images already exists..\n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/protoc from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/scripts from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/images/training from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/images/testing from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/models from scratch. \n",
            "Successfully created /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/pre_trained_models from scratch. \n",
            "/content/drive/MyDrive/Colab_Notebooks/Object_Detection/3_Output already exists..\n"
          ]
        }
      ],
      "source": [
        "import setup\n",
        "files, paths = setup.createFolderStructure(labels, home_path, system_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "caaf9fcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caaf9fcf",
        "outputId": "5a85cbca-3f1d-4bd8-83a2-5ab37a2592e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Car': 1, 'Mug': 2}\n"
          ]
        }
      ],
      "source": [
        "# Create dict with labels\n",
        "dict_labels = {}\n",
        "num = 1\n",
        "for label in labels:\n",
        "    dict_labels[label]= num\n",
        "    num += 1\n",
        "print(dict_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d6bd0a",
      "metadata": {
        "id": "44d6bd0a"
      },
      "source": [
        "## 1.3 Installing Dependencies and importing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e42ecf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e42ecf9",
        "outputId": "693f87f6-7124-4fb1-a119-4293fb2df8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python 4.6.0.66\n",
            "Uninstalling opencv-python-4.6.0.66:\n",
            "  Successfully uninstalled opencv-python-4.6.0.66\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.6.0.66\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python -y\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "01564f7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01564f7e",
        "outputId": "80d062bb-879c-4582-d893-a1ac930b1afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f4bb5647",
      "metadata": {
        "id": "f4bb5647"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "\n",
        "import uuid\n",
        "\n",
        "import time\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import shutil\n",
        "\n",
        "import math\n",
        "\n",
        "import wget"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "520241f2",
      "metadata": {
        "id": "520241f2"
      },
      "source": [
        "# 3. Prepare Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d900ebb",
      "metadata": {
        "id": "2d900ebb"
      },
      "source": [
        "## 3.1 Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a7923f0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a7923f0c",
        "outputId": "7707ed6e-a4f1-47aa-f963-8f5327cb7ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu==2.5.0 in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (3.19.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (2.9.1)\n",
            "Collecting numpy~=1.19.2\n",
            "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0) (2.5.0.dev2021032900)\n",
            "Collecting absl-py~=0.10\n",
            "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.2.0)\n",
            "Installing collected packages: numpy, absl-py, tensorflow-estimator\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.1.0\n",
            "    Uninstalling absl-py-1.1.0:\n",
            "      Successfully uninstalled absl-py-1.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tf-models-official 2.9.2 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.9.1 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
            "tensorflow 2.9.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.9.1 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 numpy-1.19.5 tensorflow-estimator-2.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    !pip install tensorflow==2.5.0\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "    !pip install tensorflow-gpu==2.5.0 \n",
        "\n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e16c0b45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e16c0b45",
        "outputId": "b678b7d5-2978-4ad5-d083-b5afcbe9ddc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning model garden..\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 74953, done.\u001b[K\n",
            "remote: Counting objects: 100% (441/441), done.\u001b[K\n",
            "remote: Compressing objects: 100% (206/206), done.\u001b[K\n",
            "remote: Total 74953 (delta 261), reused 386 (delta 230), pack-reused 74512\u001b[K\n",
            "Receiving objects: 100% (74953/74953), 580.52 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (53161/53161), done.\n",
            "Checking out files: 100% (3087/3087), done.\n"
          ]
        }
      ],
      "source": [
        "# Download the model garden (model garden is an environment that is necessary to train new models from scratch or to continue training existing models)\n",
        "# The model itself will be downloaded later\n",
        "\n",
        "# Clone repository only if it does not exist already\n",
        "os.chdir(paths['2_Tensorflow'])\n",
        "if os.path.exists(paths['2_Tensorflow']+'/models/research') is False:\n",
        "    print('Cloning model garden..')\n",
        "    !git clone https://github.com/tensorflow/models.git\n",
        "    \n",
        "else:\n",
        "    print('Model garden already exists')\n",
        "    \n",
        "os.chdir(paths['home'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1c6592a9",
      "metadata": {
        "id": "1c6592a9"
      },
      "outputs": [],
      "source": [
        "# Install protobuf\n",
        "if os.path.exists(paths['2_Tensorflow']+'/protoc/protoc-21.1-osx-aarch_64.zip') is False:\n",
        "\n",
        "    # Go to destination directory\n",
        "    os.chdir(paths['protoc'])\n",
        "    protoc_url = 'https://github.com/protocolbuffers/protobuf/releases/download/v21.1/protoc-21.1-osx-aarch_64.zip'\n",
        "    wget.download(protoc_url)\n",
        "\n",
        "    # Extract all content of downloaded file\n",
        "    from zipfile import ZipFile\n",
        "\n",
        "    with ZipFile('protoc-21.1-osx-aarch_64.zip', 'r') as zipObj:\n",
        "        zipObj.extractall()\n",
        "\n",
        "    os.environ['Path'] = paths['protoc']+'/bin'\n",
        "    os.chdir(paths['research'])\n",
        "\n",
        "    !protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "else:\n",
        "    print('Protobuf was already installed...')\n",
        "    \n",
        "os.chdir(paths['home'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "06ec3dc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ec3dc7",
        "outputId": "701dfb16-7d67-4fc8-bf5f-daabcbc1f029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning cocoapi..\n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 11.79 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ],
      "source": [
        "# Install pycocotools\n",
        "\n",
        "# Clone repository only if it does not exist already\n",
        "if os.path.exists(paths['research']+'/cocoapi') is False:\n",
        "    print('Cloning cocoapi..')\n",
        "    !git clone https://github.com/cocodataset/cocoapi.git\n",
        "    \n",
        "    # Moving cloned file to 'research' folder\n",
        "    destination = paths['research']\n",
        "    source = paths['home']+'/cocoapi'\n",
        "    shutil.move(source, destination)\n",
        "    \n",
        "else:\n",
        "    print('Cocoapi already exists')\n",
        "\n",
        "os.chdir(paths['home'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe70c4aa",
      "metadata": {
        "id": "fe70c4aa"
      },
      "source": [
        "## 3.2 Install Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b2d18cae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2d18cae",
        "outputId": "c8d449f3-d8d7-49bd-a822-f253526fbec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing setup.py...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.40.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.2)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Collecting numpy>=1.20\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.34.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.20.6)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.6)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694828 sha256=da021a888e013e66978f32f96291936e03da6ed46d0ebe507c57748054e6d627\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hpt1y40/wheels/5a/0f/27/a4adf217e3ad3683ebe0da1bf262ad626015edc70f47dc9aab\n",
            "Successfully built object-detection\n",
            "Installing collected packages: numpy, absl-py, tensorflow-estimator, object-detection\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.5.0 requires absl-py~=0.10, but you have absl-py 1.1.0 which is incompatible.\n",
            "tensorflow-gpu 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.9.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-1.1.0 numpy-1.21.6 object-detection-0.1 tensorflow-estimator-2.9.0\n",
            "Installation complete..\n"
          ]
        }
      ],
      "source": [
        "# Check if API has already been installed\n",
        "if os.path.exists(paths['research']+'/setup.py') is False:\n",
        "    print('Installing setup.py...')\n",
        "    \n",
        "    # Move to 'research' directory\n",
        "    os.chdir(paths['research'])\n",
        "\n",
        "    # Copy setup.py to current working directory\n",
        "    !cp object_detection/packages/tf2/setup.py .\n",
        "\n",
        "    # Execute setup.py (this command installs all dependencies needed for tf2 odapi)\n",
        "    !python -m pip install .\n",
        "\n",
        "    print('Installation complete..')\n",
        "\n",
        "else:\n",
        "    print('Object Detection API has already been installed')\n",
        "\n",
        "# Move back to home-directory\n",
        "os.chdir(paths['home'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a00f3be",
      "metadata": {
        "id": "9a00f3be"
      },
      "source": [
        "## 3.3 Check if API was installed successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "70dfbfba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70dfbfba",
        "outputId": "1c5d0969-1156-41e6-9af6-f2137099198d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-07-06 15:35:07.860486: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0706 15:35:08.412369 140463042905984 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.49s\n",
            "I0706 15:35:09.040414 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.13s\n",
            "I0706 15:35:10.173949 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
            "I0706 15:35:10.658634 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "I0706 15:35:10.975452 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
            "I0706 15:35:12.872871 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.9s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0706 15:35:12.873960 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0706 15:35:12.895821 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0706 15:35:12.909879 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0706 15:35:12.925076 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0706 15:35:13.019892 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0706 15:35:13.110989 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "I0706 15:35:13.210301 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0706 15:35:13.301280 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0706 15:35:13.395848 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0706 15:35:13.423074 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0706 15:35:13.602042 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0706 15:35:13.602219 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0706 15:35:13.602289 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0706 15:35:13.604320 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:13.623286 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:13.623417 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:13.682330 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:13.682468 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:13.844578 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:13.844746 140463042905984 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0706 15:35:14.003345 140463042905984 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0706 15:35:14.003525 140463042905984 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0706 15:35:14.239097 140463042905984 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0706 15:35:14.239275 140463042905984 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0706 15:35:14.468609 140463042905984 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0706 15:35:14.468786 140463042905984 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0706 15:35:14.783099 140463042905984 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0706 15:35:14.783284 140463042905984 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0706 15:35:14.858626 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0706 15:35:14.890587 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:15.097739 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0706 15:35:15.097933 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0706 15:35:15.098013 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0706 15:35:15.099771 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:15.115586 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:15.115708 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:15.237542 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:15.237706 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:15.478790 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:15.478960 140463042905984 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0706 15:35:15.710533 140463042905984 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0706 15:35:15.710708 140463042905984 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0706 15:35:16.022505 140463042905984 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0706 15:35:16.022681 140463042905984 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0706 15:35:16.330509 140463042905984 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0706 15:35:16.330680 140463042905984 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0706 15:35:16.714899 140463042905984 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0706 15:35:16.715080 140463042905984 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0706 15:35:16.867849 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0706 15:35:16.895962 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:16.957171 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0706 15:35:16.957369 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0706 15:35:16.957466 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0706 15:35:16.959089 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:16.974744 140463042905984 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0706 15:35:16.974883 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:17.108084 140463042905984 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0706 15:35:17.108267 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:17.342045 140463042905984 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0706 15:35:17.342220 140463042905984 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0706 15:35:17.569905 140463042905984 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0706 15:35:17.570276 140463042905984 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0706 15:35:17.932587 140463042905984 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0706 15:35:17.932802 140463042905984 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0706 15:35:18.271482 140463042905984 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0706 15:35:18.271706 140463042905984 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0706 15:35:18.675576 140463042905984 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0706 15:35:18.675788 140463042905984 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0706 15:35:18.822696 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0706 15:35:18.851384 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:18.908993 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0706 15:35:18.909168 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0706 15:35:18.909241 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0706 15:35:18.910958 140463042905984 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0706 15:35:18.926232 140463042905984 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0706 15:35:18.926339 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:19.049289 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:19.049452 140463042905984 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0706 15:35:19.283293 140463042905984 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0706 15:35:19.283474 140463042905984 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0706 15:35:19.505272 140463042905984 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0706 15:35:19.505442 140463042905984 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0706 15:35:19.885271 140463042905984 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0706 15:35:19.885442 140463042905984 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0706 15:35:20.456103 140463042905984 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0706 15:35:20.456287 140463042905984 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0706 15:35:20.982822 140463042905984 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0706 15:35:20.983021 140463042905984 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0706 15:35:21.134599 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0706 15:35:21.162642 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:21.225395 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0706 15:35:21.225544 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0706 15:35:21.225618 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0706 15:35:21.227155 140463042905984 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0706 15:35:21.242609 140463042905984 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0706 15:35:21.242717 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:21.366824 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:21.366989 140463042905984 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0706 15:35:21.674422 140463042905984 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0706 15:35:21.674590 140463042905984 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0706 15:35:22.007224 140463042905984 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0706 15:35:22.007395 140463042905984 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0706 15:35:22.468906 140463042905984 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0706 15:35:22.469084 140463042905984 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0706 15:35:22.942198 140463042905984 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0706 15:35:22.942365 140463042905984 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0706 15:35:23.577821 140463042905984 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0706 15:35:23.577997 140463042905984 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0706 15:35:23.727986 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0706 15:35:23.765799 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:23.837199 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0706 15:35:23.837358 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0706 15:35:23.837432 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0706 15:35:23.838912 140463042905984 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0706 15:35:23.853885 140463042905984 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0706 15:35:23.853994 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:24.034024 140463042905984 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0706 15:35:24.034209 140463042905984 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0706 15:35:24.431142 140463042905984 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0706 15:35:24.431312 140463042905984 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0706 15:35:24.838044 140463042905984 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0706 15:35:24.838230 140463042905984 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0706 15:35:25.380600 140463042905984 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0706 15:35:25.380771 140463042905984 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0706 15:35:26.163014 140463042905984 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0706 15:35:26.163206 140463042905984 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0706 15:35:26.863152 140463042905984 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0706 15:35:26.863326 140463042905984 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0706 15:35:27.094005 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0706 15:35:27.122445 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:27.204060 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0706 15:35:27.204228 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0706 15:35:27.204298 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0706 15:35:27.205784 140463042905984 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0706 15:35:27.221227 140463042905984 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0706 15:35:27.221338 140463042905984 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0706 15:35:27.409330 140463042905984 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0706 15:35:27.409533 140463042905984 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0706 15:35:27.871304 140463042905984 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0706 15:35:27.871478 140463042905984 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0706 15:35:28.325998 140463042905984 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0706 15:35:28.326179 140463042905984 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0706 15:35:28.950862 140463042905984 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0706 15:35:28.951035 140463042905984 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0706 15:35:29.605588 140463042905984 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0706 15:35:29.605768 140463042905984 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0706 15:35:30.461437 140463042905984 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0706 15:35:30.461630 140463042905984 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0706 15:35:30.725799 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0706 15:35:30.753043 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0706 15:35:30.847517 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0706 15:35:30.847679 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0706 15:35:30.847747 140463042905984 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0706 15:35:30.849275 140463042905984 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0706 15:35:30.864724 140463042905984 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0706 15:35:30.864835 140463042905984 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0706 15:35:31.139033 140463042905984 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0706 15:35:31.139219 140463042905984 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0706 15:35:31.901229 140463042905984 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0706 15:35:31.901428 140463042905984 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0706 15:35:32.433017 140463042905984 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0706 15:35:32.433202 140463042905984 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0706 15:35:33.220931 140463042905984 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0706 15:35:33.221107 140463042905984 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0706 15:35:33.983989 140463042905984 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0706 15:35:33.984186 140463042905984 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0706 15:35:35.015675 140463042905984 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0706 15:35:35.015882 140463042905984 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0706 15:35:35.349420 140463042905984 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0706 15:35:35.378366 140463042905984 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.07s\n",
            "I0706 15:35:35.489000 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0706 15:35:35.494909 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0706 15:35:35.496490 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0706 15:35:35.496957 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0706 15:35:35.498365 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0706 15:35:35.499818 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0706 15:35:35.500270 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0706 15:35:35.501198 140463042905984 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.949s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "# Move to 'research' directory\n",
        "os.chdir(paths['research'])\n",
        "import object_detection\n",
        "\n",
        "# Local machine\n",
        "if system_id == 0:\n",
        "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
        "    \n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "    !pip install numpy --upgrade # This had to be added for execution on colab. Problem solved using stackoverflow\n",
        "\n",
        "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
        "else:\n",
        "    print('No operating system was defined...')\n",
        "\n",
        "# Move back to home directory\n",
        "os.chdir(paths['home'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0006de28",
      "metadata": {
        "id": "0006de28"
      },
      "source": [
        "# 4. Prepare new training job"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e441180b",
      "metadata": {
        "id": "e441180b"
      },
      "source": [
        "## 4.1 Install dependencies and import modules (only on Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "57a4556e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57a4556e",
        "outputId": "da9eb563-7db9-418e-f2f2-6a91cca5180b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "  \n",
        "  ## Install missing modules for randomTrafficSign\n",
        "  !pip install matplotlib\n",
        "  !pip install lxml\n",
        "\n",
        "  import numpy as np\n",
        "  from xml.etree.ElementTree import ElementTree\n",
        "  from xml.etree.ElementTree import Element\n",
        "  import xml.etree.ElementTree as etree\n",
        "  import xml.dom.minidom\n",
        "\n",
        "  from lxml import etree\n",
        "  os.chdir(paths['home'])\n",
        "\n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XxrqC-lQ7IXF",
      "metadata": {
        "id": "XxrqC-lQ7IXF"
      },
      "source": [
        "## 4.2 Partition images for testing and training (only on Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KYPtSyTxziNo",
      "metadata": {
        "id": "KYPtSyTxziNo"
      },
      "source": [
        "**Important**: Images of objects must be in the following format: \"Mug_1.jpg\", \"Cat_3.jpg\" and must be located in their respective folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "KqMKGZRBYKfR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqMKGZRBYKfR",
        "outputId": "433ce14a-67df-4d49-e66a-6de70c95bdd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (5.4.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "    !pip install -U albumentations --no-binary qudida,albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "sapVybbT3jYk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sapVybbT3jYk",
        "outputId": "7892db7f-d6d3-47f2-8160-facde352a266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 backgrounds\n",
            "Found 7 objects for label: Car. Multiplying by factor 150\n",
            "Multiplying image: Car_4.png\n",
            "Multiplying image: Car_3.png\n",
            "Multiplying image: Car_6.png\n",
            "Multiplying image: Car_7.png\n",
            "Multiplying image: Car_2.png\n",
            "Multiplying image: Car_1.png\n",
            "Multiplying image: Car_5.png\n",
            "Multiplication completed. Currently available for label: Car, total: 1050, testing: 158, training: 892\n",
            "Found 3 objects for label: Mug. Multiplying by factor 150\n",
            "Multiplying image: Mug_3.png\n",
            "Multiplying image: Mug_2.png\n",
            "Multiplying image: Mug_1.png\n",
            "Multiplication completed. Currently available for label: Mug, total: 450, testing: 68, training: 382\n"
          ]
        }
      ],
      "source": [
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "    # imagePreprocessing.py must be in same directory as this main script\n",
        "    %matplotlib inline\n",
        "    path = paths['0_User_Input']+'/scripts'\n",
        "    os.chdir(path)\n",
        "    import imageProcessing as imgprep\n",
        "    os.chdir(paths['home'])\n",
        "\n",
        "    imgprep.clearPreprocessing(paths['images'])\n",
        "    imgprep.clearTraining(paths['training']+'/images')\n",
        "\n",
        "    numImgs = 150\n",
        "    upperScale = 150\n",
        "    lowerScale = 80\n",
        "\n",
        "    # Modify and multiply images and store in 1_Preprocessing folder\n",
        "    imgprep.main(dict_labels, paths['backgrounds'], paths['objects'], numImgs, upperScale, lowerScale, paths['images']+'/', paths['training']+'/')\n",
        "\n",
        "    imgprep.clearPreprocessing(paths['images'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11a93934",
      "metadata": {
        "id": "11a93934"
      },
      "source": [
        "## 5.4 Create labelmap (only on Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c6e44434",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6e44434",
        "outputId": "36819b83-f3a5-48a4-af04-e9af7dfd38da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'Car', 'id': 1}, {'name': 'Mug', 'id': 2}]\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "    # Convert label-dict to needed format\n",
        "    labelmap = []\n",
        "    for key in dict_labels:\n",
        "      temp = {}\n",
        "      temp['name'] = key\n",
        "      temp['id'] = dict_labels[key]\n",
        "      labelmap.append(temp)\n",
        "    print(labelmap)\n",
        "\n",
        "    files['labelmap'] = paths['annotations']+'/label_map.pbtxt'\n",
        "\n",
        "    with open(files['labelmap'], 'w') as file:\n",
        "      for label in labelmap:\n",
        "          file.write('item { \\n')\n",
        "          file.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "          file.write('\\tid:{}\\n'.format(label['id']))\n",
        "          file.write('}\\n')\n",
        "        \n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42670147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42670147",
        "outputId": "a33a2d30-e496-40a7-ae26-23ac2eaa3365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install pandas\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edbe07d6",
      "metadata": {
        "id": "edbe07d6"
      },
      "source": [
        "## 5.5 Create TFRecord (only on colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3668f3c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3668f3c2",
        "outputId": "f254afdd-87c1-45ae-8c7a-7ef2dfd57247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "  # Add labelmap and tfrecords to 'files' dictionary\n",
        "  files['tf_train'] = paths['annotations']+'/train.record'\n",
        "  files['tf_test'] = paths['annotations']+'/test.record'\n",
        "\n",
        "  # Add line to download TF record file from nicknochnack\n",
        "\n",
        "  # Copy generatetfrecord.py to scripts\n",
        "  source = paths['0_User_Input']+'/scripts/generatetfrecord.py'\n",
        "  shutil.copy(source, paths['scripts'])\n",
        "\n",
        "  # Change directory to 'scripts'\n",
        "  os.chdir(paths['workspace']+'/scripts')\n",
        "\n",
        "  # Create / overwrite TFRecord files for training and testing\n",
        "\n",
        "  # Create train data:\n",
        "  !python generatetfrecord.py -x {paths['images_training']} -l {files['labelmap']} -o {files['tf_train']}\n",
        "\n",
        "  # Create test data:\n",
        "  !python generatetfrecord.py -x {paths['images_testing']} -l {files['labelmap']} -o {files['tf_test']}\n",
        "\n",
        "  # Go back to home directory\n",
        "  os.chdir(paths['home'])\n",
        "\n",
        " \n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b339fe9",
      "metadata": {
        "id": "3b339fe9"
      },
      "source": [
        "## 5.6 Download pre-trained model (only on colab)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "44cd98fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44cd98fc",
        "outputId": "d6d5bc01-0a21-48de-ca18-ffedd1725471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was successfully downloaded...\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "  # Update the settings for the image import and multiplication script depending on which size of image the model uses!\n",
        "\n",
        "  # Check if the chosen model has already been downloaded\n",
        "  if os.path.exists(paths['pre_trained_models']+'/'+str(pre_trained_model_name)) is False:\n",
        "\n",
        "      # Go to destination directory\n",
        "      os.chdir(paths['pre_trained_models'])\n",
        "      wget.download(pre_trained_model_url)\n",
        "\n",
        "      # Extract all content of downloaded file\n",
        "      import tarfile\n",
        "\n",
        "      file = tarfile.open('ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz')\n",
        "\n",
        "      file.extractall(paths['pre_trained_models'])\n",
        "\n",
        "      file.close()\n",
        "                    \n",
        "      # Delete downloaded tar.gz file to save storage space\n",
        "      # Add code here\n",
        "      #\n",
        "      #\n",
        "      \n",
        "      # Create new folder for this model in training/models\n",
        "      paths['active_model'] = paths['models']+'/'+custom_model_name\n",
        "      os.makedirs(paths['active_model'])\n",
        "      \n",
        "      print('Model was successfully downloaded...')\n",
        "\n",
        "\n",
        "  else:\n",
        "    print(str(pre_trained_model_name)+' was already installed...')\n",
        "    \n",
        "    os.chdir(paths['home'])\n",
        "\n",
        "else:\n",
        "    print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9d8741",
      "metadata": {
        "id": "5d9d8741"
      },
      "source": [
        "## 5.7 Update the config file and pipeline for the new training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ae3f7e2a",
      "metadata": {
        "id": "ae3f7e2a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "256fe75d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256fe75d",
        "outputId": "ddaad63d-b87e-4dbe-f480-49a3a7a2eada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline copied to active model directory...\n",
            "Pipeline successfully configured...\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "  ## Copy or replace pipeline in active model directory\n",
        "  files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config'\n",
        "  paths['active_model'] = paths['models']+'/'+custom_model_name\n",
        "  files['pipeline_active'] = paths['active_model']+'/pipeline.config'\n",
        "  paths['downloaded_model'] = paths['pre_trained_models']+'/'+pre_trained_model_name\n",
        "\n",
        "  # If pipeline already exists in active directory, replace it\n",
        "  if os.path.exists(files['pipeline_active']) == True:\n",
        "      os.remove(files['pipeline_active'])\n",
        "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
        "      print('Pipeline replaced in active model directory...')\n",
        "\n",
        "  # If pipeline does not yet exist in active directory, copy it from downloaded model\n",
        "  else:\n",
        "      files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config' \n",
        "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
        "      print('Pipeline copied to active model directory...')\n",
        "\n",
        "  ## Configure pipeline\n",
        "\n",
        "  config = config_util.get_configs_from_pipeline_file(files['pipeline_active'])\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.io.gfile.GFile(files['pipeline_active'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "      text_format.Merge(proto_str, pipeline_config)  \n",
        "\n",
        "\n",
        "  pipeline_config.model.ssd.num_classes = len(labels) # Number of labels the model should be trained for\n",
        "  pipeline_config.train_config.batch_size = 4 # This should be the number of training jobs that run parallel\n",
        "\n",
        "  # Get checkpoint 0 from (original) downloaded model \n",
        "  files['checkpoint0'] = paths['downloaded_model']+'/checkpoint/ckpt-0'\n",
        "\n",
        "  pipeline_config.train_config.fine_tune_checkpoint = files['checkpoint0']\n",
        "\n",
        "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "\n",
        "  # Get labelmap\n",
        "  pipeline_config.train_input_reader.label_map_path= files['labelmap']\n",
        "\n",
        "  # Get TF-Record\n",
        "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [files['tf_train']]\n",
        "  pipeline_config.eval_input_reader[0].label_map_path = files['labelmap']\n",
        "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [files['tf_test']]\n",
        "\n",
        "  config_text = text_format.MessageToString(pipeline_config)\n",
        "\n",
        "  # Update active pipeline\n",
        "  with tf.io.gfile.GFile(files['pipeline_active'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "      f.write(config_text)   \n",
        "      \n",
        "  print('Pipeline successfully configured...')  \n",
        "\n",
        "  # Copy model_main_tf2.py to workspace -> training   'TensorFlow/models/research/' file to \n",
        "  source = paths['research']+'/object_detection/model_main_tf2.py'\n",
        "  destination = paths['training']\n",
        "  shutil.copy(source, destination)\n",
        "\n",
        "else:\n",
        "    print('No operating system was defined...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08eb2c1",
      "metadata": {
        "id": "b08eb2c1"
      },
      "source": [
        "# 6. Start new training job (only on colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "054d6094",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054d6094",
        "outputId": "e6bec8fd-8040-4f8e-9699-18c4d91c4e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "2022-07-06 15:38:04.940684: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0706 15:38:04.947924 139790858835840 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0706 15:38:04.954953 139790858835840 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0706 15:38:04.955120 139790858835840 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0706 15:38:05.308015 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
            "I0706 15:38:05.334287 139790858835840 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
            "I0706 15:38:05.344254 139790858835840 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0706 15:38:05.344429 139790858835840 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0706 15:38:05.344530 139790858835840 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0706 15:38:05.348076 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0706 15:38:05.405566 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0706 15:38:12.375504 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0706 15:38:15.167654 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0706 15:38:16.624686 139790858835840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.263623 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.267852 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.269881 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.270745 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.272669 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.273502 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.275419 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.276256 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.278257 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0706 15:38:44.279196 139790858835840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0706 15:38:44.909967 139785876719360 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.679s\n",
            "I0706 15:39:52.458024 139790858835840 model_lib_v2.py:707] Step 100 per-step time 0.679s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37628794,\n",
            " 'Loss/localization_loss': 0.35486263,\n",
            " 'Loss/regularization_loss': 0.15242289,\n",
            " 'Loss/total_loss': 0.8835735,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0706 15:39:52.458364 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.37628794,\n",
            " 'Loss/localization_loss': 0.35486263,\n",
            " 'Loss/regularization_loss': 0.15242289,\n",
            " 'Loss/total_loss': 0.8835735,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.316s\n",
            "I0706 15:40:24.037524 139790858835840 model_lib_v2.py:707] Step 200 per-step time 0.316s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25926545,\n",
            " 'Loss/localization_loss': 0.22933161,\n",
            " 'Loss/regularization_loss': 0.15270938,\n",
            " 'Loss/total_loss': 0.64130646,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0706 15:40:24.037838 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25926545,\n",
            " 'Loss/localization_loss': 0.22933161,\n",
            " 'Loss/regularization_loss': 0.15270938,\n",
            " 'Loss/total_loss': 0.64130646,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.321s\n",
            "I0706 15:40:56.168152 139790858835840 model_lib_v2.py:707] Step 300 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2057812,\n",
            " 'Loss/localization_loss': 0.17477377,\n",
            " 'Loss/regularization_loss': 0.1527831,\n",
            " 'Loss/total_loss': 0.53333807,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0706 15:40:56.168430 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2057812,\n",
            " 'Loss/localization_loss': 0.17477377,\n",
            " 'Loss/regularization_loss': 0.1527831,\n",
            " 'Loss/total_loss': 0.53333807,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.325s\n",
            "I0706 15:41:28.638889 139790858835840 model_lib_v2.py:707] Step 400 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31136042,\n",
            " 'Loss/localization_loss': 0.16780347,\n",
            " 'Loss/regularization_loss': 0.15300962,\n",
            " 'Loss/total_loss': 0.63217354,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0706 15:41:28.639184 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.31136042,\n",
            " 'Loss/localization_loss': 0.16780347,\n",
            " 'Loss/regularization_loss': 0.15300962,\n",
            " 'Loss/total_loss': 0.63217354,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.322s\n",
            "I0706 15:42:00.858647 139790858835840 model_lib_v2.py:707] Step 500 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19253922,\n",
            " 'Loss/localization_loss': 0.3198697,\n",
            " 'Loss/regularization_loss': 0.15320744,\n",
            " 'Loss/total_loss': 0.66561633,\n",
            " 'learning_rate': 0.053333}\n",
            "I0706 15:42:00.858972 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19253922,\n",
            " 'Loss/localization_loss': 0.3198697,\n",
            " 'Loss/regularization_loss': 0.15320744,\n",
            " 'Loss/total_loss': 0.66561633,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.322s\n",
            "I0706 15:42:33.078251 139790858835840 model_lib_v2.py:707] Step 600 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1914689,\n",
            " 'Loss/localization_loss': 0.16531731,\n",
            " 'Loss/regularization_loss': 0.15354702,\n",
            " 'Loss/total_loss': 0.5103332,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0706 15:42:33.078549 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1914689,\n",
            " 'Loss/localization_loss': 0.16531731,\n",
            " 'Loss/regularization_loss': 0.15354702,\n",
            " 'Loss/total_loss': 0.5103332,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.323s\n",
            "I0706 15:43:05.363390 139790858835840 model_lib_v2.py:707] Step 700 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2018737,\n",
            " 'Loss/localization_loss': 0.1981244,\n",
            " 'Loss/regularization_loss': 0.15397328,\n",
            " 'Loss/total_loss': 0.5539714,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0706 15:43:05.363681 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2018737,\n",
            " 'Loss/localization_loss': 0.1981244,\n",
            " 'Loss/regularization_loss': 0.15397328,\n",
            " 'Loss/total_loss': 0.5539714,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.321s\n",
            "I0706 15:43:37.508514 139790858835840 model_lib_v2.py:707] Step 800 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15515853,\n",
            " 'Loss/localization_loss': 0.1030123,\n",
            " 'Loss/regularization_loss': 0.15419894,\n",
            " 'Loss/total_loss': 0.4123698,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0706 15:43:37.508816 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15515853,\n",
            " 'Loss/localization_loss': 0.1030123,\n",
            " 'Loss/regularization_loss': 0.15419894,\n",
            " 'Loss/total_loss': 0.4123698,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.322s\n",
            "I0706 15:44:09.672348 139790858835840 model_lib_v2.py:707] Step 900 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29645622,\n",
            " 'Loss/localization_loss': 0.13943318,\n",
            " 'Loss/regularization_loss': 0.15444222,\n",
            " 'Loss/total_loss': 0.5903316,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0706 15:44:09.672744 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.29645622,\n",
            " 'Loss/localization_loss': 0.13943318,\n",
            " 'Loss/regularization_loss': 0.15444222,\n",
            " 'Loss/total_loss': 0.5903316,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.322s\n",
            "I0706 15:44:41.880603 139790858835840 model_lib_v2.py:707] Step 1000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2431744,\n",
            " 'Loss/localization_loss': 0.1808684,\n",
            " 'Loss/regularization_loss': 0.15474589,\n",
            " 'Loss/total_loss': 0.5787887,\n",
            " 'learning_rate': 0.08}\n",
            "I0706 15:44:41.880886 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2431744,\n",
            " 'Loss/localization_loss': 0.1808684,\n",
            " 'Loss/regularization_loss': 0.15474589,\n",
            " 'Loss/total_loss': 0.5787887,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.327s\n",
            "I0706 15:45:14.579685 139790858835840 model_lib_v2.py:707] Step 1100 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27345625,\n",
            " 'Loss/localization_loss': 0.20147434,\n",
            " 'Loss/regularization_loss': 0.15500486,\n",
            " 'Loss/total_loss': 0.62993544,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0706 15:45:14.579964 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.27345625,\n",
            " 'Loss/localization_loss': 0.20147434,\n",
            " 'Loss/regularization_loss': 0.15500486,\n",
            " 'Loss/total_loss': 0.62993544,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.323s\n",
            "I0706 15:45:46.876952 139790858835840 model_lib_v2.py:707] Step 1200 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.35276696,\n",
            " 'Loss/localization_loss': 0.21896046,\n",
            " 'Loss/regularization_loss': 0.15530479,\n",
            " 'Loss/total_loss': 0.7270322,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0706 15:45:46.877261 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.35276696,\n",
            " 'Loss/localization_loss': 0.21896046,\n",
            " 'Loss/regularization_loss': 0.15530479,\n",
            " 'Loss/total_loss': 0.7270322,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.321s\n",
            "I0706 15:46:18.986925 139790858835840 model_lib_v2.py:707] Step 1300 per-step time 0.321s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18392882,\n",
            " 'Loss/localization_loss': 0.12370915,\n",
            " 'Loss/regularization_loss': 0.15581267,\n",
            " 'Loss/total_loss': 0.4634506,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0706 15:46:18.987318 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18392882,\n",
            " 'Loss/localization_loss': 0.12370915,\n",
            " 'Loss/regularization_loss': 0.15581267,\n",
            " 'Loss/total_loss': 0.4634506,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.322s\n",
            "I0706 15:46:51.186886 139790858835840 model_lib_v2.py:707] Step 1400 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11059876,\n",
            " 'Loss/localization_loss': 0.104984336,\n",
            " 'Loss/regularization_loss': 0.1557977,\n",
            " 'Loss/total_loss': 0.3713808,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0706 15:46:51.187185 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11059876,\n",
            " 'Loss/localization_loss': 0.104984336,\n",
            " 'Loss/regularization_loss': 0.1557977,\n",
            " 'Loss/total_loss': 0.3713808,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.320s\n",
            "I0706 15:47:23.229418 139790858835840 model_lib_v2.py:707] Step 1500 per-step time 0.320s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16420825,\n",
            " 'Loss/localization_loss': 0.12451129,\n",
            " 'Loss/regularization_loss': 0.15571643,\n",
            " 'Loss/total_loss': 0.44443595,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0706 15:47:23.229717 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16420825,\n",
            " 'Loss/localization_loss': 0.12451129,\n",
            " 'Loss/regularization_loss': 0.15571643,\n",
            " 'Loss/total_loss': 0.44443595,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.324s\n",
            "I0706 15:47:55.641298 139790858835840 model_lib_v2.py:707] Step 1600 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13662405,\n",
            " 'Loss/localization_loss': 0.13083956,\n",
            " 'Loss/regularization_loss': 0.15558746,\n",
            " 'Loss/total_loss': 0.4230511,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0706 15:47:55.642063 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13662405,\n",
            " 'Loss/localization_loss': 0.13083956,\n",
            " 'Loss/regularization_loss': 0.15558746,\n",
            " 'Loss/total_loss': 0.4230511,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.325s\n",
            "I0706 15:48:28.105823 139790858835840 model_lib_v2.py:707] Step 1700 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13476077,\n",
            " 'Loss/localization_loss': 0.16574036,\n",
            " 'Loss/regularization_loss': 0.15529136,\n",
            " 'Loss/total_loss': 0.4557925,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0706 15:48:28.106124 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13476077,\n",
            " 'Loss/localization_loss': 0.16574036,\n",
            " 'Loss/regularization_loss': 0.15529136,\n",
            " 'Loss/total_loss': 0.4557925,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.324s\n",
            "I0706 15:49:00.527343 139790858835840 model_lib_v2.py:707] Step 1800 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12040466,\n",
            " 'Loss/localization_loss': 0.11046862,\n",
            " 'Loss/regularization_loss': 0.15481798,\n",
            " 'Loss/total_loss': 0.3856913,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0706 15:49:00.527625 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12040466,\n",
            " 'Loss/localization_loss': 0.11046862,\n",
            " 'Loss/regularization_loss': 0.15481798,\n",
            " 'Loss/total_loss': 0.3856913,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.324s\n",
            "I0706 15:49:32.944402 139790858835840 model_lib_v2.py:707] Step 1900 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25026798,\n",
            " 'Loss/localization_loss': 0.17739554,\n",
            " 'Loss/regularization_loss': 0.15446813,\n",
            " 'Loss/total_loss': 0.5821316,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0706 15:49:32.944687 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25026798,\n",
            " 'Loss/localization_loss': 0.17739554,\n",
            " 'Loss/regularization_loss': 0.15446813,\n",
            " 'Loss/total_loss': 0.5821316,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.322s\n",
            "I0706 15:50:05.102959 139790858835840 model_lib_v2.py:707] Step 2000 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12100507,\n",
            " 'Loss/localization_loss': 0.08066975,\n",
            " 'Loss/regularization_loss': 0.15406404,\n",
            " 'Loss/total_loss': 0.35573888,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0706 15:50:05.103286 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12100507,\n",
            " 'Loss/localization_loss': 0.08066975,\n",
            " 'Loss/regularization_loss': 0.15406404,\n",
            " 'Loss/total_loss': 0.35573888,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.328s\n",
            "I0706 15:50:37.894456 139790858835840 model_lib_v2.py:707] Step 2100 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1614488,\n",
            " 'Loss/localization_loss': 0.096370645,\n",
            " 'Loss/regularization_loss': 0.1538557,\n",
            " 'Loss/total_loss': 0.41167516,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0706 15:50:37.894760 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1614488,\n",
            " 'Loss/localization_loss': 0.096370645,\n",
            " 'Loss/regularization_loss': 0.1538557,\n",
            " 'Loss/total_loss': 0.41167516,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.324s\n",
            "I0706 15:51:10.282052 139790858835840 model_lib_v2.py:707] Step 2200 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22870548,\n",
            " 'Loss/localization_loss': 0.17148793,\n",
            " 'Loss/regularization_loss': 0.15345404,\n",
            " 'Loss/total_loss': 0.5536474,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0706 15:51:10.282336 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22870548,\n",
            " 'Loss/localization_loss': 0.17148793,\n",
            " 'Loss/regularization_loss': 0.15345404,\n",
            " 'Loss/total_loss': 0.5536474,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.324s\n",
            "I0706 15:51:42.675641 139790858835840 model_lib_v2.py:707] Step 2300 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11720817,\n",
            " 'Loss/localization_loss': 0.07560007,\n",
            " 'Loss/regularization_loss': 0.15310216,\n",
            " 'Loss/total_loss': 0.3459104,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0706 15:51:42.675935 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11720817,\n",
            " 'Loss/localization_loss': 0.07560007,\n",
            " 'Loss/regularization_loss': 0.15310216,\n",
            " 'Loss/total_loss': 0.3459104,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.326s\n",
            "I0706 15:52:15.323818 139790858835840 model_lib_v2.py:707] Step 2400 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13203259,\n",
            " 'Loss/localization_loss': 0.106185995,\n",
            " 'Loss/regularization_loss': 0.15272158,\n",
            " 'Loss/total_loss': 0.39094016,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0706 15:52:15.324161 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13203259,\n",
            " 'Loss/localization_loss': 0.106185995,\n",
            " 'Loss/regularization_loss': 0.15272158,\n",
            " 'Loss/total_loss': 0.39094016,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.327s\n",
            "I0706 15:52:48.005883 139790858835840 model_lib_v2.py:707] Step 2500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09111541,\n",
            " 'Loss/localization_loss': 0.07564979,\n",
            " 'Loss/regularization_loss': 0.1523098,\n",
            " 'Loss/total_loss': 0.319075,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0706 15:52:48.006179 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.09111541,\n",
            " 'Loss/localization_loss': 0.07564979,\n",
            " 'Loss/regularization_loss': 0.1523098,\n",
            " 'Loss/total_loss': 0.319075,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.325s\n",
            "I0706 15:53:20.489306 139790858835840 model_lib_v2.py:707] Step 2600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07473838,\n",
            " 'Loss/localization_loss': 0.08372484,\n",
            " 'Loss/regularization_loss': 0.15185685,\n",
            " 'Loss/total_loss': 0.31032008,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0706 15:53:20.489590 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07473838,\n",
            " 'Loss/localization_loss': 0.08372484,\n",
            " 'Loss/regularization_loss': 0.15185685,\n",
            " 'Loss/total_loss': 0.31032008,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.324s\n",
            "I0706 15:53:52.935032 139790858835840 model_lib_v2.py:707] Step 2700 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10535817,\n",
            " 'Loss/localization_loss': 0.07970876,\n",
            " 'Loss/regularization_loss': 0.15142488,\n",
            " 'Loss/total_loss': 0.33649182,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0706 15:53:52.935397 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10535817,\n",
            " 'Loss/localization_loss': 0.07970876,\n",
            " 'Loss/regularization_loss': 0.15142488,\n",
            " 'Loss/total_loss': 0.33649182,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.324s\n",
            "I0706 15:54:25.339426 139790858835840 model_lib_v2.py:707] Step 2800 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1034911,\n",
            " 'Loss/localization_loss': 0.07053897,\n",
            " 'Loss/regularization_loss': 0.151038,\n",
            " 'Loss/total_loss': 0.32506806,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0706 15:54:25.339727 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1034911,\n",
            " 'Loss/localization_loss': 0.07053897,\n",
            " 'Loss/regularization_loss': 0.151038,\n",
            " 'Loss/total_loss': 0.32506806,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.325s\n",
            "I0706 15:54:57.826163 139790858835840 model_lib_v2.py:707] Step 2900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11099681,\n",
            " 'Loss/localization_loss': 0.08097042,\n",
            " 'Loss/regularization_loss': 0.15065373,\n",
            " 'Loss/total_loss': 0.34262097,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0706 15:54:57.826429 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11099681,\n",
            " 'Loss/localization_loss': 0.08097042,\n",
            " 'Loss/regularization_loss': 0.15065373,\n",
            " 'Loss/total_loss': 0.34262097,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.326s\n",
            "I0706 15:55:30.442850 139790858835840 model_lib_v2.py:707] Step 3000 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15318932,\n",
            " 'Loss/localization_loss': 0.072990954,\n",
            " 'Loss/regularization_loss': 0.15062894,\n",
            " 'Loss/total_loss': 0.3768092,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0706 15:55:30.443142 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15318932,\n",
            " 'Loss/localization_loss': 0.072990954,\n",
            " 'Loss/regularization_loss': 0.15062894,\n",
            " 'Loss/total_loss': 0.3768092,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.329s\n",
            "I0706 15:56:03.372378 139790858835840 model_lib_v2.py:707] Step 3100 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16883186,\n",
            " 'Loss/localization_loss': 0.104914255,\n",
            " 'Loss/regularization_loss': 0.15074012,\n",
            " 'Loss/total_loss': 0.42448622,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0706 15:56:03.372684 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16883186,\n",
            " 'Loss/localization_loss': 0.104914255,\n",
            " 'Loss/regularization_loss': 0.15074012,\n",
            " 'Loss/total_loss': 0.42448622,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.325s\n",
            "I0706 15:56:35.833942 139790858835840 model_lib_v2.py:707] Step 3200 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.105507396,\n",
            " 'Loss/localization_loss': 0.04477338,\n",
            " 'Loss/regularization_loss': 0.1503661,\n",
            " 'Loss/total_loss': 0.30064687,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0706 15:56:35.834241 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.105507396,\n",
            " 'Loss/localization_loss': 0.04477338,\n",
            " 'Loss/regularization_loss': 0.1503661,\n",
            " 'Loss/total_loss': 0.30064687,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.322s\n",
            "I0706 15:57:08.052239 139790858835840 model_lib_v2.py:707] Step 3300 per-step time 0.322s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15219566,\n",
            " 'Loss/localization_loss': 0.07475188,\n",
            " 'Loss/regularization_loss': 0.14979321,\n",
            " 'Loss/total_loss': 0.37674075,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0706 15:57:08.052534 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15219566,\n",
            " 'Loss/localization_loss': 0.07475188,\n",
            " 'Loss/regularization_loss': 0.14979321,\n",
            " 'Loss/total_loss': 0.37674075,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.325s\n",
            "I0706 15:57:40.531224 139790858835840 model_lib_v2.py:707] Step 3400 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12837201,\n",
            " 'Loss/localization_loss': 0.0818852,\n",
            " 'Loss/regularization_loss': 0.1493153,\n",
            " 'Loss/total_loss': 0.35957253,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0706 15:57:40.531525 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12837201,\n",
            " 'Loss/localization_loss': 0.0818852,\n",
            " 'Loss/regularization_loss': 0.1493153,\n",
            " 'Loss/total_loss': 0.35957253,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.327s\n",
            "I0706 15:58:13.280299 139790858835840 model_lib_v2.py:707] Step 3500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13576692,\n",
            " 'Loss/localization_loss': 0.050359532,\n",
            " 'Loss/regularization_loss': 0.14878814,\n",
            " 'Loss/total_loss': 0.3349146,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0706 15:58:13.280634 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13576692,\n",
            " 'Loss/localization_loss': 0.050359532,\n",
            " 'Loss/regularization_loss': 0.14878814,\n",
            " 'Loss/total_loss': 0.3349146,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.325s\n",
            "I0706 15:58:45.816173 139790858835840 model_lib_v2.py:707] Step 3600 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11164153,\n",
            " 'Loss/localization_loss': 0.06815214,\n",
            " 'Loss/regularization_loss': 0.14831775,\n",
            " 'Loss/total_loss': 0.3281114,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0706 15:58:45.816457 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11164153,\n",
            " 'Loss/localization_loss': 0.06815214,\n",
            " 'Loss/regularization_loss': 0.14831775,\n",
            " 'Loss/total_loss': 0.3281114,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.331s\n",
            "I0706 15:59:18.905512 139790858835840 model_lib_v2.py:707] Step 3700 per-step time 0.331s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07374557,\n",
            " 'Loss/localization_loss': 0.032431435,\n",
            " 'Loss/regularization_loss': 0.14777628,\n",
            " 'Loss/total_loss': 0.25395328,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0706 15:59:18.905793 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07374557,\n",
            " 'Loss/localization_loss': 0.032431435,\n",
            " 'Loss/regularization_loss': 0.14777628,\n",
            " 'Loss/total_loss': 0.25395328,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.326s\n",
            "I0706 15:59:51.475231 139790858835840 model_lib_v2.py:707] Step 3800 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13034979,\n",
            " 'Loss/localization_loss': 0.10355158,\n",
            " 'Loss/regularization_loss': 0.14730911,\n",
            " 'Loss/total_loss': 0.38121048,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0706 15:59:51.475523 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13034979,\n",
            " 'Loss/localization_loss': 0.10355158,\n",
            " 'Loss/regularization_loss': 0.14730911,\n",
            " 'Loss/total_loss': 0.38121048,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.324s\n",
            "I0706 16:00:23.920223 139790858835840 model_lib_v2.py:707] Step 3900 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07256369,\n",
            " 'Loss/localization_loss': 0.05640719,\n",
            " 'Loss/regularization_loss': 0.14675091,\n",
            " 'Loss/total_loss': 0.2757218,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0706 16:00:23.920529 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07256369,\n",
            " 'Loss/localization_loss': 0.05640719,\n",
            " 'Loss/regularization_loss': 0.14675091,\n",
            " 'Loss/total_loss': 0.2757218,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.325s\n",
            "I0706 16:00:56.465603 139790858835840 model_lib_v2.py:707] Step 4000 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10843705,\n",
            " 'Loss/localization_loss': 0.042762082,\n",
            " 'Loss/regularization_loss': 0.14644589,\n",
            " 'Loss/total_loss': 0.29764503,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0706 16:00:56.465879 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10843705,\n",
            " 'Loss/localization_loss': 0.042762082,\n",
            " 'Loss/regularization_loss': 0.14644589,\n",
            " 'Loss/total_loss': 0.29764503,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.330s\n",
            "I0706 16:01:29.433992 139790858835840 model_lib_v2.py:707] Step 4100 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088854805,\n",
            " 'Loss/localization_loss': 0.063529916,\n",
            " 'Loss/regularization_loss': 0.14628862,\n",
            " 'Loss/total_loss': 0.29867333,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0706 16:01:29.434280 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.088854805,\n",
            " 'Loss/localization_loss': 0.063529916,\n",
            " 'Loss/regularization_loss': 0.14628862,\n",
            " 'Loss/total_loss': 0.29867333,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.325s\n",
            "I0706 16:02:01.894224 139790858835840 model_lib_v2.py:707] Step 4200 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09857124,\n",
            " 'Loss/localization_loss': 0.082022406,\n",
            " 'Loss/regularization_loss': 0.14580365,\n",
            " 'Loss/total_loss': 0.3263973,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0706 16:02:01.894536 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.09857124,\n",
            " 'Loss/localization_loss': 0.082022406,\n",
            " 'Loss/regularization_loss': 0.14580365,\n",
            " 'Loss/total_loss': 0.3263973,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.323s\n",
            "I0706 16:02:34.239701 139790858835840 model_lib_v2.py:707] Step 4300 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10427781,\n",
            " 'Loss/localization_loss': 0.05185294,\n",
            " 'Loss/regularization_loss': 0.14524077,\n",
            " 'Loss/total_loss': 0.3013715,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0706 16:02:34.239989 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10427781,\n",
            " 'Loss/localization_loss': 0.05185294,\n",
            " 'Loss/regularization_loss': 0.14524077,\n",
            " 'Loss/total_loss': 0.3013715,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.325s\n",
            "I0706 16:03:06.704517 139790858835840 model_lib_v2.py:707] Step 4400 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06799283,\n",
            " 'Loss/localization_loss': 0.026759272,\n",
            " 'Loss/regularization_loss': 0.14467002,\n",
            " 'Loss/total_loss': 0.23942213,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0706 16:03:06.704802 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06799283,\n",
            " 'Loss/localization_loss': 0.026759272,\n",
            " 'Loss/regularization_loss': 0.14467002,\n",
            " 'Loss/total_loss': 0.23942213,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.324s\n",
            "I0706 16:03:39.058027 139790858835840 model_lib_v2.py:707] Step 4500 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06830206,\n",
            " 'Loss/localization_loss': 0.041099023,\n",
            " 'Loss/regularization_loss': 0.14407659,\n",
            " 'Loss/total_loss': 0.25347766,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0706 16:03:39.058322 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06830206,\n",
            " 'Loss/localization_loss': 0.041099023,\n",
            " 'Loss/regularization_loss': 0.14407659,\n",
            " 'Loss/total_loss': 0.25347766,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.323s\n",
            "I0706 16:04:11.408229 139790858835840 model_lib_v2.py:707] Step 4600 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.113870636,\n",
            " 'Loss/localization_loss': 0.11309214,\n",
            " 'Loss/regularization_loss': 0.14362587,\n",
            " 'Loss/total_loss': 0.37058866,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0706 16:04:11.408546 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.113870636,\n",
            " 'Loss/localization_loss': 0.11309214,\n",
            " 'Loss/regularization_loss': 0.14362587,\n",
            " 'Loss/total_loss': 0.37058866,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.326s\n",
            "I0706 16:04:44.008024 139790858835840 model_lib_v2.py:707] Step 4700 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07410897,\n",
            " 'Loss/localization_loss': 0.049197845,\n",
            " 'Loss/regularization_loss': 0.14313866,\n",
            " 'Loss/total_loss': 0.2664455,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0706 16:04:44.008337 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07410897,\n",
            " 'Loss/localization_loss': 0.049197845,\n",
            " 'Loss/regularization_loss': 0.14313866,\n",
            " 'Loss/total_loss': 0.2664455,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.326s\n",
            "I0706 16:05:16.631603 139790858835840 model_lib_v2.py:707] Step 4800 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.066585176,\n",
            " 'Loss/localization_loss': 0.025183039,\n",
            " 'Loss/regularization_loss': 0.142573,\n",
            " 'Loss/total_loss': 0.2343412,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0706 16:05:16.631875 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.066585176,\n",
            " 'Loss/localization_loss': 0.025183039,\n",
            " 'Loss/regularization_loss': 0.142573,\n",
            " 'Loss/total_loss': 0.2343412,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.325s\n",
            "I0706 16:05:49.143869 139790858835840 model_lib_v2.py:707] Step 4900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.066097885,\n",
            " 'Loss/localization_loss': 0.043735,\n",
            " 'Loss/regularization_loss': 0.14203992,\n",
            " 'Loss/total_loss': 0.2518728,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0706 16:05:49.144176 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.066097885,\n",
            " 'Loss/localization_loss': 0.043735,\n",
            " 'Loss/regularization_loss': 0.14203992,\n",
            " 'Loss/total_loss': 0.2518728,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.327s\n",
            "I0706 16:06:21.810862 139790858835840 model_lib_v2.py:707] Step 5000 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09550667,\n",
            " 'Loss/localization_loss': 0.023977531,\n",
            " 'Loss/regularization_loss': 0.14242467,\n",
            " 'Loss/total_loss': 0.2619089,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0706 16:06:21.811177 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.09550667,\n",
            " 'Loss/localization_loss': 0.023977531,\n",
            " 'Loss/regularization_loss': 0.14242467,\n",
            " 'Loss/total_loss': 0.2619089,\n",
            " 'learning_rate': 0.078691795}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.329s\n",
            "I0706 16:06:54.747114 139790858835840 model_lib_v2.py:707] Step 5100 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.092900984,\n",
            " 'Loss/localization_loss': 0.06799995,\n",
            " 'Loss/regularization_loss': 0.14244275,\n",
            " 'Loss/total_loss': 0.30334368,\n",
            " 'learning_rate': 0.07862595}\n",
            "I0706 16:06:54.747407 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.092900984,\n",
            " 'Loss/localization_loss': 0.06799995,\n",
            " 'Loss/regularization_loss': 0.14244275,\n",
            " 'Loss/total_loss': 0.30334368,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.325s\n",
            "I0706 16:07:27.244487 139790858835840 model_lib_v2.py:707] Step 5200 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06464549,\n",
            " 'Loss/localization_loss': 0.049911555,\n",
            " 'Loss/regularization_loss': 0.14193843,\n",
            " 'Loss/total_loss': 0.25649548,\n",
            " 'learning_rate': 0.07855851}\n",
            "I0706 16:07:27.244779 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06464549,\n",
            " 'Loss/localization_loss': 0.049911555,\n",
            " 'Loss/regularization_loss': 0.14193843,\n",
            " 'Loss/total_loss': 0.25649548,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.326s\n",
            "I0706 16:07:59.844342 139790858835840 model_lib_v2.py:707] Step 5300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14142965,\n",
            " 'Loss/localization_loss': 0.055547282,\n",
            " 'Loss/regularization_loss': 0.14157937,\n",
            " 'Loss/total_loss': 0.3385563,\n",
            " 'learning_rate': 0.07848949}\n",
            "I0706 16:07:59.844662 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14142965,\n",
            " 'Loss/localization_loss': 0.055547282,\n",
            " 'Loss/regularization_loss': 0.14157937,\n",
            " 'Loss/total_loss': 0.3385563,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.324s\n",
            "I0706 16:08:32.266560 139790858835840 model_lib_v2.py:707] Step 5400 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08288341,\n",
            " 'Loss/localization_loss': 0.035827808,\n",
            " 'Loss/regularization_loss': 0.14110382,\n",
            " 'Loss/total_loss': 0.25981504,\n",
            " 'learning_rate': 0.078418896}\n",
            "I0706 16:08:32.266852 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.08288341,\n",
            " 'Loss/localization_loss': 0.035827808,\n",
            " 'Loss/regularization_loss': 0.14110382,\n",
            " 'Loss/total_loss': 0.25981504,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.324s\n",
            "I0706 16:09:04.662339 139790858835840 model_lib_v2.py:707] Step 5500 per-step time 0.324s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06312831,\n",
            " 'Loss/localization_loss': 0.036896687,\n",
            " 'Loss/regularization_loss': 0.14061366,\n",
            " 'Loss/total_loss': 0.24063866,\n",
            " 'learning_rate': 0.078346714}\n",
            "I0706 16:09:04.662670 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06312831,\n",
            " 'Loss/localization_loss': 0.036896687,\n",
            " 'Loss/regularization_loss': 0.14061366,\n",
            " 'Loss/total_loss': 0.24063866,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.323s\n",
            "I0706 16:09:36.972308 139790858835840 model_lib_v2.py:707] Step 5600 per-step time 0.323s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07147903,\n",
            " 'Loss/localization_loss': 0.0661941,\n",
            " 'Loss/regularization_loss': 0.14003642,\n",
            " 'Loss/total_loss': 0.27770954,\n",
            " 'learning_rate': 0.07827295}\n",
            "I0706 16:09:36.972594 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07147903,\n",
            " 'Loss/localization_loss': 0.0661941,\n",
            " 'Loss/regularization_loss': 0.14003642,\n",
            " 'Loss/total_loss': 0.27770954,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.325s\n",
            "I0706 16:10:09.486456 139790858835840 model_lib_v2.py:707] Step 5700 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13949075,\n",
            " 'Loss/localization_loss': 0.065216936,\n",
            " 'Loss/regularization_loss': 0.13948174,\n",
            " 'Loss/total_loss': 0.3441894,\n",
            " 'learning_rate': 0.07819763}\n",
            "I0706 16:10:09.486805 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13949075,\n",
            " 'Loss/localization_loss': 0.065216936,\n",
            " 'Loss/regularization_loss': 0.13948174,\n",
            " 'Loss/total_loss': 0.3441894,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.329s\n",
            "I0706 16:10:42.366490 139790858835840 model_lib_v2.py:707] Step 5800 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07769974,\n",
            " 'Loss/localization_loss': 0.03505432,\n",
            " 'Loss/regularization_loss': 0.13904825,\n",
            " 'Loss/total_loss': 0.25180233,\n",
            " 'learning_rate': 0.07812072}\n",
            "I0706 16:10:42.366786 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07769974,\n",
            " 'Loss/localization_loss': 0.03505432,\n",
            " 'Loss/regularization_loss': 0.13904825,\n",
            " 'Loss/total_loss': 0.25180233,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.325s\n",
            "I0706 16:11:14.831928 139790858835840 model_lib_v2.py:707] Step 5900 per-step time 0.325s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.072416715,\n",
            " 'Loss/localization_loss': 0.038856406,\n",
            " 'Loss/regularization_loss': 0.13858333,\n",
            " 'Loss/total_loss': 0.24985646,\n",
            " 'learning_rate': 0.078042254}\n",
            "I0706 16:11:14.832237 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.072416715,\n",
            " 'Loss/localization_loss': 0.038856406,\n",
            " 'Loss/regularization_loss': 0.13858333,\n",
            " 'Loss/total_loss': 0.24985646,\n",
            " 'learning_rate': 0.078042254}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.329s\n",
            "I0706 16:11:47.742224 139790858835840 model_lib_v2.py:707] Step 6000 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12981366,\n",
            " 'Loss/localization_loss': 0.0821887,\n",
            " 'Loss/regularization_loss': 0.13809322,\n",
            " 'Loss/total_loss': 0.35009557,\n",
            " 'learning_rate': 0.07796223}\n",
            "I0706 16:11:47.742528 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12981366,\n",
            " 'Loss/localization_loss': 0.0821887,\n",
            " 'Loss/regularization_loss': 0.13809322,\n",
            " 'Loss/total_loss': 0.35009557,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.333s\n",
            "I0706 16:12:21.037483 139790858835840 model_lib_v2.py:707] Step 6100 per-step time 0.333s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07933235,\n",
            " 'Loss/localization_loss': 0.031117763,\n",
            " 'Loss/regularization_loss': 0.13759454,\n",
            " 'Loss/total_loss': 0.24804465,\n",
            " 'learning_rate': 0.077880636}\n",
            "I0706 16:12:21.037804 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07933235,\n",
            " 'Loss/localization_loss': 0.031117763,\n",
            " 'Loss/regularization_loss': 0.13759454,\n",
            " 'Loss/total_loss': 0.24804465,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.329s\n",
            "I0706 16:12:53.947697 139790858835840 model_lib_v2.py:707] Step 6200 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10272853,\n",
            " 'Loss/localization_loss': 0.05067019,\n",
            " 'Loss/regularization_loss': 0.13728161,\n",
            " 'Loss/total_loss': 0.29068035,\n",
            " 'learning_rate': 0.07779749}\n",
            "I0706 16:12:53.947986 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10272853,\n",
            " 'Loss/localization_loss': 0.05067019,\n",
            " 'Loss/regularization_loss': 0.13728161,\n",
            " 'Loss/total_loss': 0.29068035,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.329s\n",
            "I0706 16:13:26.855661 139790858835840 model_lib_v2.py:707] Step 6300 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10426832,\n",
            " 'Loss/localization_loss': 0.040300768,\n",
            " 'Loss/regularization_loss': 0.13678826,\n",
            " 'Loss/total_loss': 0.28135735,\n",
            " 'learning_rate': 0.07771279}\n",
            "I0706 16:13:26.855941 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10426832,\n",
            " 'Loss/localization_loss': 0.040300768,\n",
            " 'Loss/regularization_loss': 0.13678826,\n",
            " 'Loss/total_loss': 0.28135735,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.328s\n",
            "I0706 16:13:59.646392 139790858835840 model_lib_v2.py:707] Step 6400 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1347334,\n",
            " 'Loss/localization_loss': 0.06407214,\n",
            " 'Loss/regularization_loss': 0.13624637,\n",
            " 'Loss/total_loss': 0.3350519,\n",
            " 'learning_rate': 0.077626534}\n",
            "I0706 16:13:59.646714 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1347334,\n",
            " 'Loss/localization_loss': 0.06407214,\n",
            " 'Loss/regularization_loss': 0.13624637,\n",
            " 'Loss/total_loss': 0.3350519,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.327s\n",
            "I0706 16:14:32.381218 139790858835840 model_lib_v2.py:707] Step 6500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17069739,\n",
            " 'Loss/localization_loss': 0.076846935,\n",
            " 'Loss/regularization_loss': 0.1357288,\n",
            " 'Loss/total_loss': 0.38327312,\n",
            " 'learning_rate': 0.077538736}\n",
            "I0706 16:14:32.381508 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17069739,\n",
            " 'Loss/localization_loss': 0.076846935,\n",
            " 'Loss/regularization_loss': 0.1357288,\n",
            " 'Loss/total_loss': 0.38327312,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.329s\n",
            "I0706 16:15:05.257432 139790858835840 model_lib_v2.py:707] Step 6600 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15462452,\n",
            " 'Loss/localization_loss': 0.07925413,\n",
            " 'Loss/regularization_loss': 0.13519801,\n",
            " 'Loss/total_loss': 0.36907667,\n",
            " 'learning_rate': 0.077449396}\n",
            "I0706 16:15:05.257712 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15462452,\n",
            " 'Loss/localization_loss': 0.07925413,\n",
            " 'Loss/regularization_loss': 0.13519801,\n",
            " 'Loss/total_loss': 0.36907667,\n",
            " 'learning_rate': 0.077449396}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.329s\n",
            "I0706 16:15:38.190407 139790858835840 model_lib_v2.py:707] Step 6700 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.120947614,\n",
            " 'Loss/localization_loss': 0.048399564,\n",
            " 'Loss/regularization_loss': 0.13467343,\n",
            " 'Loss/total_loss': 0.3040206,\n",
            " 'learning_rate': 0.077358514}\n",
            "I0706 16:15:38.190701 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.120947614,\n",
            " 'Loss/localization_loss': 0.048399564,\n",
            " 'Loss/regularization_loss': 0.13467343,\n",
            " 'Loss/total_loss': 0.3040206,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.330s\n",
            "I0706 16:16:11.227693 139790858835840 model_lib_v2.py:707] Step 6800 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06339348,\n",
            " 'Loss/localization_loss': 0.024294239,\n",
            " 'Loss/regularization_loss': 0.13415603,\n",
            " 'Loss/total_loss': 0.22184375,\n",
            " 'learning_rate': 0.0772661}\n",
            "I0706 16:16:11.227999 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06339348,\n",
            " 'Loss/localization_loss': 0.024294239,\n",
            " 'Loss/regularization_loss': 0.13415603,\n",
            " 'Loss/total_loss': 0.22184375,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.330s\n",
            "I0706 16:16:44.215246 139790858835840 model_lib_v2.py:707] Step 6900 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08046912,\n",
            " 'Loss/localization_loss': 0.05273756,\n",
            " 'Loss/regularization_loss': 0.13359706,\n",
            " 'Loss/total_loss': 0.26680374,\n",
            " 'learning_rate': 0.077172145}\n",
            "I0706 16:16:44.215556 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.08046912,\n",
            " 'Loss/localization_loss': 0.05273756,\n",
            " 'Loss/regularization_loss': 0.13359706,\n",
            " 'Loss/total_loss': 0.26680374,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.330s\n",
            "I0706 16:17:17.191374 139790858835840 model_lib_v2.py:707] Step 7000 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.082139015,\n",
            " 'Loss/localization_loss': 0.03097282,\n",
            " 'Loss/regularization_loss': 0.13307825,\n",
            " 'Loss/total_loss': 0.24619009,\n",
            " 'learning_rate': 0.07707667}\n",
            "I0706 16:17:17.191677 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.082139015,\n",
            " 'Loss/localization_loss': 0.03097282,\n",
            " 'Loss/regularization_loss': 0.13307825,\n",
            " 'Loss/total_loss': 0.24619009,\n",
            " 'learning_rate': 0.07707667}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.334s\n",
            "I0706 16:17:50.571172 139790858835840 model_lib_v2.py:707] Step 7100 per-step time 0.334s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05579681,\n",
            " 'Loss/localization_loss': 0.019854302,\n",
            " 'Loss/regularization_loss': 0.13270593,\n",
            " 'Loss/total_loss': 0.20835704,\n",
            " 'learning_rate': 0.07697967}\n",
            "I0706 16:17:50.571484 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.05579681,\n",
            " 'Loss/localization_loss': 0.019854302,\n",
            " 'Loss/regularization_loss': 0.13270593,\n",
            " 'Loss/total_loss': 0.20835704,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.329s\n",
            "I0706 16:18:23.419735 139790858835840 model_lib_v2.py:707] Step 7200 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09746917,\n",
            " 'Loss/localization_loss': 0.076324016,\n",
            " 'Loss/regularization_loss': 0.13225156,\n",
            " 'Loss/total_loss': 0.30604476,\n",
            " 'learning_rate': 0.07688115}\n",
            "I0706 16:18:23.420035 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.09746917,\n",
            " 'Loss/localization_loss': 0.076324016,\n",
            " 'Loss/regularization_loss': 0.13225156,\n",
            " 'Loss/total_loss': 0.30604476,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.326s\n",
            "I0706 16:18:56.061113 139790858835840 model_lib_v2.py:707] Step 7300 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.092261486,\n",
            " 'Loss/localization_loss': 0.018387191,\n",
            " 'Loss/regularization_loss': 0.13179508,\n",
            " 'Loss/total_loss': 0.24244376,\n",
            " 'learning_rate': 0.07678111}\n",
            "I0706 16:18:56.061414 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.092261486,\n",
            " 'Loss/localization_loss': 0.018387191,\n",
            " 'Loss/regularization_loss': 0.13179508,\n",
            " 'Loss/total_loss': 0.24244376,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.327s\n",
            "I0706 16:19:28.806789 139790858835840 model_lib_v2.py:707] Step 7400 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06211291,\n",
            " 'Loss/localization_loss': 0.025871895,\n",
            " 'Loss/regularization_loss': 0.13131902,\n",
            " 'Loss/total_loss': 0.21930382,\n",
            " 'learning_rate': 0.076679565}\n",
            "I0706 16:19:28.807106 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06211291,\n",
            " 'Loss/localization_loss': 0.025871895,\n",
            " 'Loss/regularization_loss': 0.13131902,\n",
            " 'Loss/total_loss': 0.21930382,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.327s\n",
            "I0706 16:20:01.523604 139790858835840 model_lib_v2.py:707] Step 7500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0727249,\n",
            " 'Loss/localization_loss': 0.042092472,\n",
            " 'Loss/regularization_loss': 0.13087764,\n",
            " 'Loss/total_loss': 0.24569502,\n",
            " 'learning_rate': 0.0765765}\n",
            "I0706 16:20:01.523957 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.0727249,\n",
            " 'Loss/localization_loss': 0.042092472,\n",
            " 'Loss/regularization_loss': 0.13087764,\n",
            " 'Loss/total_loss': 0.24569502,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.328s\n",
            "I0706 16:20:34.329547 139790858835840 model_lib_v2.py:707] Step 7600 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07464115,\n",
            " 'Loss/localization_loss': 0.03336005,\n",
            " 'Loss/regularization_loss': 0.13059483,\n",
            " 'Loss/total_loss': 0.23859604,\n",
            " 'learning_rate': 0.07647194}\n",
            "I0706 16:20:34.329862 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07464115,\n",
            " 'Loss/localization_loss': 0.03336005,\n",
            " 'Loss/regularization_loss': 0.13059483,\n",
            " 'Loss/total_loss': 0.23859604,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.327s\n",
            "I0706 16:21:06.984915 139790858835840 model_lib_v2.py:707] Step 7700 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17062384,\n",
            " 'Loss/localization_loss': 0.13602398,\n",
            " 'Loss/regularization_loss': 0.13055351,\n",
            " 'Loss/total_loss': 0.43720135,\n",
            " 'learning_rate': 0.07636588}\n",
            "I0706 16:21:06.985201 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17062384,\n",
            " 'Loss/localization_loss': 0.13602398,\n",
            " 'Loss/regularization_loss': 0.13055351,\n",
            " 'Loss/total_loss': 0.43720135,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.328s\n",
            "I0706 16:21:39.791701 139790858835840 model_lib_v2.py:707] Step 7800 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07214035,\n",
            " 'Loss/localization_loss': 0.028090985,\n",
            " 'Loss/regularization_loss': 0.13003688,\n",
            " 'Loss/total_loss': 0.23026821,\n",
            " 'learning_rate': 0.07625833}\n",
            "I0706 16:21:39.792241 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07214035,\n",
            " 'Loss/localization_loss': 0.028090985,\n",
            " 'Loss/regularization_loss': 0.13003688,\n",
            " 'Loss/total_loss': 0.23026821,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.329s\n",
            "I0706 16:22:12.736873 139790858835840 model_lib_v2.py:707] Step 7900 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16289282,\n",
            " 'Loss/localization_loss': 0.10244279,\n",
            " 'Loss/regularization_loss': 0.12969865,\n",
            " 'Loss/total_loss': 0.39503425,\n",
            " 'learning_rate': 0.07614928}\n",
            "I0706 16:22:12.737692 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16289282,\n",
            " 'Loss/localization_loss': 0.10244279,\n",
            " 'Loss/regularization_loss': 0.12969865,\n",
            " 'Loss/total_loss': 0.39503425,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.328s\n",
            "I0706 16:22:45.508492 139790858835840 model_lib_v2.py:707] Step 8000 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11661917,\n",
            " 'Loss/localization_loss': 0.068215616,\n",
            " 'Loss/regularization_loss': 0.12915596,\n",
            " 'Loss/total_loss': 0.31399074,\n",
            " 'learning_rate': 0.07603875}\n",
            "I0706 16:22:45.508774 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11661917,\n",
            " 'Loss/localization_loss': 0.068215616,\n",
            " 'Loss/regularization_loss': 0.12915596,\n",
            " 'Loss/total_loss': 0.31399074,\n",
            " 'learning_rate': 0.07603875}\n",
            "INFO:tensorflow:Step 8100 per-step time 0.335s\n",
            "I0706 16:23:18.996151 139790858835840 model_lib_v2.py:707] Step 8100 per-step time 0.335s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05707236,\n",
            " 'Loss/localization_loss': 0.028216599,\n",
            " 'Loss/regularization_loss': 0.12861687,\n",
            " 'Loss/total_loss': 0.21390583,\n",
            " 'learning_rate': 0.07592674}\n",
            "I0706 16:23:18.996429 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.05707236,\n",
            " 'Loss/localization_loss': 0.028216599,\n",
            " 'Loss/regularization_loss': 0.12861687,\n",
            " 'Loss/total_loss': 0.21390583,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.328s\n",
            "I0706 16:23:51.829373 139790858835840 model_lib_v2.py:707] Step 8200 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06332585,\n",
            " 'Loss/localization_loss': 0.027946262,\n",
            " 'Loss/regularization_loss': 0.12813294,\n",
            " 'Loss/total_loss': 0.21940506,\n",
            " 'learning_rate': 0.075813256}\n",
            "I0706 16:23:51.829684 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06332585,\n",
            " 'Loss/localization_loss': 0.027946262,\n",
            " 'Loss/regularization_loss': 0.12813294,\n",
            " 'Loss/total_loss': 0.21940506,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.327s\n",
            "I0706 16:24:24.531741 139790858835840 model_lib_v2.py:707] Step 8300 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10086234,\n",
            " 'Loss/localization_loss': 0.032710228,\n",
            " 'Loss/regularization_loss': 0.12760167,\n",
            " 'Loss/total_loss': 0.26117423,\n",
            " 'learning_rate': 0.07569829}\n",
            "I0706 16:24:24.532041 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10086234,\n",
            " 'Loss/localization_loss': 0.032710228,\n",
            " 'Loss/regularization_loss': 0.12760167,\n",
            " 'Loss/total_loss': 0.26117423,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.328s\n",
            "I0706 16:24:57.357535 139790858835840 model_lib_v2.py:707] Step 8400 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08384779,\n",
            " 'Loss/localization_loss': 0.033953547,\n",
            " 'Loss/regularization_loss': 0.12708196,\n",
            " 'Loss/total_loss': 0.2448833,\n",
            " 'learning_rate': 0.07558186}\n",
            "I0706 16:24:57.357816 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.08384779,\n",
            " 'Loss/localization_loss': 0.033953547,\n",
            " 'Loss/regularization_loss': 0.12708196,\n",
            " 'Loss/total_loss': 0.2448833,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.327s\n",
            "I0706 16:25:30.051971 139790858835840 model_lib_v2.py:707] Step 8500 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11221,\n",
            " 'Loss/localization_loss': 0.023435801,\n",
            " 'Loss/regularization_loss': 0.12653336,\n",
            " 'Loss/total_loss': 0.26217917,\n",
            " 'learning_rate': 0.07546397}\n",
            "I0706 16:25:30.052290 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11221,\n",
            " 'Loss/localization_loss': 0.023435801,\n",
            " 'Loss/regularization_loss': 0.12653336,\n",
            " 'Loss/total_loss': 0.26217917,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.328s\n",
            "I0706 16:26:02.877813 139790858835840 model_lib_v2.py:707] Step 8600 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.056055214,\n",
            " 'Loss/localization_loss': 0.015906326,\n",
            " 'Loss/regularization_loss': 0.12608238,\n",
            " 'Loss/total_loss': 0.19804391,\n",
            " 'learning_rate': 0.075344615}\n",
            "I0706 16:26:02.878141 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.056055214,\n",
            " 'Loss/localization_loss': 0.015906326,\n",
            " 'Loss/regularization_loss': 0.12608238,\n",
            " 'Loss/total_loss': 0.19804391,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.328s\n",
            "I0706 16:26:35.700911 139790858835840 model_lib_v2.py:707] Step 8700 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12682235,\n",
            " 'Loss/localization_loss': 0.08743487,\n",
            " 'Loss/regularization_loss': 0.12559906,\n",
            " 'Loss/total_loss': 0.33985627,\n",
            " 'learning_rate': 0.07522382}\n",
            "I0706 16:26:35.701214 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12682235,\n",
            " 'Loss/localization_loss': 0.08743487,\n",
            " 'Loss/regularization_loss': 0.12559906,\n",
            " 'Loss/total_loss': 0.33985627,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.328s\n",
            "I0706 16:27:08.486202 139790858835840 model_lib_v2.py:707] Step 8800 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046789702,\n",
            " 'Loss/localization_loss': 0.018611835,\n",
            " 'Loss/regularization_loss': 0.12510477,\n",
            " 'Loss/total_loss': 0.19050631,\n",
            " 'learning_rate': 0.07510157}\n",
            "I0706 16:27:08.486508 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.046789702,\n",
            " 'Loss/localization_loss': 0.018611835,\n",
            " 'Loss/regularization_loss': 0.12510477,\n",
            " 'Loss/total_loss': 0.19050631,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.329s\n",
            "I0706 16:27:41.403881 139790858835840 model_lib_v2.py:707] Step 8900 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.057302773,\n",
            " 'Loss/localization_loss': 0.02404796,\n",
            " 'Loss/regularization_loss': 0.124651484,\n",
            " 'Loss/total_loss': 0.2060022,\n",
            " 'learning_rate': 0.074977875}\n",
            "I0706 16:27:41.404200 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.057302773,\n",
            " 'Loss/localization_loss': 0.02404796,\n",
            " 'Loss/regularization_loss': 0.124651484,\n",
            " 'Loss/total_loss': 0.2060022,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.327s\n",
            "I0706 16:28:14.110791 139790858835840 model_lib_v2.py:707] Step 9000 per-step time 0.327s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06319701,\n",
            " 'Loss/localization_loss': 0.013410599,\n",
            " 'Loss/regularization_loss': 0.12413777,\n",
            " 'Loss/total_loss': 0.20074537,\n",
            " 'learning_rate': 0.07485275}\n",
            "I0706 16:28:14.111096 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06319701,\n",
            " 'Loss/localization_loss': 0.013410599,\n",
            " 'Loss/regularization_loss': 0.12413777,\n",
            " 'Loss/total_loss': 0.20074537,\n",
            " 'learning_rate': 0.07485275}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.332s\n",
            "I0706 16:28:47.343760 139790858835840 model_lib_v2.py:707] Step 9100 per-step time 0.332s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07470569,\n",
            " 'Loss/localization_loss': 0.034907136,\n",
            " 'Loss/regularization_loss': 0.12403119,\n",
            " 'Loss/total_loss': 0.23364401,\n",
            " 'learning_rate': 0.07472619}\n",
            "I0706 16:28:47.344515 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07470569,\n",
            " 'Loss/localization_loss': 0.034907136,\n",
            " 'Loss/regularization_loss': 0.12403119,\n",
            " 'Loss/total_loss': 0.23364401,\n",
            " 'learning_rate': 0.07472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.328s\n",
            "I0706 16:29:20.191325 139790858835840 model_lib_v2.py:707] Step 9200 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.110396385,\n",
            " 'Loss/localization_loss': 0.14696126,\n",
            " 'Loss/regularization_loss': 0.12371789,\n",
            " 'Loss/total_loss': 0.38107556,\n",
            " 'learning_rate': 0.07459819}\n",
            "I0706 16:29:20.191602 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.110396385,\n",
            " 'Loss/localization_loss': 0.14696126,\n",
            " 'Loss/regularization_loss': 0.12371789,\n",
            " 'Loss/total_loss': 0.38107556,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.329s\n",
            "I0706 16:29:53.103617 139790858835840 model_lib_v2.py:707] Step 9300 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062138963,\n",
            " 'Loss/localization_loss': 0.029522756,\n",
            " 'Loss/regularization_loss': 0.123440884,\n",
            " 'Loss/total_loss': 0.21510261,\n",
            " 'learning_rate': 0.074468784}\n",
            "I0706 16:29:53.103914 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.062138963,\n",
            " 'Loss/localization_loss': 0.029522756,\n",
            " 'Loss/regularization_loss': 0.123440884,\n",
            " 'Loss/total_loss': 0.21510261,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.330s\n",
            "I0706 16:30:26.082769 139790858835840 model_lib_v2.py:707] Step 9400 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13565315,\n",
            " 'Loss/localization_loss': 0.02606625,\n",
            " 'Loss/regularization_loss': 0.122909315,\n",
            " 'Loss/total_loss': 0.28462872,\n",
            " 'learning_rate': 0.074337944}\n",
            "I0706 16:30:26.083062 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13565315,\n",
            " 'Loss/localization_loss': 0.02606625,\n",
            " 'Loss/regularization_loss': 0.122909315,\n",
            " 'Loss/total_loss': 0.28462872,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.328s\n",
            "I0706 16:30:58.863493 139790858835840 model_lib_v2.py:707] Step 9500 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07137448,\n",
            " 'Loss/localization_loss': 0.021900602,\n",
            " 'Loss/regularization_loss': 0.12249397,\n",
            " 'Loss/total_loss': 0.21576905,\n",
            " 'learning_rate': 0.074205704}\n",
            "I0706 16:30:58.863772 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07137448,\n",
            " 'Loss/localization_loss': 0.021900602,\n",
            " 'Loss/regularization_loss': 0.12249397,\n",
            " 'Loss/total_loss': 0.21576905,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.329s\n",
            "I0706 16:31:31.759058 139790858835840 model_lib_v2.py:707] Step 9600 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09002786,\n",
            " 'Loss/localization_loss': 0.044499177,\n",
            " 'Loss/regularization_loss': 0.12208737,\n",
            " 'Loss/total_loss': 0.25661442,\n",
            " 'learning_rate': 0.07407206}\n",
            "I0706 16:31:31.759343 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.09002786,\n",
            " 'Loss/localization_loss': 0.044499177,\n",
            " 'Loss/regularization_loss': 0.12208737,\n",
            " 'Loss/total_loss': 0.25661442,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.326s\n",
            "I0706 16:32:04.368694 139790858835840 model_lib_v2.py:707] Step 9700 per-step time 0.326s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.100624025,\n",
            " 'Loss/localization_loss': 0.044860728,\n",
            " 'Loss/regularization_loss': 0.121750526,\n",
            " 'Loss/total_loss': 0.26723528,\n",
            " 'learning_rate': 0.073937014}\n",
            "I0706 16:32:04.368988 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.100624025,\n",
            " 'Loss/localization_loss': 0.044860728,\n",
            " 'Loss/regularization_loss': 0.121750526,\n",
            " 'Loss/total_loss': 0.26723528,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.328s\n",
            "I0706 16:32:37.182121 139790858835840 model_lib_v2.py:707] Step 9800 per-step time 0.328s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06782094,\n",
            " 'Loss/localization_loss': 0.03591955,\n",
            " 'Loss/regularization_loss': 0.12125086,\n",
            " 'Loss/total_loss': 0.22499135,\n",
            " 'learning_rate': 0.07380057}\n",
            "I0706 16:32:37.182408 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.06782094,\n",
            " 'Loss/localization_loss': 0.03591955,\n",
            " 'Loss/regularization_loss': 0.12125086,\n",
            " 'Loss/total_loss': 0.22499135,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.329s\n",
            "I0706 16:33:10.106591 139790858835840 model_lib_v2.py:707] Step 9900 per-step time 0.329s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07779424,\n",
            " 'Loss/localization_loss': 0.045806266,\n",
            " 'Loss/regularization_loss': 0.120749116,\n",
            " 'Loss/total_loss': 0.24434963,\n",
            " 'learning_rate': 0.073662736}\n",
            "I0706 16:33:10.106865 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.07779424,\n",
            " 'Loss/localization_loss': 0.045806266,\n",
            " 'Loss/regularization_loss': 0.120749116,\n",
            " 'Loss/total_loss': 0.24434963,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.330s\n",
            "I0706 16:33:43.075884 139790858835840 model_lib_v2.py:707] Step 10000 per-step time 0.330s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050647594,\n",
            " 'Loss/localization_loss': 0.030410513,\n",
            " 'Loss/regularization_loss': 0.12034435,\n",
            " 'Loss/total_loss': 0.20140246,\n",
            " 'learning_rate': 0.07352352}\n",
            "I0706 16:33:43.076172 139790858835840 model_lib_v2.py:708] {'Loss/classification_loss': 0.050647594,\n",
            " 'Loss/localization_loss': 0.030410513,\n",
            " 'Loss/regularization_loss': 0.12034435,\n",
            " 'Loss/total_loss': 0.20140246,\n",
            " 'learning_rate': 0.07352352}\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "    print('Skipping step')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "  \n",
        "  files['training_script'] = paths['training']+'/model_main_tf2.py'\n",
        "  model_dir = paths['active_model']\n",
        "  \n",
        "  command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(files['training_script'], model_dir, files['pipeline_active'])\n",
        "  # first argument: Path to the model_main_tf2.py file\n",
        "  # second argument: Path to the diretory in which the pipeline.config file is placed (not the path to the file itself)\n",
        "  # third argument: Path to actual pipeline.config in active directory\n",
        "\n",
        "  # This command is necessary to fix issue with training on colab\n",
        "  # source: https://stackoverflow.com/questions/70998639/dnn-library-is-not-found-ssd-mobile-net-v2-in-colab#answer-72404540\n",
        "  !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "\n",
        "  !{command}\n",
        "\n",
        "else:\n",
        "  print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9AuGfWolM0nF",
      "metadata": {
        "id": "9AuGfWolM0nF"
      },
      "source": [
        "# 7 Evaluate training (both)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "BECyzsFhM4P-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BECyzsFhM4P-",
        "outputId": "f3ea5633-969d-4a55-caa4-5110beb379ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py\", line 89, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 195, in checkpoints_iterator\n",
            "    checkpoint_dir, checkpoint_path, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n",
            "    time.sleep(seconds_to_sleep)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 325, in run\n",
            "    if FLAGS.pdb_post_mortem and sys.stdout.isatty():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/flags/_flagvalues.py\", line 469, in __getattr__\n",
            "    fl = self._flags()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/flags/_flagvalues.py\", line 140, in _flags\n",
            "    return self.__dict__['__flags']\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "\n",
        "  paths['train'] = paths['models']+'/my_ssd_mobilenet_v2_fpnlite/train'\n",
        "  paths['eval'] = paths['models']+'/my_ssd_mobilenet_v2_fpnlite/eval'\n",
        "\n",
        "  os.chdir(paths['train'])\n",
        "  !tensorboard --logdir=.\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "  command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(files['training_script'], model_dir, files['pipeline_active'], model_dir)\n",
        "  !{command}\n",
        "\n",
        "else:\n",
        "  print('No operating system was defined...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z8h8jfhMAPw4",
      "metadata": {
        "id": "Z8h8jfhMAPw4"
      },
      "source": [
        "# 8 Download model (Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "VCeIQNwLALYQ",
      "metadata": {
        "id": "VCeIQNwLALYQ",
        "outputId": "ed124b8d-188c-4945-ea76-faf95ab15a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/models/my_ssd_mobilenet_v2_fpnlite/my_ssd_mobilenet_v2_fpnlite.zip' -> '/content/drive/MyDrive/Colab_Notebooks/Object_Detection/3_Output/my_ssd_mobilenet_v2_fpnlite.zip'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ca7c1840db0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'active_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcustom_model_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3_Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Copy labelmap to export folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/models/my_ssd_mobilenet_v2_fpnlite/my_ssd_mobilenet_v2_fpnlite.zip'"
          ]
        }
      ],
      "source": [
        "# Local machine\n",
        "if system_id == 0:\n",
        "  print('Skipping step...')\n",
        "\n",
        "# Google colab    \n",
        "elif system_id == 1:\n",
        "\n",
        "    # Make zip file from directory\n",
        "    import zipfile\n",
        "    os.chdir(paths['models'])\n",
        "\n",
        "    def zipdir(path, ziph):\n",
        "      # ziph is zipfile handle\n",
        "      for root, dirs, files in os.walk(path):\n",
        "          for file in files:\n",
        "              ziph.write(os.path.join(root, file), \n",
        "                        os.path.relpath(os.path.join(root, file), \n",
        "                                        os.path.join(path, '..')))\n",
        "\n",
        "    with zipfile.ZipFile(custom_model_name+'.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "      zipdir(paths['active_model'], zipf)\n",
        "        \n",
        "    # Move zipfile to output folder \n",
        "    source = paths['active_model']+'/'+custom_model_name+'.zip'\n",
        "    destination = paths['3_Output']\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "    # Copy labelmap to export folder\n",
        "    destination = paths['3_Output']\n",
        "    source = files['labelmap']\n",
        "    shutil.copy(source, destination)\n",
        "\n",
        "else:\n",
        "  print('No operating system was defined...')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_Preparing_Model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "joshBak",
      "language": "python",
      "name": "joshbak"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}