{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28293d11",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joshba06/Object_Detection/blob/main/PreparationAndTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h3jZ8O9eJKiC",
   "metadata": {
    "id": "h3jZ8O9eJKiC"
   },
   "source": [
    "# Readme\n",
    "\n",
    "**Step 1**: \n",
    "\n",
    "This script has to be run on both, Colab (training) and the local machine (object detection). Set the variable \"system_id\" to 1, if running on Colab or to 0 if running on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bba4db",
   "metadata": {
    "id": "16bba4db"
   },
   "source": [
    "# 1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xTsthyMa7O1t",
   "metadata": {
    "id": "xTsthyMa7O1t"
   },
   "source": [
    "## 1.1 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cbd24",
   "metadata": {
    "id": "900cbd24"
   },
   "outputs": [],
   "source": [
    "# Choose 1, if running on colab and 0 if running on local machine\n",
    "system_id = 0\n",
    "\n",
    "# Define the objects that you would like to train the deep learning-model with below\n",
    "labels = ['Engine']\n",
    "\n",
    "# Change model url and name if model changes\n",
    "pre_trained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "pre_trained_model_name = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "custom_model_name = 'my_ssd_mobilenet_v2_fpnlite'\n",
    "\n",
    "img_size = (640, 640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1fba8",
   "metadata": {
    "id": "edb1fba8"
   },
   "source": [
    "## 1.2 Create file and folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VYjsBYZoo2PX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYjsBYZoo2PX",
    "outputId": "f404483b-7b53-40c3-9b64-34c4445df23c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Local machine\n",
    "if system_id == 0:\n",
    "    home_path = '/Users/niklas/Virtual_Environment/Version_5/projectAutonomous'\n",
    "    print('Running on local machine...')\n",
    "    os.chdir(home_path)   \n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    \n",
    "    print('Running on Google Colab...')\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Setup path to home directory \n",
    "    home_path = '/content/drive/MyDrive/Colab_Notebooks/Object_Detection'\n",
    "    os.chdir(home_path)    \n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a85065",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56a85065",
    "outputId": "895ba508-07df-4f1e-bbb9-ad5f370b4901"
   },
   "outputs": [],
   "source": [
    "import setup\n",
    "files, paths = setup.createFolderStructure(labels, home_path, system_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf9fcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caaf9fcf",
    "outputId": "5a85cbca-3f1d-4bd8-83a2-5ab37a2592e1"
   },
   "outputs": [],
   "source": [
    "# Create dict with labels\n",
    "dict_labels = {}\n",
    "num = 1\n",
    "for label in labels:\n",
    "    dict_labels[label]= num\n",
    "    num += 1\n",
    "print(dict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6bd0a",
   "metadata": {
    "id": "44d6bd0a"
   },
   "source": [
    "## 1.3 Installing Dependencies and importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42ecf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e42ecf9",
    "outputId": "693f87f6-7124-4fb1-a119-4293fb2df8be"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    try:\n",
    "        import cv2 as cv\n",
    "\n",
    "        import pkg_resources\n",
    "        installed_packages = pkg_resources.working_set\n",
    "        installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)\n",
    "           for i in installed_packages])\n",
    "        #print(installed_packages_list)\n",
    "\n",
    "        for i in range(len(installed_packages_list)):\n",
    "            package_name = installed_packages_list[i].split('==')[0]\n",
    "\n",
    "            # Uninstall any package of openCV that is not \"opencv-contrib-python\"\n",
    "            if ('opencv' in package_name) and (package_name != 'opencv-contrib-python'):\n",
    "                package_name = installed_packages_list[i].split('==')[0]\n",
    "                print('Uninstalling '+package_name)\n",
    "                !pip uninstall {package_name} -y\n",
    "\n",
    "            # Check if correct version of \"opencv-contrib-python\" is installed, otherwise re-install it\n",
    "            elif package_name == 'opencv-contrib-python':\n",
    "                package_version = installed_packages_list[i].split('==')[1]\n",
    "                #print('Version of package \"{}\" is: {}'.format(package_name, package_version))\n",
    "                if package_version == '4.6.0.66':\n",
    "                    print('Correct package is installed:  {} version {}'.format(package_name, package_version))\n",
    "                    nothing = 0\n",
    "                else:\n",
    "                    !pip uninstall {package_name} -y\n",
    "            \n",
    "        \n",
    "        # Install correct version of \"opencv-contrib-python\" (installation is skipped if package is installed)\n",
    "        !pip install opencv-contrib-python==4.6.0.66\n",
    "\n",
    "\n",
    "    except:\n",
    "        !pip install opencv-contrib-python==4.6.0.66\n",
    "\n",
    "elif system_id == 1:\n",
    "    print('No need to install openCV in Colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01564f7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01564f7e",
    "outputId": "80d062bb-879c-4582-d893-a1ac930b1afd"
   },
   "outputs": [],
   "source": [
    "# Package for downloading content via URLs\n",
    "!pip install wget\n",
    "\n",
    "# Package for displaying opencv in jupyter notebook plot\n",
    "!pip install pyqt5\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb5647",
   "metadata": {
    "id": "f4bb5647"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "import uuid\n",
    "\n",
    "import time\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import shutil\n",
    "\n",
    "import math\n",
    "\n",
    "import wget\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520241f2",
   "metadata": {
    "id": "520241f2"
   },
   "source": [
    "# 3. Prepare Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900ebb",
   "metadata": {
    "id": "2d900ebb"
   },
   "source": [
    "## 3.1 Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7923f0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "a7923f0c",
    "outputId": "7707ed6e-a4f1-47aa-f963-8f5327cb7ddc"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        if tf.__version__ == \"2.5.0\":\n",
    "            print('Tenforflow version 2.5.0 is already installed...')\n",
    "        else:\n",
    "            print('Tensorflow version is: '+str(tf.__version__))\n",
    "            !pip install tensorflow==2.5.0\n",
    "    except:\n",
    "        !pip install tensorflow==2.5.0\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    !pip install tensorflow-gpu==2.5.0 \n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c0b45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e16c0b45",
    "outputId": "b678b7d5-2978-4ad5-d083-b5afcbe9ddc4"
   },
   "outputs": [],
   "source": [
    "# Download the model garden (model garden is an environment that is necessary to train new models from scratch or to continue training existing models)\n",
    "# The model itself will be downloaded later\n",
    "\n",
    "# Clone repository only if it does not exist already\n",
    "os.chdir(paths['2_Tensorflow'])\n",
    "if os.path.exists(paths['2_Tensorflow']+'/models/research') is False:\n",
    "    print('Cloning model garden..')\n",
    "    !git clone https://github.com/tensorflow/models.git\n",
    "    \n",
    "else:\n",
    "    print('Model garden is already installed...')\n",
    "    \n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6592a9",
   "metadata": {
    "id": "1c6592a9"
   },
   "outputs": [],
   "source": [
    "# Install protobuf\n",
    "if os.path.exists(paths['2_Tensorflow']+'/protoc/protoc-21.1-osx-aarch_64.zip') is False:\n",
    "\n",
    "    # Go to destination directory\n",
    "    os.chdir(paths['protoc'])\n",
    "    protoc_url = 'https://github.com/protocolbuffers/protobuf/releases/download/v21.1/protoc-21.1-osx-aarch_64.zip'\n",
    "    wget.download(protoc_url)\n",
    "\n",
    "    # Extract all content of downloaded file\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    with ZipFile('protoc-21.1-osx-aarch_64.zip', 'r') as zipObj:\n",
    "        zipObj.extractall()\n",
    "\n",
    "    os.environ['Path'] = paths['protoc']+'/bin'\n",
    "    os.chdir(paths['research'])\n",
    "\n",
    "    !protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "else:\n",
    "    print('Protobuf is already installed...')\n",
    "    \n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec3dc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06ec3dc7",
    "outputId": "701dfb16-7d67-4fc8-bf5f-daabcbc1f029"
   },
   "outputs": [],
   "source": [
    "# Install pycocotools\n",
    "\n",
    "# Clone repository only if it does not exist already\n",
    "if os.path.exists(paths['research']+'/cocoapi') is False:\n",
    "    print('Cloning cocoapi..')\n",
    "    !git clone https://github.com/cocodataset/cocoapi.git\n",
    "    \n",
    "    # Moving cloned file to 'research' folder\n",
    "    destination = paths['research']\n",
    "    source = paths['home']+'/cocoapi'\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "else:\n",
    "    print('Cocoapi is already installed...')\n",
    "\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70c4aa",
   "metadata": {
    "id": "fe70c4aa"
   },
   "source": [
    "## 3.2 Install Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d18cae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2d18cae",
    "outputId": "c8d449f3-d8d7-49bd-a822-f253526fbec1"
   },
   "outputs": [],
   "source": [
    "# Check if API has already been installed\n",
    "if os.path.exists(paths['research']+'/setup.py') is False:\n",
    "    print('Installing setup.py...')\n",
    "    \n",
    "    # Move to 'research' directory\n",
    "    os.chdir(paths['research'])\n",
    "\n",
    "    # Copy setup.py to current working directory\n",
    "    !cp object_detection/packages/tf2/setup.py .\n",
    "\n",
    "    # Execute setup.py (this command installs all dependencies needed for tf2 odapi)\n",
    "    !python -m pip install .\n",
    "\n",
    "    print('Installation complete..')\n",
    "\n",
    "else:\n",
    "    print('Object Detection API is already installed...')\n",
    "\n",
    "# Move back to home-directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00f3be",
   "metadata": {
    "id": "9a00f3be"
   },
   "source": [
    "## 3.3 Check if API was installed successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfbfba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70dfbfba",
    "outputId": "1c5d0969-1156-41e6-9af6-f2137099198d"
   },
   "outputs": [],
   "source": [
    "# Move to 'research' directory\n",
    "os.chdir(paths['research'])\n",
    "import object_detection\n",
    "\n",
    "# Local machine\n",
    "if system_id == 0:\n",
    "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
    "    \n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    !pip install numpy --upgrade # This had to be added for execution on colab. Problem solved using stackoverflow\n",
    "\n",
    "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
    "else:\n",
    "    print('No operating system was defined...')\n",
    "\n",
    "# Move back to home directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006de28",
   "metadata": {
    "id": "0006de28"
   },
   "source": [
    "# 4. Prepare new training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441180b",
   "metadata": {
    "id": "e441180b"
   },
   "source": [
    "## 4.1 Install dependencies and import modules (only on Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4556e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57a4556e",
    "outputId": "da9eb563-7db9-418e-f2f2-6a91cca5180b"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "  \n",
    "  ## Install missing modules for randomTrafficSign\n",
    "  !pip install matplotlib\n",
    "  !pip install lxml\n",
    "\n",
    "  import numpy as np\n",
    "  from xml.etree.ElementTree import ElementTree\n",
    "  from xml.etree.ElementTree import Element\n",
    "  import xml.etree.ElementTree as etree\n",
    "  import xml.dom.minidom\n",
    "\n",
    "  from lxml import etree\n",
    "  os.chdir(paths['home'])\n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XxrqC-lQ7IXF",
   "metadata": {
    "id": "XxrqC-lQ7IXF"
   },
   "source": [
    "## 4.2 Partition images for testing and training (only on Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KYPtSyTxziNo",
   "metadata": {
    "id": "KYPtSyTxziNo"
   },
   "source": [
    "**Important**: Images of objects must be in the following format: \"Mug_1.jpg\", \"Cat_3.jpg\" and must be located in their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KqMKGZRBYKfR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqMKGZRBYKfR",
    "outputId": "433ce14a-67df-4d49-e66a-6de70c95bdd8"
   },
   "outputs": [],
   "source": [
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    !pip install -U albumentations --no-binary qudida,albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapVybbT3jYk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sapVybbT3jYk",
    "outputId": "7892db7f-d6d3-47f2-8160-facde352a266"
   },
   "outputs": [],
   "source": [
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "    # imagePreprocessing.py must be in same directory as this main script\n",
    "    %matplotlib inline\n",
    "    path = paths['0_User_Input']+'/scripts'\n",
    "    os.chdir(path)\n",
    "    import imageProcessing as imgprep\n",
    "    os.chdir(paths['home'])\n",
    "\n",
    "    imgprep.clearPreprocessing(paths['images'])\n",
    "    imgprep.clearTraining(paths['training']+'/images')\n",
    "\n",
    "    numImgs = 250\n",
    "    upperScale = 350\n",
    "    lowerScale = 150\n",
    "\n",
    "    # Modify and multiply images and store in 1_Preprocessing folder\n",
    "    imgprep.main(dict_labels, paths['backgrounds'], paths['objects'], numImgs, upperScale, lowerScale, paths['images']+'/', paths['training']+'/')\n",
    "\n",
    "    imgprep.clearPreprocessing(paths['images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a93934",
   "metadata": {
    "id": "11a93934"
   },
   "source": [
    "## 5.4 Create labelmap (only on Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e44434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6e44434",
    "outputId": "36819b83-f3a5-48a4-af04-e9af7dfd38da"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "    # Convert label-dict to needed format\n",
    "    labelmap = []\n",
    "    for key in dict_labels:\n",
    "      temp = {}\n",
    "      temp['name'] = key\n",
    "      temp['id'] = dict_labels[key]\n",
    "      labelmap.append(temp)\n",
    "    print(labelmap)\n",
    "\n",
    "    files['labelmap'] = paths['annotations']+'/label_map.pbtxt'\n",
    "\n",
    "    with open(files['labelmap'], 'w') as file:\n",
    "      for label in labelmap:\n",
    "          file.write('item { \\n')\n",
    "          file.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "          file.write('\\tid:{}\\n'.format(label['id']))\n",
    "          file.write('}\\n')\n",
    "        \n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42670147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42670147",
    "outputId": "a33a2d30-e496-40a7-ae26-23ac2eaa3365"
   },
   "outputs": [],
   "source": [
    "# Install pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe07d6",
   "metadata": {
    "id": "edbe07d6"
   },
   "source": [
    "## 5.5 Create TFRecord (only on colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668f3c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3668f3c2",
    "outputId": "f254afdd-87c1-45ae-8c7a-7ef2dfd57247"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "  # Add labelmap and tfrecords to 'files' dictionary\n",
    "  files['tf_train'] = paths['annotations']+'/train.record'\n",
    "  files['tf_test'] = paths['annotations']+'/test.record'\n",
    "\n",
    "  # Add line to download TF record file from nicknochnack\n",
    "\n",
    "  # Copy generatetfrecord.py to scripts\n",
    "  source = paths['0_User_Input']+'/scripts/generatetfrecord.py'\n",
    "  shutil.copy(source, paths['scripts'])\n",
    "\n",
    "  # Change directory to 'scripts'\n",
    "  os.chdir(paths['workspace']+'/scripts')\n",
    "\n",
    "  # Create / overwrite TFRecord files for training and testing\n",
    "\n",
    "  # Create train data:\n",
    "  !python generatetfrecord.py -x {paths['images_training']} -l {files['labelmap']} -o {files['tf_train']}\n",
    "\n",
    "  # Create test data:\n",
    "  !python generatetfrecord.py -x {paths['images_testing']} -l {files['labelmap']} -o {files['tf_test']}\n",
    "\n",
    "  # Go back to home directory\n",
    "  os.chdir(paths['home'])\n",
    "\n",
    " \n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b339fe9",
   "metadata": {
    "id": "3b339fe9"
   },
   "source": [
    "## 5.6 Download pre-trained model (only on colab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd98fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44cd98fc",
    "outputId": "d6d5bc01-0a21-48de-ca18-ffedd1725471"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "  # Update the settings for the image import and multiplication script depending on which size of image the model uses!\n",
    "\n",
    "  # Check if the chosen model has already been downloaded\n",
    "  if os.path.exists(paths['pre_trained_models']+'/'+str(pre_trained_model_name)) is False:\n",
    "\n",
    "      # Go to destination directory\n",
    "      os.chdir(paths['pre_trained_models'])\n",
    "      wget.download(pre_trained_model_url)\n",
    "\n",
    "      # Extract all content of downloaded file\n",
    "      import tarfile\n",
    "\n",
    "      file = tarfile.open('ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz')\n",
    "\n",
    "      file.extractall(paths['pre_trained_models'])\n",
    "\n",
    "      file.close()\n",
    "                    \n",
    "      # Delete downloaded tar.gz file to save storage space\n",
    "      # Add code here\n",
    "      #\n",
    "      #\n",
    "      \n",
    "      # Create new folder for this model in training/models\n",
    "      paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "      os.makedirs(paths['active_model'])\n",
    "      \n",
    "      print('Model was successfully downloaded...')\n",
    "\n",
    "\n",
    "  else:\n",
    "    print(str(pre_trained_model_name)+' was already installed...')\n",
    "    \n",
    "    os.chdir(paths['home'])\n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d8741",
   "metadata": {
    "id": "5d9d8741"
   },
   "source": [
    "## 5.7 Update the config file and pipeline for the new training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f7e2a",
   "metadata": {
    "id": "ae3f7e2a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fe75d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256fe75d",
    "outputId": "ddaad63d-b87e-4dbe-f480-49a3a7a2eada"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "  ## Copy or replace pipeline in active model directory\n",
    "  files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config'\n",
    "  paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "  files['pipeline_active'] = paths['active_model']+'/pipeline.config'\n",
    "  paths['downloaded_model'] = paths['pre_trained_models']+'/'+pre_trained_model_name\n",
    "\n",
    "  # If pipeline already exists in active directory, replace it\n",
    "  if os.path.exists(files['pipeline_active']) == True:\n",
    "      os.remove(files['pipeline_active'])\n",
    "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "      print('Pipeline replaced in active model directory...')\n",
    "\n",
    "  # If pipeline does not yet exist in active directory, copy it from downloaded model\n",
    "  else:\n",
    "      files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config' \n",
    "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "      print('Pipeline copied to active model directory...')\n",
    "\n",
    "  ## Configure pipeline\n",
    "\n",
    "  config = config_util.get_configs_from_pipeline_file(files['pipeline_active'])\n",
    "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "  with tf.io.gfile.GFile(files['pipeline_active'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "      text_format.Merge(proto_str, pipeline_config)  \n",
    "\n",
    "\n",
    "  pipeline_config.model.ssd.num_classes = len(labels) # Number of labels the model should be trained for\n",
    "  pipeline_config.train_config.batch_size = 4 # This should be the number of training jobs that run parallel\n",
    "\n",
    "  # Get checkpoint 0 from (original) downloaded model \n",
    "  files['checkpoint0'] = paths['downloaded_model']+'/checkpoint/ckpt-0'\n",
    "\n",
    "  pipeline_config.train_config.fine_tune_checkpoint = files['checkpoint0']\n",
    "\n",
    "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "\n",
    "  # Get labelmap\n",
    "  pipeline_config.train_input_reader.label_map_path= files['labelmap']\n",
    "\n",
    "  # Get TF-Record\n",
    "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [files['tf_train']]\n",
    "  pipeline_config.eval_input_reader[0].label_map_path = files['labelmap']\n",
    "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [files['tf_test']]\n",
    "\n",
    "  config_text = text_format.MessageToString(pipeline_config)\n",
    "\n",
    "  # Update active pipeline\n",
    "  with tf.io.gfile.GFile(files['pipeline_active'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "      f.write(config_text)   \n",
    "      \n",
    "  print('Pipeline successfully configured...')  \n",
    "\n",
    "  # Copy model_main_tf2.py to workspace -> training   'TensorFlow/models/research/' file to \n",
    "  source = paths['research']+'/object_detection/model_main_tf2.py'\n",
    "  destination = paths['training']\n",
    "  shutil.copy(source, destination)\n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08eb2c1",
   "metadata": {
    "id": "b08eb2c1"
   },
   "source": [
    "# 6. Start new training job (only on colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d6094",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "054d6094",
    "outputId": "e6bec8fd-8040-4f8e-9699-18c4d91c4e47"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "  \n",
    "  files['training_script'] = paths['training']+'/model_main_tf2.py'\n",
    "  model_dir = paths['active_model']\n",
    "  \n",
    "  command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(files['training_script'], model_dir, files['pipeline_active'])\n",
    "  # first argument: Path to the model_main_tf2.py file\n",
    "  # second argument: Path to the diretory in which the pipeline.config file is placed (not the path to the file itself)\n",
    "  # third argument: Path to actual pipeline.config in active directory\n",
    "\n",
    "  # This command is necessary to fix issue with training on colab\n",
    "  # source: https://stackoverflow.com/questions/70998639/dnn-library-is-not-found-ssd-mobile-net-v2-in-colab#answer-72404540\n",
    "  !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "\n",
    "  !{command}\n",
    "\n",
    "else:\n",
    "  print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9AuGfWolM0nF",
   "metadata": {
    "id": "9AuGfWolM0nF"
   },
   "source": [
    "# 7 Evaluate training (both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BECyzsFhM4P-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BECyzsFhM4P-",
    "outputId": "f3ea5633-969d-4a55-caa4-5110beb379ff"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "\n",
    "  paths['train'] = paths['3_Output']+'/my_ssd_mobilenet_v2_fpnlite/train'\n",
    "  paths['eval'] = paths['3_Output']+'/my_ssd_mobilenet_v2_fpnlite/eval'\n",
    "\n",
    "  os.chdir(paths['eval'])\n",
    "  !tensorboard --logdir=.\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "  command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(files['training_script'], model_dir, files['pipeline_active'], model_dir)\n",
    "  !{command}\n",
    "\n",
    "else:\n",
    "  print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z8h8jfhMAPw4",
   "metadata": {
    "id": "Z8h8jfhMAPw4"
   },
   "source": [
    "# 8 Download model (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VCeIQNwLALYQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "VCeIQNwLALYQ",
    "outputId": "ed124b8d-188c-4945-ea76-faf95ab15a88"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "  print('Skipping step...')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "\n",
    "    # Copy labelmap to model folder\n",
    "    source = files['labelmap']\n",
    "    shutil.copy(source, paths['active_model'])\n",
    "\n",
    "    # Move active file directory to output folder\n",
    "    from distutils.dir_util import copy_tree\n",
    "    copy_tree(paths['active_model'], paths['3_Output']+'/'+custom_model_name)\n",
    "\n",
    "    # Delete model directory from models folder\n",
    "    shutil.rmtree(paths['active_model'])\n",
    "    print('Removed model directory from 2_Tensorflow')\n",
    "\n",
    "else:\n",
    "  print('No operating system was defined...')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "1_Preparing_Model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "joshBakNew",
   "language": "python",
   "name": "joshbaknew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
