{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28293d11",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joshba06/Object_Detection/blob/main/PreparationAndTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h3jZ8O9eJKiC",
   "metadata": {
    "id": "h3jZ8O9eJKiC"
   },
   "source": [
    "# Readme\n",
    "\n",
    "**Step 1**: \n",
    "\n",
    "This script has to be run on both, Colab (training) and the local machine (object detection). Set the variable \"system_id\" to 1, if running on Colab or to 0 if running on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bba4db",
   "metadata": {
    "id": "16bba4db"
   },
   "source": [
    "# 1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xTsthyMa7O1t",
   "metadata": {
    "id": "xTsthyMa7O1t"
   },
   "source": [
    "## 1.1 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900cbd24",
   "metadata": {
    "id": "900cbd24"
   },
   "outputs": [],
   "source": [
    "homePathColab = '/content/drive/MyDrive/Colab_Notebooks/Object_Detection'\n",
    "homePathLocal = '/Users/niklas/Virtual_Environment/Version_5/projectAutonomous'\n",
    "\n",
    "# Define the objects that you would like to train the deep learning-model with below\n",
    "labels = ['Engine']\n",
    "\n",
    "# Change model url and name if model changes\n",
    "pre_trained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "pre_trained_model_name = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "custom_model_name = 'my_ssd_mobilenet_v2_fpnlite'\n",
    "\n",
    "img_size = (640, 640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1fba8",
   "metadata": {
    "id": "edb1fba8"
   },
   "source": [
    "## 1.2 Create folder structure and install required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "VYjsBYZoo2PX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYjsBYZoo2PX",
    "outputId": "f404483b-7b53-40c3-9b64-34c4445df23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine...\n"
     ]
    }
   ],
   "source": [
    "# Import basic packages\n",
    "import os\n",
    "import shutil\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "systemName = platform.system()\n",
    "\n",
    "import setup\n",
    "if systemName == 'Linux': # Running on colab\n",
    "    print('Running on Google Colab...')\n",
    "    homePath = homePathColab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    files, paths = setup.installPackages(homePath, labels, firstInstallation=True)\n",
    "else:\n",
    "    print('Running on local machine...')\n",
    "    homePath = homePathLocal\n",
    "    files, paths = setup.installPackages(homePath, labels, firstInstallation=True)\n",
    "\n",
    "os.chdir(paths['home'])    \n",
    "\n",
    "# Import installed packages\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import uuid\n",
    "import time\n",
    "import pathlib\n",
    "import shutil\n",
    "import math\n",
    "import wget\n",
    "import sys\n",
    "import numpy as np\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "from xml.etree.ElementTree import Element\n",
    "import xml.etree.ElementTree as etree\n",
    "import xml.dom.minidom\n",
    "from lxml import etree\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XxrqC-lQ7IXF",
   "metadata": {
    "id": "XxrqC-lQ7IXF"
   },
   "source": [
    "## 4.2 Partition images for testing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KYPtSyTxziNo",
   "metadata": {
    "id": "KYPtSyTxziNo"
   },
   "source": [
    "**Important**: Images of objects must be in the following format: \"Mug_1.jpg\", \"Cat_3.jpg\" and must be located in their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict with labels\n",
    "dict_labels = {}\n",
    "num = 1\n",
    "for label in labels:    \n",
    "    dict_labels[label]= num\n",
    "    num += 1\n",
    "print(dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sapVybbT3jYk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sapVybbT3jYk",
    "outputId": "7892db7f-d6d3-47f2-8160-facde352a266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "    os.chdir(paths['scripts'])\n",
    "    import imageProcessing as imgprep\n",
    "    os.chdir(paths['home'])\n",
    "\n",
    "    imgprep.clearPreprocessing(paths['images'])\n",
    "    imgprep.clearTraining(paths['training']+'/images')\n",
    "\n",
    "    numImgs = 250\n",
    "    upperScale = 350\n",
    "    lowerScale = 150\n",
    "\n",
    "    # Modify and multiply images and store in 1_Preprocessing folder\n",
    "    imgprep.main(dict_labels, paths['backgrounds'], paths['objects'], numImgs, upperScale, lowerScale, paths['images']+'/', paths['training']+'/')\n",
    "\n",
    "    imgprep.clearPreprocessing(paths['images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a93934",
   "metadata": {
    "id": "11a93934"
   },
   "source": [
    "## 5.4 Create labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e44434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6e44434",
    "outputId": "36819b83-f3a5-48a4-af04-e9af7dfd38da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "\n",
    "    # Convert label-dict to needed format\n",
    "    labelmap = []\n",
    "    for key in dict_labels:\n",
    "      temp = {}\n",
    "      temp['name'] = key\n",
    "      temp['id'] = dict_labels[key]\n",
    "      labelmap.append(temp)\n",
    "    print(labelmap)\n",
    "\n",
    "    with open(files['labelmap'], 'w') as file:\n",
    "      for label in labelmap:\n",
    "          file.write('item { \\n')\n",
    "          file.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "          file.write('\\tid:{}\\n'.format(label['id']))\n",
    "          file.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe07d6",
   "metadata": {
    "id": "edbe07d6"
   },
   "source": [
    "## 5.5 Create TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3668f3c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3668f3c2",
    "outputId": "f254afdd-87c1-45ae-8c7a-7ef2dfd57247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "\n",
    "  # Create / overwrite TFRecord files for training and testing\n",
    "  subprocess.run(['python', files['generateTfRecord'], '-x', paths['images_training'], '-l', files['labelmap'], '-o', files['tf_train']])\n",
    "  subprocess.run(['python', files['generateTfRecord'], '-x', paths['images_testing'], '-l', files['labelmap'], '-o', files['tf_test']])\n",
    "\n",
    "# Go back to home directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b339fe9",
   "metadata": {
    "id": "3b339fe9"
   },
   "source": [
    "## 5.6 Download pre-trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44cd98fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44cd98fc",
    "outputId": "d6d5bc01-0a21-48de-ca18-ffedd1725471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "\n",
    "  # Check if the chosen model has already been downloaded\n",
    "  if os.path.exists(paths['pre_trained_models']+'/'+str(pre_trained_model_name)) is False:\n",
    "\n",
    "      # Go to destination directory\n",
    "      os.chdir(paths['pre_trained_models'])\n",
    "      wget.download(pre_trained_model_url)\n",
    "\n",
    "      # Extract all content of downloaded file\n",
    "      import tarfile\n",
    "\n",
    "      file = tarfile.open('ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz')\n",
    "\n",
    "      file.extractall(paths['pre_trained_models'])\n",
    "\n",
    "      file.close()\n",
    "      \n",
    "      # Create new folder for this model in training/models\n",
    "      paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "      os.makedirs(paths['active_model'])\n",
    "      \n",
    "      print('Model was successfully downloaded...')\n",
    "\n",
    "\n",
    "  else:\n",
    "    print(str(pre_trained_model_name)+' was already installed...')\n",
    "    \n",
    "    os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d8741",
   "metadata": {
    "id": "5d9d8741"
   },
   "source": [
    "## 5.7 Update the config file and pipeline for the new training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "256fe75d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256fe75d",
    "outputId": "ddaad63d-b87e-4dbe-f480-49a3a7a2eada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "\n",
    "  ## Copy or replace pipeline in active model directory\n",
    "  files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config'\n",
    "  paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "  files['pipeline_active'] = paths['active_model']+'/pipeline.config'\n",
    "  paths['downloaded_model'] = paths['pre_trained_models']+'/'+pre_trained_model_name\n",
    "\n",
    "  # If pipeline already exists in active directory, replace it\n",
    "  if os.path.exists(files['pipeline_active']) == True:\n",
    "      os.remove(files['pipeline_active'])\n",
    "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "      print('Pipeline replaced in active model directory...')\n",
    "\n",
    "  # If pipeline does not yet exist in active directory, copy it from downloaded model\n",
    "  else:\n",
    "      files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config' \n",
    "      shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "      print('Pipeline copied to active model directory...')\n",
    "\n",
    "  ## Configure pipeline\n",
    "\n",
    "  config = config_util.get_configs_from_pipeline_file(files['pipeline_active'])\n",
    "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "  with tf.io.gfile.GFile(files['pipeline_active'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "      text_format.Merge(proto_str, pipeline_config)  \n",
    "\n",
    "\n",
    "  pipeline_config.model.ssd.num_classes = len(labels) # Number of labels the model should be trained for\n",
    "  pipeline_config.train_config.batch_size = 4 # This should be the number of training jobs that run parallel\n",
    "\n",
    "  # Get checkpoint 0 from (original) downloaded model \n",
    "  files['checkpoint0'] = paths['downloaded_model']+'/checkpoint/ckpt-0'\n",
    "\n",
    "  pipeline_config.train_config.fine_tune_checkpoint = files['checkpoint0']\n",
    "\n",
    "  pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "\n",
    "  # Get labelmap\n",
    "  pipeline_config.train_input_reader.label_map_path= files['labelmap']\n",
    "\n",
    "  # Get TF-Record\n",
    "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [files['tf_train']]\n",
    "  pipeline_config.eval_input_reader[0].label_map_path = files['labelmap']\n",
    "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [files['tf_test']]\n",
    "\n",
    "  config_text = text_format.MessageToString(pipeline_config)\n",
    "\n",
    "  # Update active pipeline\n",
    "  with tf.io.gfile.GFile(files['pipeline_active'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "      f.write(config_text)   \n",
    "      \n",
    "  print('Pipeline successfully configured...')  \n",
    "\n",
    "  # Copy model_main_tf2.py to workspace -> training   'TensorFlow/models/research/'\n",
    "  source = paths['research']+'/object_detection/model_main_tf2.py'\n",
    "  destination = paths['training']\n",
    "  shutil.copy(source, destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08eb2c1",
   "metadata": {
    "id": "b08eb2c1"
   },
   "source": [
    "# 6. Start new training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "054d6094",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "054d6094",
    "outputId": "e6bec8fd-8040-4f8e-9699-18c4d91c4e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping step\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "    print('Skipping step')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "  \n",
    "  files['training_script'] = paths['training']+'/model_main_tf2.py'\n",
    "  \n",
    "  # This command is necessary to fix issue with training on colab\n",
    "  # source: https://stackoverflow.com/questions/70998639/dnn-library-is-not-found-ssd-mobile-net-v2-in-colab#answer-72404540\n",
    "  subprocess.run(['pip', 'install', '--allow-change-held-packages', 'libcudnn8=8.1.0.77-1+cuda11.2'])\n",
    "  #!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "  subprocess.run(['python',files['training_script'], '--model_dir='+paths['active_model'], '--pipeline_config_path='+files['pipeline_active'], '--num_train_steps=10000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9AuGfWolM0nF",
   "metadata": {
    "id": "9AuGfWolM0nF"
   },
   "source": [
    "# 7 Evaluate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BECyzsFhM4P-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BECyzsFhM4P-",
    "outputId": "f3ea5633-969d-4a55-caa4-5110beb379ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "\n",
    "  paths['train'] = paths['3_Output']+'/'+custom_model_name+'/train'\n",
    "  paths['eval'] = paths['3_Output']+'/'+custom_model_name+'/eval'\n",
    "\n",
    "  os.chdir(paths['eval'])\n",
    "  !tensorboard --logdir=.\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "  subprocess.run(['python',files['training_script'], '--model_dir='+paths['active_model'], '--pipeline_config_path='+files['pipeline_active'], '--checkpoint_dir=', paths['active_model']])\n",
    "\n",
    "  #command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(files['training_script'], model_dir, files['pipeline_active'], model_dir)\n",
    "  #!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z8h8jfhMAPw4",
   "metadata": {
    "id": "Z8h8jfhMAPw4"
   },
   "source": [
    "# 8 Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VCeIQNwLALYQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "VCeIQNwLALYQ",
    "outputId": "ed124b8d-188c-4945-ea76-faf95ab15a88"
   },
   "outputs": [],
   "source": [
    "# Local machine\n",
    "if systemName != 'Linux':\n",
    "  print('Skipping step...')\n",
    "\n",
    "# Google colab    \n",
    "else:\n",
    "\n",
    "    # Copy labelmap to model folder\n",
    "    shutil.copy(files['labelmap'], paths['active_model'])\n",
    "\n",
    "    # Move active file directory to output folder\n",
    "    from distutils.dir_util import copy_tree\n",
    "    copy_tree(paths['active_model'], paths['3_Output']+'/'+custom_model_name)\n",
    "\n",
    "    # Delete model directory from models folder\n",
    "    shutil.rmtree(paths['active_model'])\n",
    "    print('Copied model to 3_Output and removed model directory from 2_Tensorflow')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "1_Preparing_Model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "joshBakNew",
   "language": "python",
   "name": "joshbaknew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
