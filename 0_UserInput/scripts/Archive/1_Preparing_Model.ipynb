{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033021df",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joshba06/Object_Detection/blob/main/1_Preparing_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bba4db",
   "metadata": {
    "id": "16bba4db"
   },
   "source": [
    "# 1. Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900cbd24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "900cbd24",
    "outputId": "cabd177a-b0b2-473e-82f9-38369fbe1c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine...\n"
     ]
    }
   ],
   "source": [
    "# Choose \"1\" if running on Colab, choose \"0\" if running on local machine\n",
    "system_id = 0\n",
    "\n",
    "if system_id == 0:\n",
    "    print('Running on local machine...')\n",
    "elif system_id == 1:\n",
    "    print('Running on Google Colab...')\n",
    "else:\n",
    "    print('Please define which operating system you are running on...!')\n",
    "\n",
    "# Define the objects that you would like to train the deep learning-model with below\n",
    "labels = ['Pen', 'Mug']\n",
    "\n",
    "labelmap = [{'name':'Pen', 'id':1}, {'name':'Mug', 'id':2}]\n",
    "\n",
    "# Change model url and name if model changes\n",
    "pre_trained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "pre_trained_model_name = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "custom_model_name = 'my_ssd_mobilenet_v2_fpnlite'\n",
    "\n",
    "img_size = (640, 640)\n",
    "\n",
    "# Make sure the top folder for Colab is renamed to \"Colab-Notebooks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VYjsBYZoo2PX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYjsBYZoo2PX",
    "outputId": "ce46b7f3-b0e7-49fb-e541-cf44df21d2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Local machine\n",
    "if system_id == 0:\n",
    "    home_path = '/Users/niklas/Virtual_Environment/Version_1/Object_Detection'\n",
    "    print('Running on local machine...')\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    \n",
    "    print('Running on Google Colab...')\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Setup path to home directory \n",
    "    home_path = '/content/drive/MyDrive/Colab_Notebooks/Object_Detection'\n",
    "    os.chdir(home_path)    \n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1fba8",
   "metadata": {
    "id": "edb1fba8"
   },
   "source": [
    "## 1.2 Create file and folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaf9fcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caaf9fcf",
    "outputId": "5c7662fe-d7db-485b-ab51-dcd20c5a21aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/0_User_Input already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/0_User_Input/backgrounds already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/0_User_Input/objects already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/1_Preprocessing already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/1_Preprocessing/images already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/protoc already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/scripts already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training/annotations already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training/images/training already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training/images/testing already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training/models already exists..\n",
      "/Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/workspace/training/pre_trained_models already exists..\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with paths to most used directories\n",
    "paths = {\n",
    "    '0_User_Input': os.path.join(home_path,'0_User_Input'),\n",
    "    'backgrounds': os.path.join(home_path,'0_User_Input/backgrounds'),\n",
    "    'objects': os.path.join(home_path,'0_User_Input/objects'),\n",
    "\n",
    "    '1_Preprocessing': os.path.join(home_path,'1_Preprocessing'),\n",
    "    'images': os.path.join(home_path,'1_Preprocessing/images'),\n",
    "\n",
    "    '2_Tensorflow': os.path.join(home_path,'2_Tensorflow'),\n",
    "    'protoc': os.path.join(home_path,'2_Tensorflow/protoc'),\n",
    "    'workspace': os.path.join(home_path,'2_Tensorflow/workspace'),\n",
    "    'scripts': os.path.join(home_path,'2_Tensorflow/workspace/scripts'),   \n",
    "    'training': os.path.join(home_path,'2_Tensorflow/workspace/training'),\n",
    "    'annotations': os.path.join(home_path,'2_Tensorflow/workspace/training/annotations'),\n",
    "    'images_training': os.path.join(home_path,'2_Tensorflow/workspace/training/images/training'),\n",
    "    'images_testing': os.path.join(home_path,'2_Tensorflow/workspace/training/images/testing'),\n",
    "    'models': os.path.join(home_path,'2_Tensorflow/workspace/training/models'),\n",
    "    'pre_trained_models': os.path.join(home_path,'2_Tensorflow/workspace/training/pre_trained_models'),\n",
    "}\n",
    "\n",
    "# Create folder structure from dictionary\n",
    "for key in paths:\n",
    "    \n",
    "    # If path does not exist, create new\n",
    "    if os.path.exists(paths[key]) is False:\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(paths[key])\n",
    "        except OSError:\n",
    "            print('Failed to create %s from scratch.' % paths[key])\n",
    "        else:\n",
    "            print ('Successfully created %s from scratch. ' % paths[key])        \n",
    "        \n",
    "    # If path does exist, do not replace old path\n",
    "    else:        \n",
    "        print('%s already exists..' %paths[key])\n",
    "\n",
    "# Create subfolders for labels\n",
    "for label in labels:\n",
    "  temp_path_prep = os.path.join(paths['images'], label)\n",
    "  \n",
    "  if os.path.exists(temp_path_prep) is False:\n",
    "    try:\n",
    "        os.makedirs(temp_path_prep)\n",
    "    except OSError:\n",
    "        print('Failed to create %s from scratch.' % temp_path_prep)\n",
    "    else:\n",
    "        print ('Successfully created %s from scratch. ' % temp_path_prep)\n",
    "\n",
    "# Create dictionary with paths to most used files\n",
    "files = {}\n",
    "       \n",
    "paths['home'] = home_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6bd0a",
   "metadata": {
    "id": "44d6bd0a"
   },
   "source": [
    "## 1.3 Installing Dependencies and importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e42ecf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e42ecf9",
    "outputId": "de36b360-8ed6-43ae-88a8-dc9d290f06c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (46.4 MB)\n",
      "Collecting numpy>=1.19.3\n",
      "  Using cached numpy-1.23.0-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.23.0 opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python -y\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01564f7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01564f7e",
    "outputId": "adb52bcc-cd72-4d63-d3d2-16d209be33b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4bb5647",
   "metadata": {
    "id": "f4bb5647"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Import uuid (module that allows us to name images uniquely)\n",
    "import uuid\n",
    "\n",
    "import time\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# Overwrite old folders and move directories\n",
    "import shutil\n",
    "\n",
    "import math\n",
    "\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe26b5",
   "metadata": {
    "id": "6dfe26b5"
   },
   "source": [
    "# 2. User action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d5cc3da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d5cc3da",
    "outputId": "790989ce-716e-45d6-edca-8b24fd36952d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check whether the correct number of images is displayed:...\n",
      "{'backgrounds': 0}\n"
     ]
    }
   ],
   "source": [
    "# Check if images are located in the correct folders\n",
    "folders = os.listdir(paths['objects'])\n",
    "image_count = {}\n",
    "print('Please check whether the correct number of images is displayed:...')\n",
    "\n",
    "for folder in folders:\n",
    "    if folder in labels:\n",
    "        path = os.listdir(paths['objects']+'/'+folder)\n",
    "        image_count[folder] = len(path)\n",
    "        \n",
    "image_count['backgrounds'] = len(os.listdir(paths['backgrounds']))\n",
    "\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520241f2",
   "metadata": {
    "id": "520241f2"
   },
   "source": [
    "# 3. Prepare Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900ebb",
   "metadata": {
    "id": "2d900ebb"
   },
   "source": [
    "## 3.1 Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7923f0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a7923f0c",
    "outputId": "fcd120f6-9395-4a72-8676-856fdf9aed8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.5.0\n",
      "  Using cached tensorflow-2.5.0-cp39-cp39-macosx_10_11_x86_64.whl (195.7 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp39-cp39-macosx_10_9_x86_64.whl\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp39-cp39-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Using cached grpcio-1.34.1-cp39-cp39-macosx_10_10_x86_64.whl (3.7 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-4.21.2-cp37-abi3-macosx_10_9_universal2.whl (483 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-macosx_10_9_x86_64.whl (961 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.9.0-py2.py3-none-any.whl (167 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (56.0.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pyasn1, keras-nightly, flatbuffers, zipp, wheel, werkzeug, urllib3, tensorboard-data-server, six, rsa, pyasn1-modules, protobuf, oauthlib, numpy, idna, gast, charset-normalizer, certifi, cachetools, requests, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, absl-py, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.0\n",
      "    Uninstalling numpy-1.23.0:\n",
      "      Successfully uninstalled numpy-1.23.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.1.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-3.3 importlib-metadata-4.12.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.19.5 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.8 six-1.15.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.9 werkzeug-2.1.2 wheel-0.37.1 wrapt-1.12.1 zipp-3.8.0\n"
     ]
    }
   ],
   "source": [
    "# Local machine\n",
    "if system_id == 0:\n",
    "    !pip install tensorflow==2.5.0\n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    !pip install tensorflow-gpu==2.5.0 \n",
    "\n",
    "else:\n",
    "    print('No operating system was defined...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16c0b45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e16c0b45",
    "outputId": "e240c1bd-8dc1-40f1-ddc9-303515b16d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model garden already exists\n"
     ]
    }
   ],
   "source": [
    "# Download the model garden (model garden is an environment that is necessary to train new models from scratch or to continue training existing models)\n",
    "# The model itself will be downloaded later\n",
    "\n",
    "# Clone repository only if it does not exist already\n",
    "os.chdir(paths['2_Tensorflow'])\n",
    "if os.path.exists(paths['2_Tensorflow']+'/models/research') is False:\n",
    "    print('Cloning model garden..')\n",
    "    !git clone https://github.com/tensorflow/models.git\n",
    "    \n",
    "else:\n",
    "    print('Model garden already exists')\n",
    "\n",
    "paths['research'] = paths['2_Tensorflow']+'/models/research'\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6592a9",
   "metadata": {
    "id": "1c6592a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protobuf was already installed...\n"
     ]
    }
   ],
   "source": [
    "# Install protobuf\n",
    "\n",
    "if os.path.exists(paths['2_Tensorflow']+'/protoc/protoc-21.1-osx-aarch_64.zip') is False:\n",
    "\n",
    "    # Go to destination directory\n",
    "    os.chdir(paths['protoc'])\n",
    "    protoc_url = 'https://github.com/protocolbuffers/protobuf/releases/download/v21.1/protoc-21.1-osx-aarch_64.zip'\n",
    "    wget.download(protoc_url)\n",
    "\n",
    "    # Extract all content of downloaded file\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    with ZipFile('protoc-21.1-osx-aarch_64.zip', 'r') as zipObj:\n",
    "        zipObj.extractall()\n",
    "\n",
    "    os.environ['Path'] = paths['protoc']+'/bin'\n",
    "    os.chdir(paths['research'])\n",
    "\n",
    "    !protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "\n",
    "else:\n",
    "    print('Protobuf was already installed...')\n",
    "    \n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06ec3dc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06ec3dc7",
    "outputId": "82d27f11-2d20-4709-aa7d-fff013ec977f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocoapi already exists\n"
     ]
    }
   ],
   "source": [
    "# Install pycocotools\n",
    "\n",
    "# Clone repository only if it does not exist already\n",
    "if os.path.exists(paths['research']+'/cocoapi') is False:\n",
    "    print('Cloning cocoapi..')\n",
    "    !git clone https://github.com/cocodataset/cocoapi.git\n",
    "    \n",
    "    # Moving cloned file to 'research' folder\n",
    "    destination = paths['research']\n",
    "    source = paths['home']+'/cocoapi'\n",
    "    shutil.move(source, destination)\n",
    "    \n",
    "else:\n",
    "    print('Cocoapi already exists')\n",
    "\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70c4aa",
   "metadata": {
    "id": "fe70c4aa"
   },
   "source": [
    "## 3.2 Install Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2d18cae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2d18cae",
    "outputId": "c7b66146-d5ce-4f8d-e291-53dcdadd8fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing setup.py...\n",
      "Processing /Users/niklas/Virtual_Environment/Version_1/Object_Detection/2_Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3\n",
      "  Using cached avro_python3-1.10.2-py3-none-any.whl\n",
      "Collecting apache-beam\n",
      "  Using cached apache_beam-2.40.0-cp39-cp39-macosx_10_9_x86_64.whl (4.7 MB)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.2.0-cp39-cp39-macosx_10_10_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml\n",
      "  Downloading lxml-4.9.1-cp39-cp39-macosx_10_15_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp39-cp39-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "Collecting Cython\n",
      "  Using cached Cython-0.29.30-py2.py3-none-any.whl (985 kB)\n",
      "Collecting contextlib2\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: six in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.4-cp39-cp39-macosx_10_9_x86_64.whl\n",
      "Collecting lvis\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.8.1-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.6 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.3-cp39-cp39-macosx_10_9_x86_64.whl (11.5 MB)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Using cached tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "Collecting tensorflow_io\n",
      "  Using cached tensorflow_io-0.26.0-cp39-cp39-macosx_10_14_x86_64.whl (24.6 MB)\n",
      "Collecting keras\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Collecting pyyaml<6.0,>=5.1\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-macosx_10_9_x86_64.whl (259 kB)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py_cpuinfo-8.0.0-py3-none-any.whl\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp39-cp39-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (46.4 MB)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "Collecting tensorflow-hub>=0.6.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Using cached tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Collecting tensorflow-addons\n",
      "  Using cached tensorflow_addons-0.17.1-cp39-cp39-macosx_10_15_x86_64.whl (588 kB)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.23.0-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Using cached google_api_python_client-2.52.0-py2.py3-none-any.whl (8.7 MB)\n",
      "Collecting oauth2client\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting tensorflow-text~=2.9.0\n",
      "  Using cached tensorflow_text-2.9.0-cp39-cp39-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "Collecting tensorflow~=2.9.0\n",
      "  Using cached tensorflow-2.9.1-cp39-cp39-macosx_10_14_x86_64.whl (228.5 MB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tf-slim->object-detection==0.1) (0.15.0)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Using cached crcmod-1.7-cp39-cp39-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Using cached pymongo-3.12.3-cp39-cp39-macosx_10_9_x86_64.whl (395 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Collecting fastavro<2,>=0.23.6\n",
      "  Using cached fastavro-1.5.2-cp39-cp39-macosx_10_15_x86_64.whl (506 kB)\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Using cached proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
      "Collecting pyarrow<8.0.0,>=0.15.1\n",
      "  Using cached pyarrow-7.0.0-cp39-cp39-macosx_10_13_x86_64.whl (20.2 MB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Using cached dill-0.3.1.1-py3-none-any.whl\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Using cached hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.28.1)\n",
      "Requirement already satisfied: grpcio<2,>=1.33.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
      "Collecting httplib2<0.21.0,>=0.8\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Collecting cloudpickle<3,>=2.1.0\n",
      "  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.6-cp39-cp39-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (447 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0.25 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
      "Collecting cycler>=0.10.0\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.1.0\n",
      "  Using cached kiwisolver-1.4.3-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.26.0\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Using cached google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Collecting docopt\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting python-slugify\n",
      "  Using cached python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: certifi in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
      "Requirement already satisfied: urllib3 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: setuptools in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (56.0.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Collecting absl-py>=0.2.2\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Using cached dm_tree-0.1.7-cp39-cp39-macosx_10_9_x86_64.whl (109 kB)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2022.6.2-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Using cached scikit_learn-1.1.1-cp39-cp39-macosx_10_13_x86_64.whl (8.6 MB)\n",
      "Collecting typeguard>=2.7\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
      "Collecting etils[epath]\n",
      "  Using cached etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting toml\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Collecting importlib_resources\n",
      "  Using cached importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: zipp in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1661540 sha256=0fc9c2806e4e469ed2a687bcb59bcf2186ae9707c238c405dc244a2121ad8beb\n",
      "  Stored in directory: /private/var/folders/hd/gz2v7mz153nbydn703wyfm140000gn/T/pip-ephem-wheel-cache-1guc544w/wheels/a5/79/73/1dcefe479d60ac65edd608e4aafeb6301a11cd19863e4d835c\n",
      "Successfully built object-detection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: text-unidecode, sentencepiece, pytz, py-cpuinfo, libclang, keras, gin-config, docopt, dm-tree, crcmod, uritemplate, typeguard, tqdm, toml, threadpoolctl, tensorflow-io-gcs-filesystem, tensorflow-estimator, tabulate, regex, pyyaml, python-slugify, pyparsing, pymongo, proto-plus, promise, portalocker, pillow, orjson, numpy, lxml, kiwisolver, joblib, importlib_resources, googleapis-common-protos, fonttools, fastavro, etils, dill, Cython, cycler, contextlib2, colorama, cloudpickle, avro-python3, absl-py, tf-slim, tensorflow-model-optimization, tensorflow-metadata, tensorflow_io, tensorflow-hub, scipy, sacrebleu, pydot, pyarrow, pandas, opencv-python-headless, kaggle, httplib2, hdfs, tensorflow-addons, scikit-learn, oauth2client, matplotlib, google-auth-httplib2, google-api-core, apache-beam, tensorflow-datasets, seqeval, pycocotools, lvis, google-api-python-client, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed Cython-0.29.30 absl-py-1.1.0 apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.1.1 dm-tree-0.1.7 docopt-0.6.2 etils-0.6.0 fastavro-1.5.2 fonttools-4.33.3 gin-config-0.5.0 google-api-core-2.8.2 google-api-python-client-2.52.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.56.3 hdfs-2.7.0 httplib2-0.20.4 importlib_resources-5.8.0 joblib-1.1.0 kaggle-1.5.12 keras-2.9.0 kiwisolver-1.4.3 libclang-14.0.1 lvis-0.5.3 lxml-4.9.1 matplotlib-3.5.2 numpy-1.22.4 oauth2client-4.1.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.6 pandas-1.4.3 pillow-9.2.0 portalocker-2.4.0 promise-2.3 proto-plus-1.20.6 py-cpuinfo-8.0.0 pyarrow-7.0.0 pycocotools-2.0.4 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 python-slugify-6.1.2 pytz-2022.1 pyyaml-5.4.1 regex-2022.6.2 sacrebleu-2.1.0 scikit-learn-1.1.1 scipy-1.8.1 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.10 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflow-metadata-1.9.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 tensorflow_io-0.26.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.64.0 typeguard-2.13.3 uritemplate-4.1.1\n",
      "Installation complete..\n"
     ]
    }
   ],
   "source": [
    "# Check if API has already been installed\n",
    "if os.path.exists(paths['research']+'/setup.py') is False:\n",
    "    print('Installing setup.py...')\n",
    "    \n",
    "    # Move to 'research' directory\n",
    "    os.chdir(paths['research'])\n",
    "\n",
    "    # Copy setup.py to current working directory\n",
    "    !cp object_detection/packages/tf2/setup.py .\n",
    "\n",
    "    # Execute setup.py (this command installs all dependencies needed for tf2 odapi)\n",
    "    !python -m pip install .\n",
    "\n",
    "    print('Installation complete..')\n",
    "\n",
    "else:\n",
    "    print('Object Detection API has already been installed')\n",
    "\n",
    "# Move back to home-directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00f3be",
   "metadata": {
    "id": "9a00f3be"
   },
   "source": [
    "## 3.3 Check if API was installed successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70dfbfba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70dfbfba",
    "outputId": "311eb50e-9624-41ab-c989-a4dd9d89798d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.9.6: /Users/niklas/Virtual_Environment/Version_1/joshBak2/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-07-04 07:38:21.602647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/niklas/Virtual_Environment/Version_1/joshBak2/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1102: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0704 07:38:22.238353 4620293632 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.98s\n",
      "I0704 07:38:22.559390 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.98s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.96s\n",
      "I0704 07:38:23.517618 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.96s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
      "I0704 07:38:23.860682 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.44s\n",
      "I0704 07:38:24.300992 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.44s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.94s\n",
      "I0704 07:38:27.244423 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.94s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0704 07:38:27.246524 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "I0704 07:38:27.291589 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I0704 07:38:27.314232 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.09s\n",
      "I0704 07:38:27.404382 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.49s\n",
      "I0704 07:38:27.898894 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.49s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.41s\n",
      "I0704 07:38:28.306921 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.41s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.29s\n",
      "I0704 07:38:28.597112 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.29s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "I0704 07:38:28.723217 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.19s\n",
      "I0704 07:38:28.917861 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.06s\n",
      "I0704 07:38:28.980816 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0704 07:38:29.239042 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0704 07:38:29.239289 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0704 07:38:29.239833 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0704 07:38:29.243974 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:29.271665 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:29.271793 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:29.355825 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:29.356064 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:29.553926 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:29.554067 4620293632 efficientnet_model.py:143] round_filter input=40 output=40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0704 07:38:29.735615 4620293632 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0704 07:38:29.735800 4620293632 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0704 07:38:30.190960 4620293632 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0704 07:38:30.191088 4620293632 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0704 07:38:30.470999 4620293632 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0704 07:38:30.471130 4620293632 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0704 07:38:30.990633 4620293632 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0704 07:38:30.990766 4620293632 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0704 07:38:31.093255 4620293632 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0704 07:38:31.162914 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:38:31.239610 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0704 07:38:31.239749 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0704 07:38:31.239809 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0704 07:38:31.241541 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:31.262746 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:31.262863 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:31.512566 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:31.512698 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:31.805450 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:31.805665 4620293632 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0704 07:38:32.112857 4620293632 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0704 07:38:32.112988 4620293632 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0704 07:38:32.460882 4620293632 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0704 07:38:32.461010 4620293632 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0704 07:38:32.920022 4620293632 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0704 07:38:32.920156 4620293632 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0704 07:38:33.480556 4620293632 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0704 07:38:33.480690 4620293632 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0704 07:38:34.139374 4620293632 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0704 07:38:34.477296 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:38:35.023449 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0704 07:38:35.023825 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0704 07:38:35.024214 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0704 07:38:35.026502 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:35.218106 4620293632 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0704 07:38:35.220268 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:36.344846 4620293632 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0704 07:38:36.344974 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:37.990341 4620293632 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0704 07:38:37.990695 4620293632 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0704 07:38:39.494832 4620293632 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0704 07:38:39.494992 4620293632 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0704 07:38:40.931133 4620293632 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0704 07:38:40.931824 4620293632 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0704 07:38:41.779474 4620293632 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0704 07:38:41.779603 4620293632 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0704 07:38:42.767866 4620293632 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0704 07:38:42.768146 4620293632 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0704 07:38:43.018811 4620293632 efficientnet_model.py:143] round_filter input=1280 output=1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0704 07:38:43.104254 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:38:43.225333 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0704 07:38:43.225466 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0704 07:38:43.225523 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0704 07:38:43.227651 4620293632 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0704 07:38:43.242722 4620293632 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0704 07:38:43.242837 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:43.379703 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:43.380676 4620293632 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0704 07:38:43.687472 4620293632 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0704 07:38:43.687597 4620293632 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0704 07:38:44.003265 4620293632 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0704 07:38:44.003405 4620293632 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0704 07:38:44.559960 4620293632 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0704 07:38:44.560090 4620293632 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0704 07:38:45.082814 4620293632 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0704 07:38:45.082949 4620293632 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0704 07:38:45.789372 4620293632 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0704 07:38:45.789505 4620293632 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0704 07:38:46.092058 4620293632 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0704 07:38:46.151651 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:38:46.230918 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0704 07:38:46.231102 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0704 07:38:46.231168 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0704 07:38:46.234195 4620293632 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0704 07:38:46.252420 4620293632 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0704 07:38:46.252538 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:46.395720 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:46.395848 4620293632 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0704 07:38:46.774500 4620293632 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0704 07:38:46.774631 4620293632 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0704 07:38:47.154579 4620293632 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0704 07:38:47.154714 4620293632 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0704 07:38:47.891968 4620293632 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0704 07:38:47.892172 4620293632 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0704 07:38:48.662757 4620293632 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0704 07:38:48.662889 4620293632 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0704 07:38:49.621381 4620293632 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0704 07:38:49.621510 4620293632 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0704 07:38:50.020083 4620293632 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0704 07:38:50.107866 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0704 07:38:50.633527 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0704 07:38:50.634283 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0704 07:38:50.635155 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0704 07:38:50.638129 4620293632 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0704 07:38:50.657358 4620293632 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0704 07:38:50.657554 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:50.925000 4620293632 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0704 07:38:50.925135 4620293632 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0704 07:38:51.597238 4620293632 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0704 07:38:51.597455 4620293632 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0704 07:38:52.101858 4620293632 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0704 07:38:52.101992 4620293632 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0704 07:38:53.042021 4620293632 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0704 07:38:53.042618 4620293632 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0704 07:38:54.157568 4620293632 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0704 07:38:54.157700 4620293632 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0704 07:38:55.556613 4620293632 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0704 07:38:55.556745 4620293632 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0704 07:38:56.113146 4620293632 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0704 07:38:56.239577 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:38:56.377189 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0704 07:38:56.377325 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0704 07:38:56.377383 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0704 07:38:56.380026 4620293632 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0704 07:38:56.409766 4620293632 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0704 07:38:56.410026 4620293632 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0704 07:38:56.763624 4620293632 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0704 07:38:56.763782 4620293632 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0704 07:38:57.423959 4620293632 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0704 07:38:57.424087 4620293632 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0704 07:38:58.123953 4620293632 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0704 07:38:58.124094 4620293632 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0704 07:38:58.989893 4620293632 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0704 07:38:58.990058 4620293632 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0704 07:39:00.216600 4620293632 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0704 07:39:00.217003 4620293632 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0704 07:39:02.169805 4620293632 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0704 07:39:02.170114 4620293632 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0704 07:39:02.655925 4620293632 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0704 07:39:02.748687 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0704 07:39:02.893859 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0704 07:39:02.893994 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0704 07:39:02.894052 4620293632 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0704 07:39:02.896287 4620293632 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0704 07:39:02.912518 4620293632 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0704 07:39:02.912635 4620293632 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0704 07:39:03.193513 4620293632 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0704 07:39:03.193683 4620293632 efficientnet_model.py:143] round_filter input=24 output=48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0704 07:39:03.954707 4620293632 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0704 07:39:03.954905 4620293632 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0704 07:39:04.718446 4620293632 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0704 07:39:04.718583 4620293632 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0704 07:39:06.260586 4620293632 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0704 07:39:06.260718 4620293632 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0704 07:39:07.476800 4620293632 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0704 07:39:07.477296 4620293632 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0704 07:39:10.540776 4620293632 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0704 07:39:10.540970 4620293632 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0704 07:39:11.566021 4620293632 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0704 07:39:11.713286 4620293632 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 42.95s\n",
      "I0704 07:39:11.931565 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 42.95s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0704 07:39:11.941340 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0704 07:39:11.944149 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0704 07:39:11.945594 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0704 07:39:11.947686 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0704 07:39:11.949373 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0704 07:39:11.949800 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0704 07:39:11.951018 4620293632 test_util.py:2458] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 50.369s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# Move to 'research' directory\n",
    "os.chdir(paths['research'])\n",
    "import object_detection\n",
    "\n",
    "# Local machine\n",
    "if system_id == 0:\n",
    "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
    "    \n",
    "\n",
    "# Google colab    \n",
    "elif system_id == 1:\n",
    "    !pip install numpy --upgrade # This had to be added for execution on colab. Problem solved using stackoverflow\n",
    "\n",
    "    # Open file for testing (unforunately it does not work when using paths[research])\n",
    "    #testfile_path = '/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py'\n",
    "    #!python {testfile_path}\n",
    "    !python {paths['research']+'/object_detection/builders/model_builder_tf2_test.py'}\n",
    "else:\n",
    "    print('No operating system was defined...')\n",
    "\n",
    "# Move back to home directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006de28",
   "metadata": {
    "id": "0006de28"
   },
   "source": [
    "# 4. Prepare new training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441180b",
   "metadata": {
    "id": "e441180b"
   },
   "source": [
    "## 4.1 Install dependencies and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a4556e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57a4556e",
    "outputId": "140e6ead-ecfb-4e31-ca54-dbdbe76251cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
     ]
    }
   ],
   "source": [
    "## Install missing modules for randomTrafficSign\n",
    "!pip install matplotlib\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f8a44b",
   "metadata": {
    "id": "d4f8a44b"
   },
   "outputs": [],
   "source": [
    "os.chdir(paths['0_User_Input']+'/scripts')\n",
    "import randomTrafficSign as ts\n",
    "\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "from xml.etree.ElementTree import Element\n",
    "import xml.etree.ElementTree as etree\n",
    "import xml.dom.minidom\n",
    "\n",
    "from lxml import etree\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Pdds-tn9A7Ho",
   "metadata": {
    "id": "Pdds-tn9A7Ho"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XxrqC-lQ7IXF",
   "metadata": {
    "id": "XxrqC-lQ7IXF"
   },
   "source": [
    "## 4.2 Partition images for testing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KYPtSyTxziNo",
   "metadata": {
    "id": "KYPtSyTxziNo"
   },
   "source": [
    "**Important**: Images of objects must be in the following format: \"Mug_1.jpg\", \"Cat_3.jpg\" and must be located in their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sapVybbT3jYk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sapVybbT3jYk",
    "outputId": "5842c2de-a588-4668-9af8-09e97dc48919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file called .DS_Store found in array\n",
      "Working on image: 1(Pen)\n",
      "Working on image: 2(Pen)\n",
      "Working on image: 3(Pen)\n",
      "Working on image: 4(Pen)\n",
      "Created 200 images for label Pen\n",
      "Label: Pen, total: 200, testing: 30, training: 170\n",
      "Random numbers: \n",
      "[128, 188, 55, 81, 32, 106, 34, 98, 135, 61, 42, 1, 49, 6, 32, 152, 41, 162, 157, 140, 144, 146, 63, 105, 60, 163, 155, 73, 60, 127, 86, 16, 44, 34, 159, 71, 19, 162, 10, 33, 0, 45, 145, 37, 101, 114, 116, 109, 86, 16, 123, 52, 71, 20, 76, 96, 8, 117, 4, 108, 6, 27, 124, 111, 22, 119, 67, 11, 52, 36, 0, 43, 17, 13, 123, 87, 8, 77, 5, 54, 54, 85, 57, 67, 108, 36, 70, 45, 10, 9, 87, 14, 89, 9, 20, 104, 95, 95, 8, 58, 80, 51, 70, 49, 35, 61, 0, 27, 87, 13, 4, 26, 2, 26, 63, 38, 58, 36, 27, 24, 60, 34, 62, 42, 5, 64, 1, 43, 8, 49, 8, 4, 24, 42, 51, 61, 28, 41, 55, 3, 49, 23, 27, 51, 41, 45, 33, 47, 50, 12, 28, 5, 10, 30, 44, 43, 13, 14, 17, 31, 15, 31, 36, 2, 8, 29, 2, 17, 23, 3]\n",
      "Copied 170 images to training folder\n",
      "Random numbers: \n",
      "[0, 4, 3, 17, 16, 22, 0, 12, 15, 20, 18, 12, 2, 10, 5, 5, 12, 7, 4, 4, 3, 4, 5, 6, 4, 3, 0, 1, 0, 0]\n",
      "Copied 30 images to testing folder\n",
      "No file called .DS_Store found in array\n",
      "Working on image: 1(Mug)\n",
      "Working on image: 2(Mug)\n",
      "Working on image: 3(Mug)\n",
      "Created 150 images for label Mug\n",
      "Label: Mug, total: 150, testing: 24, training: 126\n",
      "Random numbers: \n",
      "[104, 80, 144, 86, 86, 133, 72, 35, 11, 125, 136, 9, 71, 2, 67, 114, 13, 83, 98, 53, 63, 66, 7, 17, 70, 47, 59, 67, 74, 106, 72, 110, 10, 70, 82, 111, 109, 22, 57, 40, 38, 87, 80, 73, 19, 60, 23, 11, 39, 77, 52, 1, 86, 58, 3, 92, 91, 41, 30, 67, 40, 88, 20, 65, 19, 77, 68, 19, 66, 53, 30, 51, 48, 41, 53, 70, 67, 43, 23, 13, 6, 39, 13, 29, 63, 61, 0, 0, 16, 44, 47, 26, 19, 50, 21, 14, 33, 24, 39, 4, 21, 32, 46, 30, 20, 34, 20, 40, 5, 3, 39, 2, 4, 22, 12, 33, 25, 25, 4, 2, 17, 14, 5, 16, 5, 15]\n",
      "Copied 126 images to training folder\n",
      "Random numbers: \n",
      "[9, 7, 18, 18, 11, 10, 7, 5, 0, 5, 12, 1, 1, 0, 6, 6, 2, 6, 4, 0, 2, 0, 0, 0]\n",
      "Copied 24 images to testing folder\n"
     ]
    }
   ],
   "source": [
    "factor_n = 50\n",
    "\n",
    "for label in labels:\n",
    "    folders = os.listdir(paths['objects'])\n",
    "    \n",
    "    ## Multiply each image per label by factor_n, create an xml file and move to preprocessing folder\n",
    "    # Only consider folders that correspond to current labels, disregard old labels\n",
    "    if label in folders:\n",
    "        sub_folder = os.listdir(paths['objects']+'/'+str(label))\n",
    "        \n",
    "        # Loop through subfolder and delete .ds_store files\n",
    "        try:\n",
    "            sub_folder.remove('.DS_Store')\n",
    "        except:\n",
    "            print('No file called .DS_Store found in array')\n",
    "          \n",
    "        # Multiply image and create xml file\n",
    "        all_items = []\n",
    "        path_object = paths['objects']+'/'+label\n",
    "        path_save = paths['images']+'/'+label+'/'\n",
    "        ts.main(img_size, all_items, paths['backgrounds'],path_object, factor_n, 50, 20, save_folder=path_save)\n",
    "        # first argument: Path to backgrounds folder\n",
    "        # second argument: Path to object images folder\n",
    "        # third argument: Number of images to be created for each object image\n",
    "        # fourth argument: upperScale\n",
    "        # fifth argument: lowerScale\n",
    "        # sixth argument: folder where all images are to be saved\n",
    "        # last: dictionary including all jpg and xml filenames for the current label\n",
    "\n",
    "        # Count number of images in each label folder\n",
    "        n_items = len(all_items)\n",
    "\n",
    "        # Use 15% of the images for testing, 85% for training\n",
    "        n_testing = 2*(math.ceil(0.5*0.15*n_items))\n",
    "    \n",
    "        n_training = n_items - n_testing\n",
    "        print('Label: '+str(label)+', total: '+str(n_items)+', testing: '+str(n_testing)+', training: '+str(n_training))      \n",
    "              \n",
    "        # Parition images for training and testing in a random order\n",
    "        \n",
    "        # Training\n",
    "        count = 0\n",
    "        number_history = []\n",
    "        for i in range(n_training):\n",
    "          randnum = np.random.randint(len(all_items))\n",
    "          number_history.append(randnum)\n",
    "          source_jpg = all_items[randnum][0]\n",
    "          source_xml = all_items[randnum][1]\n",
    "          #print('Copying image\" '+str(source_jpg)+'\" to training folder')\n",
    "          \n",
    "          # Ignore hidden files, such as .ds_store\n",
    "          if not (all_items[randnum][0].startswith('.') or all_items[randnum][1].startswith('.')) :\n",
    "              shutil.copy(source_jpg, paths['images_training'])\n",
    "              shutil.copy(source_xml, paths['images_training'])\n",
    "              all_items.pop(randnum)\n",
    "              count +=1\n",
    "        print('Random numbers: ')\n",
    "        print(number_history)\n",
    "        print('Copied '+str(count)+' images to training folder')       \n",
    "\n",
    "        # Testing\n",
    "        count = 0\n",
    "        number_history = []\n",
    "        for i in range(n_testing):\n",
    "          randnum = np.random.randint(len(all_items))\n",
    "          number_history.append(randnum)\n",
    "          source_jpg = all_items[randnum][0]\n",
    "          source_xml = all_items[randnum][1]\n",
    "          #print('Copying image\" '+str(source_jpg)+'\" to testing folder')\n",
    "          \n",
    "          # Ignore hidden files, such as .ds_store\n",
    "          if not (all_items[randnum][0].startswith('.') or all_items[randnum][1].startswith('.')) :\n",
    "              shutil.copy(source_jpg, paths['images_testing'])\n",
    "              shutil.copy(source_xml, paths['images_testing'])\n",
    "              all_items.pop(randnum)\n",
    "              count +=1\n",
    "        print('Random numbers: ')\n",
    "        print(number_history)\n",
    "        print('Copied '+str(count)+' images to testing folder')     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a93934",
   "metadata": {
    "id": "11a93934"
   },
   "source": [
    "## 5.4 Create labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e44434",
   "metadata": {
    "id": "c6e44434"
   },
   "outputs": [],
   "source": [
    "files['labelmap'] = paths['annotations']+'/label_map.pbtxt'\n",
    "\n",
    "with open(files['labelmap'], 'w') as file:\n",
    "    for label in labelmap:\n",
    "        file.write('item { \\n')\n",
    "        file.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        file.write('\\tid:{}\\n'.format(label['id']))\n",
    "        file.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42670147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42670147",
    "outputId": "be270cb8-4854-47a6-e534-db892710a084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Install pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe07d6",
   "metadata": {
    "id": "edbe07d6"
   },
   "source": [
    "## 5.5 Create TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3668f3c2",
   "metadata": {
    "id": "3668f3c2"
   },
   "outputs": [],
   "source": [
    "# Add labelmap and tfrecords to 'files' dictionary\n",
    "files['tf_train'] = paths['annotations']+'/train.record'\n",
    "files['tf_test'] = paths['annotations']+'/test.record'\n",
    "\n",
    "# Add line to download TF record file from nicknochnack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8dd7c55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8dd7c55",
    "outputId": "c6408612-feff-41f5-91e3-0cf8af560e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record\n",
      "Successfully created the TFRecord file: /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "# Copy generatetfrecord.py to scripts\n",
    "source = paths['0_User_Input']+'/scripts/generatetfrecord.py'\n",
    "shutil.copy(source, paths['scripts'])\n",
    "\n",
    "# Change directory to 'scripts'\n",
    "os.chdir(paths['workspace']+'/scripts')\n",
    "\n",
    "# Create / overwrite TFRecord files for training and testing\n",
    "\n",
    "# Create train data:\n",
    "!python generatetfrecord.py -x {paths['images_training']} -l {files['labelmap']} -o {files['tf_train']}\n",
    "\n",
    "# Create test data:\n",
    "!python generatetfrecord.py -x {paths['images_testing']} -l {files['labelmap']} -o {files['tf_test']}\n",
    "\n",
    "# Go back to home directory\n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b339fe9",
   "metadata": {
    "id": "3b339fe9"
   },
   "source": [
    "## 5.6 Download pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44cd98fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44cd98fc",
    "outputId": "ebb2fd54-9ac7-48ff-a8d0-95fb55269d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was successfully downloaded...\n"
     ]
    }
   ],
   "source": [
    "# Update the settings for the image import and multiplication script depending on which size of image the model uses!\n",
    "\n",
    "# Check if the chosen model has already been downloaded\n",
    "if os.path.exists(paths['pre_trained_models']+'/'+str(pre_trained_model_name)) is False:\n",
    "\n",
    "    # Go to destination directory\n",
    "    os.chdir(paths['pre_trained_models'])\n",
    "    wget.download(pre_trained_model_url)\n",
    "\n",
    "    # Extract all content of downloaded file\n",
    "    import tarfile\n",
    "\n",
    "    file = tarfile.open('ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz')\n",
    "\n",
    "    file.extractall(paths['pre_trained_models'])\n",
    "\n",
    "    file.close()\n",
    "                  \n",
    "    # Delete downloaded tar.gz file to save storage space\n",
    "    # Add code here\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    # Create new folder for this model in training/models\n",
    "    paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "    os.makedirs(paths['active_model'])\n",
    "    \n",
    "    print('Model was successfully downloaded...')\n",
    "\n",
    "\n",
    "else:\n",
    "    print(str(pre_trained_model_name)+' was already installed...')\n",
    "    \n",
    "os.chdir(paths['home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d8741",
   "metadata": {
    "id": "5d9d8741"
   },
   "source": [
    "## 5.7 Update the config file and pipeline for the new training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3f7e2a",
   "metadata": {
    "id": "ae3f7e2a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "256fe75d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "256fe75d",
    "outputId": "7797cc68-a21d-4c48-fb2c-7ef855468788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline replaced in active model directory...\n",
      "Pipeline successfully configured...\n"
     ]
    }
   ],
   "source": [
    "## Copy or replace pipeline in active model directory\n",
    "files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config'\n",
    "paths['active_model'] = paths['models']+'/'+custom_model_name\n",
    "files['pipeline_active'] = paths['active_model']+'/pipeline.config'\n",
    "paths['downloaded_model'] = paths['pre_trained_models']+'/'+pre_trained_model_name\n",
    "\n",
    "# If pipeline already exists in active directory, replace it\n",
    "if os.path.exists(files['pipeline_active']) == True:\n",
    "    os.remove(files['pipeline_active'])\n",
    "    shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "    print('Pipeline replaced in active model directory...')\n",
    "\n",
    "# If pipeline does not yet exist in active directory, copy it from downloaded model\n",
    "else:\n",
    "    files['pipeline_downloaded'] = paths['pre_trained_models']+'/'+pre_trained_model_name+'/pipeline.config' \n",
    "    shutil.copy(files['pipeline_downloaded'], paths['active_model'])\n",
    "    print('Pipeline copied to active model directory...')\n",
    "\n",
    "## Configure pipeline\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(files['pipeline_active'])\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['pipeline_active'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  \n",
    "\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = len(labels) # Number of labels the model should be trained for\n",
    "pipeline_config.train_config.batch_size = 4 # This should be the number of training jobs that run parallel\n",
    "\n",
    "# Get checkpoint 0 from (original) downloaded model \n",
    "files['checkpoint0'] = paths['downloaded_model']+'/checkpoint/ckpt-0'\n",
    "\n",
    "pipeline_config.train_config.fine_tune_checkpoint = files['checkpoint0']\n",
    "\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "\n",
    "# Get labelmap\n",
    "pipeline_config.train_input_reader.label_map_path= files['labelmap']\n",
    "\n",
    "# Get TF-Record\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [files['tf_train']]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['labelmap']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [files['tf_test']]\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "\n",
    "# Update active pipeline\n",
    "with tf.io.gfile.GFile(files['pipeline_active'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   \n",
    "    \n",
    "print('Pipeline successfully configured...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e7ed75d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8e7ed75d",
    "outputId": "894f8c2e-7126-4c34-e092-28d2dac21e35"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy model_main_tf2.py to workspace -> training   'TensorFlow/models/research/' file to \n",
    "source = paths['research']+'/object_detection/model_main_tf2.py'\n",
    "destination = paths['training']\n",
    "shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08eb2c1",
   "metadata": {
    "id": "b08eb2c1"
   },
   "source": [
    "# 6. Start new training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "054d6094",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "054d6094",
    "outputId": "c96043ee-b46c-4dda-80c2-8ff75aad1098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py --model_dir=/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/models/my_ssd_mobilenet_v2_fpnlite --pipeline_config_path=/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/models/my_ssd_mobilenet_v2_fpnlite/pipeline.config --num_train_steps=5000\n"
     ]
    }
   ],
   "source": [
    "files['training_script'] = paths['training']+'/model_main_tf2.py'\n",
    "model_dir = paths['active_model']\n",
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(files['training_script'], model_dir, files['pipeline_active'])\n",
    "# first argument: Path to the model_main_tf2.py file\n",
    "# second argument: Path to the diretory in which the pipeline.config file is placed (not the path to the file itself)\n",
    "# third argument: Path to actual pipeline.config in active directory\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ci_MfWVeFuKx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ci_MfWVeFuKx",
    "outputId": "4913b6c7-8a54-4288-e0b1-5b8a37a07d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following packages will be REMOVED:\n",
      "  libcudnn8-dev\n",
      "The following held packages will be changed:\n",
      "  libcudnn8\n",
      "The following packages will be upgraded:\n",
      "  libcudnn8\n",
      "1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n",
      "Need to get 430 MB of archives.\n",
      "After this operation, 3,139 MB disk space will be freed.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
      "Fetched 430 MB in 7s (63.3 MB/s)\n",
      "(Reading database ... 155639 files and directories currently installed.)\n",
      "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
      "(Reading database ... 155617 files and directories currently installed.)\n",
      "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
      "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
      "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
     ]
    }
   ],
   "source": [
    "# This command is necessary to fix issue with training on colab\n",
    "# source: https://stackoverflow.com/questions/70998639/dnn-library-is-not-found-ssd-mobile-net-v2-in-colab#answer-72404540\n",
    "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d3f8478",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d3f8478",
    "outputId": "2cdc8a26-b8d6-4ff0-d2fe-88529f181424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-01 08:53:49.986756: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0701 08:53:49.993685 140609947961216 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
      "I0701 08:53:50.000331 140609947961216 config_util.py:552] Maybe overwriting train_steps: 5000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0701 08:53:50.000506 140609947961216 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0701 08:53:50.145030 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
      "I0701 08:53:50.154645 140609947961216 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
      "I0701 08:53:50.155277 140609947961216 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0701 08:53:50.155431 140609947961216 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0701 08:53:50.155504 140609947961216 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0701 08:53:50.158054 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0701 08:53:50.178893 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0701 08:53:56.672274 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0701 08:54:01.032211 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0701 08:54:02.615173 140609947961216 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-07-01 08:54:22.931599: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20460000 exceeds 10% of free system memory.\n",
      "2022-07-01 08:54:23.258781: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20460000 exceeds 10% of free system memory.\n",
      "2022-07-01 08:54:23.264117: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20460000 exceeds 10% of free system memory.\n",
      "2022-07-01 08:54:23.278908: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20460000 exceeds 10% of free system memory.\n",
      "2022-07-01 08:54:23.283904: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20460000 exceeds 10% of free system memory.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.046014 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.047271 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.049244 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.050085 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.051986 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.052820 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.054733 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.055569 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.057499 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0701 08:54:27.058344 140609947961216 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0701 08:54:27.668593 140604965828352 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 0.615s\n",
      "I0701 08:55:28.781833 140609947961216 model_lib_v2.py:707] Step 100 per-step time 0.615s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3486429,\n",
      " 'Loss/localization_loss': 0.2914578,\n",
      " 'Loss/regularization_loss': 0.15205657,\n",
      " 'Loss/total_loss': 0.7921573,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0701 08:55:28.782180 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.3486429,\n",
      " 'Loss/localization_loss': 0.2914578,\n",
      " 'Loss/regularization_loss': 0.15205657,\n",
      " 'Loss/total_loss': 0.7921573,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 0.287s\n",
      "I0701 08:55:57.504072 140609947961216 model_lib_v2.py:707] Step 200 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27808794,\n",
      " 'Loss/localization_loss': 0.36951256,\n",
      " 'Loss/regularization_loss': 0.15228799,\n",
      " 'Loss/total_loss': 0.7998885,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0701 08:55:57.504383 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.27808794,\n",
      " 'Loss/localization_loss': 0.36951256,\n",
      " 'Loss/regularization_loss': 0.15228799,\n",
      " 'Loss/total_loss': 0.7998885,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 0.287s\n",
      "I0701 08:56:26.242958 140609947961216 model_lib_v2.py:707] Step 300 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6560148,\n",
      " 'Loss/localization_loss': 0.30176887,\n",
      " 'Loss/regularization_loss': 0.15267065,\n",
      " 'Loss/total_loss': 1.1104543,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0701 08:56:26.243247 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.6560148,\n",
      " 'Loss/localization_loss': 0.30176887,\n",
      " 'Loss/regularization_loss': 0.15267065,\n",
      " 'Loss/total_loss': 1.1104543,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 0.288s\n",
      "I0701 08:56:54.997075 140609947961216 model_lib_v2.py:707] Step 400 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20384604,\n",
      " 'Loss/localization_loss': 0.1984351,\n",
      " 'Loss/regularization_loss': 0.15293692,\n",
      " 'Loss/total_loss': 0.55521804,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0701 08:56:54.997379 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.20384604,\n",
      " 'Loss/localization_loss': 0.1984351,\n",
      " 'Loss/regularization_loss': 0.15293692,\n",
      " 'Loss/total_loss': 0.55521804,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 0.287s\n",
      "I0701 08:57:23.656336 140609947961216 model_lib_v2.py:707] Step 500 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22394176,\n",
      " 'Loss/localization_loss': 0.38931534,\n",
      " 'Loss/regularization_loss': 0.15335593,\n",
      " 'Loss/total_loss': 0.766613,\n",
      " 'learning_rate': 0.053333}\n",
      "I0701 08:57:23.656655 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.22394176,\n",
      " 'Loss/localization_loss': 0.38931534,\n",
      " 'Loss/regularization_loss': 0.15335593,\n",
      " 'Loss/total_loss': 0.766613,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 0.287s\n",
      "I0701 08:57:52.369101 140609947961216 model_lib_v2.py:707] Step 600 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13674931,\n",
      " 'Loss/localization_loss': 0.13585433,\n",
      " 'Loss/regularization_loss': 0.15335962,\n",
      " 'Loss/total_loss': 0.42596325,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0701 08:57:52.369423 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13674931,\n",
      " 'Loss/localization_loss': 0.13585433,\n",
      " 'Loss/regularization_loss': 0.15335962,\n",
      " 'Loss/total_loss': 0.42596325,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 0.286s\n",
      "I0701 08:58:21.017485 140609947961216 model_lib_v2.py:707] Step 700 per-step time 0.286s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2591266,\n",
      " 'Loss/localization_loss': 0.18158396,\n",
      " 'Loss/regularization_loss': 0.15358786,\n",
      " 'Loss/total_loss': 0.5942984,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0701 08:58:21.017785 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.2591266,\n",
      " 'Loss/localization_loss': 0.18158396,\n",
      " 'Loss/regularization_loss': 0.15358786,\n",
      " 'Loss/total_loss': 0.5942984,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 0.286s\n",
      "I0701 08:58:49.631903 140609947961216 model_lib_v2.py:707] Step 800 per-step time 0.286s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4952892,\n",
      " 'Loss/localization_loss': 0.27095795,\n",
      " 'Loss/regularization_loss': 0.15466392,\n",
      " 'Loss/total_loss': 0.9209111,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0701 08:58:49.632202 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.4952892,\n",
      " 'Loss/localization_loss': 0.27095795,\n",
      " 'Loss/regularization_loss': 0.15466392,\n",
      " 'Loss/total_loss': 0.9209111,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 0.288s\n",
      "I0701 08:59:18.382747 140609947961216 model_lib_v2.py:707] Step 900 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16803628,\n",
      " 'Loss/localization_loss': 0.07637106,\n",
      " 'Loss/regularization_loss': 0.15503201,\n",
      " 'Loss/total_loss': 0.39943933,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0701 08:59:18.383039 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.16803628,\n",
      " 'Loss/localization_loss': 0.07637106,\n",
      " 'Loss/regularization_loss': 0.15503201,\n",
      " 'Loss/total_loss': 0.39943933,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.287s\n",
      "I0701 08:59:47.074027 140609947961216 model_lib_v2.py:707] Step 1000 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19473948,\n",
      " 'Loss/localization_loss': 0.23374826,\n",
      " 'Loss/regularization_loss': 0.15516475,\n",
      " 'Loss/total_loss': 0.5836525,\n",
      " 'learning_rate': 0.08}\n",
      "I0701 08:59:47.074362 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.19473948,\n",
      " 'Loss/localization_loss': 0.23374826,\n",
      " 'Loss/regularization_loss': 0.15516475,\n",
      " 'Loss/total_loss': 0.5836525,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.298s\n",
      "I0701 09:00:16.843174 140609947961216 model_lib_v2.py:707] Step 1100 per-step time 0.298s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1486952,\n",
      " 'Loss/localization_loss': 0.22211547,\n",
      " 'Loss/regularization_loss': 0.15543096,\n",
      " 'Loss/total_loss': 0.52624166,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0701 09:00:16.843507 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.1486952,\n",
      " 'Loss/localization_loss': 0.22211547,\n",
      " 'Loss/regularization_loss': 0.15543096,\n",
      " 'Loss/total_loss': 0.52624166,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.285s\n",
      "I0701 09:00:45.368640 140609947961216 model_lib_v2.py:707] Step 1200 per-step time 0.285s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31801343,\n",
      " 'Loss/localization_loss': 0.20764744,\n",
      " 'Loss/regularization_loss': 0.15504001,\n",
      " 'Loss/total_loss': 0.6807009,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0701 09:00:45.368941 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.31801343,\n",
      " 'Loss/localization_loss': 0.20764744,\n",
      " 'Loss/regularization_loss': 0.15504001,\n",
      " 'Loss/total_loss': 0.6807009,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.287s\n",
      "I0701 09:01:14.063471 140609947961216 model_lib_v2.py:707] Step 1300 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22422318,\n",
      " 'Loss/localization_loss': 0.14578824,\n",
      " 'Loss/regularization_loss': 0.15499942,\n",
      " 'Loss/total_loss': 0.5250108,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0701 09:01:14.063780 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.22422318,\n",
      " 'Loss/localization_loss': 0.14578824,\n",
      " 'Loss/regularization_loss': 0.15499942,\n",
      " 'Loss/total_loss': 0.5250108,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.287s\n",
      "I0701 09:01:42.714649 140609947961216 model_lib_v2.py:707] Step 1400 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16505444,\n",
      " 'Loss/localization_loss': 0.1691245,\n",
      " 'Loss/regularization_loss': 0.1546258,\n",
      " 'Loss/total_loss': 0.48880473,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0701 09:01:42.714986 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.16505444,\n",
      " 'Loss/localization_loss': 0.1691245,\n",
      " 'Loss/regularization_loss': 0.1546258,\n",
      " 'Loss/total_loss': 0.48880473,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.286s\n",
      "I0701 09:02:11.268545 140609947961216 model_lib_v2.py:707] Step 1500 per-step time 0.286s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17672963,\n",
      " 'Loss/localization_loss': 0.12543245,\n",
      " 'Loss/regularization_loss': 0.15427312,\n",
      " 'Loss/total_loss': 0.4564352,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0701 09:02:11.268827 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17672963,\n",
      " 'Loss/localization_loss': 0.12543245,\n",
      " 'Loss/regularization_loss': 0.15427312,\n",
      " 'Loss/total_loss': 0.4564352,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.287s\n",
      "I0701 09:02:39.949745 140609947961216 model_lib_v2.py:707] Step 1600 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14167082,\n",
      " 'Loss/localization_loss': 0.115453385,\n",
      " 'Loss/regularization_loss': 0.15385468,\n",
      " 'Loss/total_loss': 0.4109789,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0701 09:02:39.950079 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.14167082,\n",
      " 'Loss/localization_loss': 0.115453385,\n",
      " 'Loss/regularization_loss': 0.15385468,\n",
      " 'Loss/total_loss': 0.4109789,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.288s\n",
      "I0701 09:03:08.736052 140609947961216 model_lib_v2.py:707] Step 1700 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.102113746,\n",
      " 'Loss/localization_loss': 0.07522635,\n",
      " 'Loss/regularization_loss': 0.1534588,\n",
      " 'Loss/total_loss': 0.3307989,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0701 09:03:08.736360 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.102113746,\n",
      " 'Loss/localization_loss': 0.07522635,\n",
      " 'Loss/regularization_loss': 0.1534588,\n",
      " 'Loss/total_loss': 0.3307989,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.288s\n",
      "I0701 09:03:37.512598 140609947961216 model_lib_v2.py:707] Step 1800 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12471653,\n",
      " 'Loss/localization_loss': 0.098413065,\n",
      " 'Loss/regularization_loss': 0.15301982,\n",
      " 'Loss/total_loss': 0.37614942,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0701 09:03:37.512926 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12471653,\n",
      " 'Loss/localization_loss': 0.098413065,\n",
      " 'Loss/regularization_loss': 0.15301982,\n",
      " 'Loss/total_loss': 0.37614942,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.286s\n",
      "I0701 09:04:06.143947 140609947961216 model_lib_v2.py:707] Step 1900 per-step time 0.286s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24985369,\n",
      " 'Loss/localization_loss': 0.18724032,\n",
      " 'Loss/regularization_loss': 0.1527706,\n",
      " 'Loss/total_loss': 0.5898646,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0701 09:04:06.144351 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.24985369,\n",
      " 'Loss/localization_loss': 0.18724032,\n",
      " 'Loss/regularization_loss': 0.1527706,\n",
      " 'Loss/total_loss': 0.5898646,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.289s\n",
      "I0701 09:04:35.004648 140609947961216 model_lib_v2.py:707] Step 2000 per-step time 0.289s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10393367,\n",
      " 'Loss/localization_loss': 0.055421196,\n",
      " 'Loss/regularization_loss': 0.15229374,\n",
      " 'Loss/total_loss': 0.3116486,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0701 09:04:35.004940 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.10393367,\n",
      " 'Loss/localization_loss': 0.055421196,\n",
      " 'Loss/regularization_loss': 0.15229374,\n",
      " 'Loss/total_loss': 0.3116486,\n",
      " 'learning_rate': 0.07991781}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.293s\n",
      "I0701 09:05:04.301023 140609947961216 model_lib_v2.py:707] Step 2100 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17327061,\n",
      " 'Loss/localization_loss': 0.13461281,\n",
      " 'Loss/regularization_loss': 0.1517238,\n",
      " 'Loss/total_loss': 0.45960724,\n",
      " 'learning_rate': 0.07990056}\n",
      "I0701 09:05:04.301339 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17327061,\n",
      " 'Loss/localization_loss': 0.13461281,\n",
      " 'Loss/regularization_loss': 0.1517238,\n",
      " 'Loss/total_loss': 0.45960724,\n",
      " 'learning_rate': 0.07990056}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.290s\n",
      "I0701 09:05:33.259859 140609947961216 model_lib_v2.py:707] Step 2200 per-step time 0.290s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.098732725,\n",
      " 'Loss/localization_loss': 0.04082891,\n",
      " 'Loss/regularization_loss': 0.15127552,\n",
      " 'Loss/total_loss': 0.29083717,\n",
      " 'learning_rate': 0.07988167}\n",
      "I0701 09:05:33.260192 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.098732725,\n",
      " 'Loss/localization_loss': 0.04082891,\n",
      " 'Loss/regularization_loss': 0.15127552,\n",
      " 'Loss/total_loss': 0.29083717,\n",
      " 'learning_rate': 0.07988167}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.290s\n",
      "I0701 09:06:02.233510 140609947961216 model_lib_v2.py:707] Step 2300 per-step time 0.290s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12708832,\n",
      " 'Loss/localization_loss': 0.1682026,\n",
      " 'Loss/regularization_loss': 0.15103371,\n",
      " 'Loss/total_loss': 0.44632465,\n",
      " 'learning_rate': 0.07986114}\n",
      "I0701 09:06:02.233812 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.12708832,\n",
      " 'Loss/localization_loss': 0.1682026,\n",
      " 'Loss/regularization_loss': 0.15103371,\n",
      " 'Loss/total_loss': 0.44632465,\n",
      " 'learning_rate': 0.07986114}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.287s\n",
      "I0701 09:06:30.895646 140609947961216 model_lib_v2.py:707] Step 2400 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15599966,\n",
      " 'Loss/localization_loss': 0.11411162,\n",
      " 'Loss/regularization_loss': 0.15069775,\n",
      " 'Loss/total_loss': 0.42080903,\n",
      " 'learning_rate': 0.07983897}\n",
      "I0701 09:06:30.895964 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.15599966,\n",
      " 'Loss/localization_loss': 0.11411162,\n",
      " 'Loss/regularization_loss': 0.15069775,\n",
      " 'Loss/total_loss': 0.42080903,\n",
      " 'learning_rate': 0.07983897}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.289s\n",
      "I0701 09:06:59.787947 140609947961216 model_lib_v2.py:707] Step 2500 per-step time 0.289s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13353501,\n",
      " 'Loss/localization_loss': 0.13018021,\n",
      " 'Loss/regularization_loss': 0.15019411,\n",
      " 'Loss/total_loss': 0.41390932,\n",
      " 'learning_rate': 0.079815164}\n",
      "I0701 09:06:59.788242 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.13353501,\n",
      " 'Loss/localization_loss': 0.13018021,\n",
      " 'Loss/regularization_loss': 0.15019411,\n",
      " 'Loss/total_loss': 0.41390932,\n",
      " 'learning_rate': 0.079815164}\n",
      "INFO:tensorflow:Step 2600 per-step time 0.290s\n",
      "I0701 09:07:28.764712 140609947961216 model_lib_v2.py:707] Step 2600 per-step time 0.290s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08306305,\n",
      " 'Loss/localization_loss': 0.037104394,\n",
      " 'Loss/regularization_loss': 0.14961593,\n",
      " 'Loss/total_loss': 0.26978338,\n",
      " 'learning_rate': 0.07978972}\n",
      "I0701 09:07:28.765070 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08306305,\n",
      " 'Loss/localization_loss': 0.037104394,\n",
      " 'Loss/regularization_loss': 0.14961593,\n",
      " 'Loss/total_loss': 0.26978338,\n",
      " 'learning_rate': 0.07978972}\n",
      "INFO:tensorflow:Step 2700 per-step time 0.288s\n",
      "I0701 09:07:57.579195 140609947961216 model_lib_v2.py:707] Step 2700 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.121372074,\n",
      " 'Loss/localization_loss': 0.108338036,\n",
      " 'Loss/regularization_loss': 0.14889155,\n",
      " 'Loss/total_loss': 0.37860167,\n",
      " 'learning_rate': 0.07976264}\n",
      "I0701 09:07:57.579647 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.121372074,\n",
      " 'Loss/localization_loss': 0.108338036,\n",
      " 'Loss/regularization_loss': 0.14889155,\n",
      " 'Loss/total_loss': 0.37860167,\n",
      " 'learning_rate': 0.07976264}\n",
      "INFO:tensorflow:Step 2800 per-step time 0.290s\n",
      "I0701 09:08:26.568462 140609947961216 model_lib_v2.py:707] Step 2800 per-step time 0.290s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08134623,\n",
      " 'Loss/localization_loss': 0.045779325,\n",
      " 'Loss/regularization_loss': 0.1482669,\n",
      " 'Loss/total_loss': 0.27539247,\n",
      " 'learning_rate': 0.07973392}\n",
      "I0701 09:08:26.568767 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08134623,\n",
      " 'Loss/localization_loss': 0.045779325,\n",
      " 'Loss/regularization_loss': 0.1482669,\n",
      " 'Loss/total_loss': 0.27539247,\n",
      " 'learning_rate': 0.07973392}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.288s\n",
      "I0701 09:08:55.357747 140609947961216 model_lib_v2.py:707] Step 2900 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.112504624,\n",
      " 'Loss/localization_loss': 0.0380647,\n",
      " 'Loss/regularization_loss': 0.14765902,\n",
      " 'Loss/total_loss': 0.29822832,\n",
      " 'learning_rate': 0.07970358}\n",
      "I0701 09:08:55.358044 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.112504624,\n",
      " 'Loss/localization_loss': 0.0380647,\n",
      " 'Loss/regularization_loss': 0.14765902,\n",
      " 'Loss/total_loss': 0.29822832,\n",
      " 'learning_rate': 0.07970358}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.292s\n",
      "I0701 09:09:24.534444 140609947961216 model_lib_v2.py:707] Step 3000 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09057834,\n",
      " 'Loss/localization_loss': 0.03715436,\n",
      " 'Loss/regularization_loss': 0.14718486,\n",
      " 'Loss/total_loss': 0.27491754,\n",
      " 'learning_rate': 0.0796716}\n",
      "I0701 09:09:24.534766 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.09057834,\n",
      " 'Loss/localization_loss': 0.03715436,\n",
      " 'Loss/regularization_loss': 0.14718486,\n",
      " 'Loss/total_loss': 0.27491754,\n",
      " 'learning_rate': 0.0796716}\n",
      "INFO:tensorflow:Step 3100 per-step time 0.298s\n",
      "I0701 09:09:54.298271 140609947961216 model_lib_v2.py:707] Step 3100 per-step time 0.298s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17037109,\n",
      " 'Loss/localization_loss': 0.059164785,\n",
      " 'Loss/regularization_loss': 0.14663737,\n",
      " 'Loss/total_loss': 0.37617326,\n",
      " 'learning_rate': 0.07963799}\n",
      "I0701 09:09:54.298596 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.17037109,\n",
      " 'Loss/localization_loss': 0.059164785,\n",
      " 'Loss/regularization_loss': 0.14663737,\n",
      " 'Loss/total_loss': 0.37617326,\n",
      " 'learning_rate': 0.07963799}\n",
      "INFO:tensorflow:Step 3200 per-step time 0.293s\n",
      "I0701 09:10:23.563539 140609947961216 model_lib_v2.py:707] Step 3200 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20363395,\n",
      " 'Loss/localization_loss': 0.090331376,\n",
      " 'Loss/regularization_loss': 0.1459936,\n",
      " 'Loss/total_loss': 0.43995893,\n",
      " 'learning_rate': 0.07960275}\n",
      "I0701 09:10:23.563832 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.20363395,\n",
      " 'Loss/localization_loss': 0.090331376,\n",
      " 'Loss/regularization_loss': 0.1459936,\n",
      " 'Loss/total_loss': 0.43995893,\n",
      " 'learning_rate': 0.07960275}\n",
      "INFO:tensorflow:Step 3300 per-step time 0.295s\n",
      "I0701 09:10:53.071840 140609947961216 model_lib_v2.py:707] Step 3300 per-step time 0.295s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21155757,\n",
      " 'Loss/localization_loss': 0.08082007,\n",
      " 'Loss/regularization_loss': 0.14542377,\n",
      " 'Loss/total_loss': 0.43780142,\n",
      " 'learning_rate': 0.07956588}\n",
      "I0701 09:10:53.072143 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.21155757,\n",
      " 'Loss/localization_loss': 0.08082007,\n",
      " 'Loss/regularization_loss': 0.14542377,\n",
      " 'Loss/total_loss': 0.43780142,\n",
      " 'learning_rate': 0.07956588}\n",
      "INFO:tensorflow:Step 3400 per-step time 0.289s\n",
      "I0701 09:11:21.945105 140609947961216 model_lib_v2.py:707] Step 3400 per-step time 0.289s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06009098,\n",
      " 'Loss/localization_loss': 0.025351321,\n",
      " 'Loss/regularization_loss': 0.14465904,\n",
      " 'Loss/total_loss': 0.23010135,\n",
      " 'learning_rate': 0.079527386}\n",
      "I0701 09:11:21.945425 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06009098,\n",
      " 'Loss/localization_loss': 0.025351321,\n",
      " 'Loss/regularization_loss': 0.14465904,\n",
      " 'Loss/total_loss': 0.23010135,\n",
      " 'learning_rate': 0.079527386}\n",
      "INFO:tensorflow:Step 3500 per-step time 0.293s\n",
      "I0701 09:11:51.216119 140609947961216 model_lib_v2.py:707] Step 3500 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08209538,\n",
      " 'Loss/localization_loss': 0.0559996,\n",
      " 'Loss/regularization_loss': 0.14424516,\n",
      " 'Loss/total_loss': 0.28234014,\n",
      " 'learning_rate': 0.07948727}\n",
      "I0701 09:11:51.216531 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08209538,\n",
      " 'Loss/localization_loss': 0.0559996,\n",
      " 'Loss/regularization_loss': 0.14424516,\n",
      " 'Loss/total_loss': 0.28234014,\n",
      " 'learning_rate': 0.07948727}\n",
      "INFO:tensorflow:Step 3600 per-step time 0.293s\n",
      "I0701 09:12:20.525999 140609947961216 model_lib_v2.py:707] Step 3600 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.100538895,\n",
      " 'Loss/localization_loss': 0.05717691,\n",
      " 'Loss/regularization_loss': 0.14390157,\n",
      " 'Loss/total_loss': 0.30161738,\n",
      " 'learning_rate': 0.079445526}\n",
      "I0701 09:12:20.526302 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.100538895,\n",
      " 'Loss/localization_loss': 0.05717691,\n",
      " 'Loss/regularization_loss': 0.14390157,\n",
      " 'Loss/total_loss': 0.30161738,\n",
      " 'learning_rate': 0.079445526}\n",
      "INFO:tensorflow:Step 3700 per-step time 0.288s\n",
      "I0701 09:12:49.370657 140609947961216 model_lib_v2.py:707] Step 3700 per-step time 0.288s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06321838,\n",
      " 'Loss/localization_loss': 0.021865139,\n",
      " 'Loss/regularization_loss': 0.14317656,\n",
      " 'Loss/total_loss': 0.22826007,\n",
      " 'learning_rate': 0.07940216}\n",
      "I0701 09:12:49.370946 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.06321838,\n",
      " 'Loss/localization_loss': 0.021865139,\n",
      " 'Loss/regularization_loss': 0.14317656,\n",
      " 'Loss/total_loss': 0.22826007,\n",
      " 'learning_rate': 0.07940216}\n",
      "INFO:tensorflow:Step 3800 per-step time 0.292s\n",
      "I0701 09:13:18.583846 140609947961216 model_lib_v2.py:707] Step 3800 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.094287686,\n",
      " 'Loss/localization_loss': 0.06435582,\n",
      " 'Loss/regularization_loss': 0.14260729,\n",
      " 'Loss/total_loss': 0.30125082,\n",
      " 'learning_rate': 0.079357184}\n",
      "I0701 09:13:18.584145 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.094287686,\n",
      " 'Loss/localization_loss': 0.06435582,\n",
      " 'Loss/regularization_loss': 0.14260729,\n",
      " 'Loss/total_loss': 0.30125082,\n",
      " 'learning_rate': 0.079357184}\n",
      "INFO:tensorflow:Step 3900 per-step time 0.289s\n",
      "I0701 09:13:47.497469 140609947961216 model_lib_v2.py:707] Step 3900 per-step time 0.289s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.085835285,\n",
      " 'Loss/localization_loss': 0.044658974,\n",
      " 'Loss/regularization_loss': 0.14198874,\n",
      " 'Loss/total_loss': 0.272483,\n",
      " 'learning_rate': 0.07931058}\n",
      "I0701 09:13:47.497791 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.085835285,\n",
      " 'Loss/localization_loss': 0.044658974,\n",
      " 'Loss/regularization_loss': 0.14198874,\n",
      " 'Loss/total_loss': 0.272483,\n",
      " 'learning_rate': 0.07931058}\n",
      "INFO:tensorflow:Step 4000 per-step time 0.290s\n",
      "I0701 09:14:16.506644 140609947961216 model_lib_v2.py:707] Step 4000 per-step time 0.290s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.060321692,\n",
      " 'Loss/localization_loss': 0.061620273,\n",
      " 'Loss/regularization_loss': 0.14162168,\n",
      " 'Loss/total_loss': 0.26356363,\n",
      " 'learning_rate': 0.07926236}\n",
      "I0701 09:14:16.506970 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.060321692,\n",
      " 'Loss/localization_loss': 0.061620273,\n",
      " 'Loss/regularization_loss': 0.14162168,\n",
      " 'Loss/total_loss': 0.26356363,\n",
      " 'learning_rate': 0.07926236}\n",
      "INFO:tensorflow:Step 4100 per-step time 0.297s\n",
      "I0701 09:14:46.208412 140609947961216 model_lib_v2.py:707] Step 4100 per-step time 0.297s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07631935,\n",
      " 'Loss/localization_loss': 0.024337137,\n",
      " 'Loss/regularization_loss': 0.14125897,\n",
      " 'Loss/total_loss': 0.24191546,\n",
      " 'learning_rate': 0.07921253}\n",
      "I0701 09:14:46.208724 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07631935,\n",
      " 'Loss/localization_loss': 0.024337137,\n",
      " 'Loss/regularization_loss': 0.14125897,\n",
      " 'Loss/total_loss': 0.24191546,\n",
      " 'learning_rate': 0.07921253}\n",
      "INFO:tensorflow:Step 4200 per-step time 0.293s\n",
      "I0701 09:15:15.468817 140609947961216 model_lib_v2.py:707] Step 4200 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14721479,\n",
      " 'Loss/localization_loss': 0.08780989,\n",
      " 'Loss/regularization_loss': 0.14060366,\n",
      " 'Loss/total_loss': 0.37562835,\n",
      " 'learning_rate': 0.07916109}\n",
      "I0701 09:15:15.469117 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.14721479,\n",
      " 'Loss/localization_loss': 0.08780989,\n",
      " 'Loss/regularization_loss': 0.14060366,\n",
      " 'Loss/total_loss': 0.37562835,\n",
      " 'learning_rate': 0.07916109}\n",
      "INFO:tensorflow:Step 4300 per-step time 0.293s\n",
      "I0701 09:15:44.745286 140609947961216 model_lib_v2.py:707] Step 4300 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18884669,\n",
      " 'Loss/localization_loss': 0.09778191,\n",
      " 'Loss/regularization_loss': 0.14017121,\n",
      " 'Loss/total_loss': 0.42679983,\n",
      " 'learning_rate': 0.07910804}\n",
      "I0701 09:15:44.745633 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.18884669,\n",
      " 'Loss/localization_loss': 0.09778191,\n",
      " 'Loss/regularization_loss': 0.14017121,\n",
      " 'Loss/total_loss': 0.42679983,\n",
      " 'learning_rate': 0.07910804}\n",
      "INFO:tensorflow:Step 4400 per-step time 0.292s\n",
      "I0701 09:16:13.943396 140609947961216 model_lib_v2.py:707] Step 4400 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07896378,\n",
      " 'Loss/localization_loss': 0.035836797,\n",
      " 'Loss/regularization_loss': 0.13952218,\n",
      " 'Loss/total_loss': 0.25432277,\n",
      " 'learning_rate': 0.07905338}\n",
      "I0701 09:16:13.943699 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07896378,\n",
      " 'Loss/localization_loss': 0.035836797,\n",
      " 'Loss/regularization_loss': 0.13952218,\n",
      " 'Loss/total_loss': 0.25432277,\n",
      " 'learning_rate': 0.07905338}\n",
      "INFO:tensorflow:Step 4500 per-step time 0.292s\n",
      "I0701 09:16:43.103392 140609947961216 model_lib_v2.py:707] Step 4500 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11860597,\n",
      " 'Loss/localization_loss': 0.035773188,\n",
      " 'Loss/regularization_loss': 0.13885781,\n",
      " 'Loss/total_loss': 0.29323697,\n",
      " 'learning_rate': 0.07899711}\n",
      "I0701 09:16:43.103674 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.11860597,\n",
      " 'Loss/localization_loss': 0.035773188,\n",
      " 'Loss/regularization_loss': 0.13885781,\n",
      " 'Loss/total_loss': 0.29323697,\n",
      " 'learning_rate': 0.07899711}\n",
      "INFO:tensorflow:Step 4600 per-step time 0.293s\n",
      "I0701 09:17:12.411026 140609947961216 model_lib_v2.py:707] Step 4600 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.051019397,\n",
      " 'Loss/localization_loss': 0.023768488,\n",
      " 'Loss/regularization_loss': 0.13819633,\n",
      " 'Loss/total_loss': 0.21298422,\n",
      " 'learning_rate': 0.078939244}\n",
      "I0701 09:17:12.411361 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.051019397,\n",
      " 'Loss/localization_loss': 0.023768488,\n",
      " 'Loss/regularization_loss': 0.13819633,\n",
      " 'Loss/total_loss': 0.21298422,\n",
      " 'learning_rate': 0.078939244}\n",
      "INFO:tensorflow:Step 4700 per-step time 0.292s\n",
      "I0701 09:17:41.576088 140609947961216 model_lib_v2.py:707] Step 4700 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08275693,\n",
      " 'Loss/localization_loss': 0.035269912,\n",
      " 'Loss/regularization_loss': 0.13754119,\n",
      " 'Loss/total_loss': 0.25556803,\n",
      " 'learning_rate': 0.07887978}\n",
      "I0701 09:17:41.577003 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.08275693,\n",
      " 'Loss/localization_loss': 0.035269912,\n",
      " 'Loss/regularization_loss': 0.13754119,\n",
      " 'Loss/total_loss': 0.25556803,\n",
      " 'learning_rate': 0.07887978}\n",
      "INFO:tensorflow:Step 4800 per-step time 0.293s\n",
      "I0701 09:18:10.827956 140609947961216 model_lib_v2.py:707] Step 4800 per-step time 0.293s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16002469,\n",
      " 'Loss/localization_loss': 0.07089505,\n",
      " 'Loss/regularization_loss': 0.13709028,\n",
      " 'Loss/total_loss': 0.36801004,\n",
      " 'learning_rate': 0.07881871}\n",
      "I0701 09:18:10.828267 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.16002469,\n",
      " 'Loss/localization_loss': 0.07089505,\n",
      " 'Loss/regularization_loss': 0.13709028,\n",
      " 'Loss/total_loss': 0.36801004,\n",
      " 'learning_rate': 0.07881871}\n",
      "INFO:tensorflow:Step 4900 per-step time 0.291s\n",
      "I0701 09:18:39.958193 140609947961216 model_lib_v2.py:707] Step 4900 per-step time 0.291s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07955934,\n",
      " 'Loss/localization_loss': 0.047088955,\n",
      " 'Loss/regularization_loss': 0.1364445,\n",
      " 'Loss/total_loss': 0.2630928,\n",
      " 'learning_rate': 0.07875605}\n",
      "I0701 09:18:39.958501 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07955934,\n",
      " 'Loss/localization_loss': 0.047088955,\n",
      " 'Loss/regularization_loss': 0.1364445,\n",
      " 'Loss/total_loss': 0.2630928,\n",
      " 'learning_rate': 0.07875605}\n",
      "INFO:tensorflow:Step 5000 per-step time 0.292s\n",
      "I0701 09:19:09.119664 140609947961216 model_lib_v2.py:707] Step 5000 per-step time 0.292s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07463472,\n",
      " 'Loss/localization_loss': 0.052333746,\n",
      " 'Loss/regularization_loss': 0.13589123,\n",
      " 'Loss/total_loss': 0.2628597,\n",
      " 'learning_rate': 0.078691795}\n",
      "I0701 09:19:09.119954 140609947961216 model_lib_v2.py:708] {'Loss/classification_loss': 0.07463472,\n",
      " 'Loss/localization_loss': 0.052333746,\n",
      " 'Loss/regularization_loss': 0.13589123,\n",
      " 'Loss/total_loss': 0.2628597,\n",
      " 'learning_rate': 0.078691795}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9AuGfWolM0nF",
   "metadata": {
    "id": "9AuGfWolM0nF"
   },
   "source": [
    "# Evaluate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "BECyzsFhM4P-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BECyzsFhM4P-",
    "outputId": "dc23dfc2-abc7-4aeb-b34c-fd1f16880969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py\", line 89, in main\n",
      "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 195, in checkpoints_iterator\n",
      "    checkpoint_dir, checkpoint_path, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/Colab_Notebooks/Object_Detection/2_Tensorflow/workspace/training/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 325, in run\n",
      "    if FLAGS.pdb_post_mortem and sys.stdout.isatty():\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/flags/_flagvalues.py\", line 467, in __getattr__\n",
      "    def __getattr__(self, name):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(files['training_script'], model_dir, files['pipeline_active'], model_dir)\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z8h8jfhMAPw4",
   "metadata": {
    "id": "Z8h8jfhMAPw4"
   },
   "source": [
    "# Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "VCeIQNwLALYQ",
   "metadata": {
    "id": "VCeIQNwLALYQ"
   },
   "outputs": [],
   "source": [
    "# Make zip file from directory\n",
    "import zipfile\n",
    "os.chdir(paths['models'])\n",
    "    \n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "with zipfile.ZipFile(custom_model_name+'.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipdir(paths['active_model'], zipf)\n",
    "\n",
    "# Download zip file to local machine manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alUPdl5nLs7p",
   "metadata": {
    "id": "alUPdl5nLs7p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "1_Preparing_Model.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "joshBak2",
   "language": "python",
   "name": "joshbak2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
